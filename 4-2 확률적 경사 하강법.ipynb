{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-2 확률적 경사 하강법.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNIccXcrJ2Ocdtjo4oCNTPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Machine-learning_Theory/blob/master/4-2%20%ED%99%95%EB%A5%A0%EC%A0%81%20%EA%B2%BD%EC%82%AC%20%ED%95%98%EA%B0%95%EB%B2%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV_I8x_DZXFS"
      },
      "source": [
        "# 확률적 경사 하강법\n",
        "\n",
        "- 경사를 따라 내려가는 방법(가장 가파른 경사를 따라 원하는 지점에 도달하는 것이 목표지만 조금씩 내려오는 것이 중요함).\n",
        "\n",
        "- 앞서 훈련한 모델을 버리지 않고 새로운 데이터에 대해서만 조금씩 훈련함. 데이터가 매일매일 업데이트 되어도 학습을 계속 이어갈 수 있음(점진적 학습 or 온라인 학습).\n",
        "\n",
        "- 하나의 샘플을 훈련 세트에서 무작위하게(확률적으로) 골라서 가장 가파른 경사를 찾음. 그다음 랜덤하게 또 다른 샘플 하나를 선택하여 경사를 조금 내려감. 전체 샘플을 모두 사용할 때까지 반복함.\n",
        "\n",
        "  - 에포크(Epoch): 훈련 세트를 한 번 모두 사용하는 과정. 수십, 수백 번 이상 수행함.\n",
        "\n",
        "- 모든 샘플을 사용했지만 경사를 다 내려오지 못했다면 다시 처음부터 시작함. 훈련 세트에 모든 샘플을 다시 채워 넣고 위 과정을 반복함.\n",
        "\n",
        "- '신경망 알고리즘'에서 꼭 사용함. 신경망 알고리즘은 일반적으로 많은 데이터를 사용하기 때문에 한 번에 모든 데이터를 사용하기 어려움. 아울러 모델이 매우 복잡하기도 해서 수학적 방법으로 해답을 얻기 어려움.\n",
        "\n",
        "- 미니배치 경사 하강법(Minibatch gradiant descent): 하나의 샘플이 아닌 무작위로 몇 개의 샘플을 선택해서 경사를 내려감. 실전과 신경망 알고리즘에서 많이 사용함.\n",
        "\n",
        "- 배치 경사 하강법(Batch gradiant descent): 극단적으로 한 번 경사로를 따라 이동하기 위해 전체 샘플을 사용함. 전체 샘플을 사용하기에 가장 안정적인 방법일 수 있으나 컴퓨터 자원을 많이 사용함. 데이터가 지나치게 많으면 전체 데이터를 모두 읽지 못할 수도 있음.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rweMcP6FT99"
      },
      "source": [
        "## 점진적인 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HSBbvjtZqqV"
      },
      "source": [
        "### 손실 함수\n",
        "\n",
        "- 손실 함수(loss function): 머신러닝 알고리즘이 얼마나 엉터리인지 측정하는 기준. 샘플 하나에 대한 손실을 정의함. 손실 함수 값이 작을수록 좋지만 어떤 값이 최솟값인지는 알지 못함. 만족할 만한 수준이면 경사를 다 내려왔다고 인정해야 함. 확률적 경사 하강법에 적절함.\n",
        "\n",
        "- 비용 함수(cost function): 훈련 세트에 있는 모든 샘플에 대한 손실 함수의 합을 의미함. 보통 손실 함수와 구분하지 않고 섞어서 사용함.\n",
        "\n",
        "- 분류에서 손실이란 정답을 못 맞히는 것임.\n",
        "\n",
        " e.g. 도미는 양성 클래스(1), 빙어는 음성 클래스(0)일 때,\n",
        " \n",
        "   - 첫 번째 타깃은 1인데 1로 예측함(맞힘).\n",
        " \n",
        "   - 두 번째 타깃은 1인데 0으로 예측함(틀림).\n",
        " \n",
        "   - 세 번째 타깃은 0인데 0으로 예측함(맞힘).\n",
        " \n",
        "   - 네 번째 타깃은 0인데 1로 예측함(틀림).\n",
        " \n",
        " 4개 중 2개를 맞혔으니 정확도는 0.5임. 손실 함수는 정확도에 음수를 취하면 -1. 0은 가장 낮으며 -0.0은 가장 높음. 그러나 이렇게 4개의 샘플만 있다면 정확도는 0, 0.25, 0.5, 0.75, 1로 5개뿐이라서 경사 하강법을 활용하여 조금씩 움직일 수 없음. 경사가 좀 더 연속적일 필요가 있음. 아래 로지스틱 손실 함수란에서 추가로 예시를 듦.\n",
        "\n",
        "- 기술적으로 손실 함수는 미분이 가능해야 함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOsKuj7shHZC"
      },
      "source": [
        "### 로지스틱 손실 함수\n",
        "\n",
        "- '이진 크로스엔트로피 손실 함수(Binary cross-entropy loss function)'라고도 부름.\n",
        "\n",
        "- 이 함수를 사용하면 로지스틱 회귀 모델이 만들어짐.\n",
        "\n",
        "- 다중 분류의 경우 '크로스엔트로피 손실 함수(cross-entropy function)'를 사용함.\n",
        "\n",
        "- 위 손실 함수란에서 문제점을 제시했듯, 경사가 연속적이려면 확률이 0 ~ 1 사이의 어떤 값도 될 수 있어야 함. 가령 위 e.g.에서 제시한 샘플 4개의 예측 확률을 0.9, 0.3, 0.2, 0.8이라고 가정하면..\n",
        "\n",
        " - 첫 번째 샘플의 예측 확률이 0.9이므로 양성 클래스의 타깃(1)과 곱한 후 음수로 바꿀 수 있음. 예측이 1에 가까울수록 좋은 모델이며 예측과 타깃의 곱의 음수는 점점 작아짐. 이 값을 손실 함수로 사용해도 좋음.\n",
        " \n",
        "   - 0.9(예측) * 1(정답인 타깃) -> -0.9(낮은 손실)\n",
        "\n",
        " - 두 번째 샘플의 예측 확률이 0.3이므로 양성 클래스의 타깃(1)과 거리가 멂. 계산해보면 첫 번째 손실보다 높은 손실이 됨.\n",
        "\n",
        "   - 0.3(예측) * 1(정답인 타깃) -> -0.3(높은 손실)\n",
        "\n",
        " - 세 번째 샘플의 예측 확률이 0.2인데, 음성 클래스의 타깃(0)이라서 그대로 곱하면 무조건 0이 되므로, 타깃을 양성 클래스의 타깃(1)처럼 바꿔서 예측값을 양성 클래스의 타깃(1)에 대한 예측으로 바꿈. 즉 1 - 0.2 = 0.8 로 사용함.\n",
        "\n",
        "   - 0.8(예측) * 1(정답인 타깃) -> -0.8(낮은 손실)\n",
        "\n",
        " - 네 번째 샘플의 예측 확률이 0.8인데, 음성 클래스의 타깃(0)이라서 그대로 곱하면 무조건 0이 되므로, 타깃을 양성 클래스의 타깃(1)처럼 바꿔서 예측값을 양성 클래스의 타깃(1)에 대한 예측으로 바꿈. 즉 1 - 0.8 = 0.2 로 사용함.\n",
        "\n",
        "   - 0.2(예측) * 1(정답인 타깃) -> -0.2(높은 손실)\n",
        "\n",
        " - 이 예측 확률들에 로그 함수를 적용하면, 예측 확률의 범위(0 ~ 1)에서 로그 함수는 음수가 되므로 최종 손실 값은 양수가 됨. 손실이 양수가 되면 이해하기 더 쉬움. 아울러 로그 함수는 0에 가까울수록 아주 큰 음수가 되므로 손실을 아주 크게 만들어서 모델에 큰 영향을 미칠 수 있음.\n",
        "\n",
        "   - 타깃 = 1 일 때 -log(예측 확률)\n",
        "\n",
        "      예측 확률이 1에서 멀어질수록 손실은 아주 큰 양수가 됨.\n",
        "\n",
        "   - 타깃 = 0 일 때 -log(1 - 예측 확률)\n",
        "\n",
        "      예측 확률이 0에서 멀어질수록 손실은 아주 큰 양수가 됨.\n",
        "\n",
        "- 회귀의 경우 손실 함수로 '평균 절댓값 오차'(타깃에서 예측을 뺀 절댓값을 모든 샘플에 평균한 값) 또는 '평균 제곱 오차'(타깃에서 예측을 뺀 값을 제곱한 다음 모든 샘플에 평균한 값)를 사용함. 값이 작을수록 좋은 모델임."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPo9PpdcFW8m"
      },
      "source": [
        "## SGDClassifier\n",
        "\n",
        "- '확률적 경사 하강법'을 제공하는 대표적인 분류용 클래스.\n",
        "\n",
        "- `loss`: 손실 함수의 종류를 지정하는 매개변수. `log`는 '로지스틱 손실 함수'. 기본값은 `hinge`. 아래에서 '힌지 손실(hinge loss)'에 대하여 간략하게 설명함.\n",
        "\n",
        "- `penalty`: 규제의 종류를 지정하는 매개변수. 기본값은 `l2`.\n",
        "\n",
        "- `alpha`: 규제 강도를 지정하는 매개변수. 기본값은 0.0001.\n",
        "\n",
        "- `max_iter`: 수행할 에포크 횟수를 지정하는 매개변수. 10이면 10회를 반복함.\n",
        "\n",
        "- `tol`: 반복을 멈출 조건을 지정하는 매개변수. 기본값은 `0.001`.\n",
        "\n",
        "- `n_iter_no_change`: 손실이 `tol`만큼 줄어들지 않으면 알고리즘이 중단되도록 에포크를 지정하는 매개변수. 기본값은 `5`.\n",
        "\n",
        "- `SGDRegressor`: 확률적 경사 하강법을 사용한 회귀 모델을 만드는 클래스. `SGDClassifier` 클래스에서 사용하는 매개변수와 동일하게 사용함.\n",
        "\n",
        "   - `loss`: 기본값은 제곱 오차를 나타내는 `squared_loss`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyWZrLgZPDeH"
      },
      "source": [
        "### 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaokJuINPzd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a651f17c-fe83-4253-cb2f-c202739eb133"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "fish = pd.read_csv('https://bit.ly/fish_csv_data')\n",
        "print(fish)\n",
        "\n",
        "fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n",
        "fish_target = fish['Species'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Species  Weight  Length  Diagonal   Height   Width\n",
            "0     Bream   242.0    25.4      30.0  11.5200  4.0200\n",
            "1     Bream   290.0    26.3      31.2  12.4800  4.3056\n",
            "2     Bream   340.0    26.5      31.1  12.3778  4.6961\n",
            "3     Bream   363.0    29.0      33.5  12.7300  4.4555\n",
            "4     Bream   430.0    29.0      34.0  12.4440  5.1340\n",
            "..      ...     ...     ...       ...      ...     ...\n",
            "154   Smelt    12.2    12.2      13.4   2.0904  1.3936\n",
            "155   Smelt    13.4    12.4      13.5   2.4300  1.2690\n",
            "156   Smelt    12.2    13.0      13.8   2.2770  1.2558\n",
            "157   Smelt    19.7    14.3      15.2   2.8728  2.0672\n",
            "158   Smelt    19.9    15.0      16.2   2.9322  1.8792\n",
            "\n",
            "[159 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR4yoE-rNeIV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlE3QsZoNyJg"
      },
      "source": [
        "# 훈련 세트와 테스트 세트의 특성을 표준화 전처리 함.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "ss.fit(train_input) # 반드시 훈련 세트에서 학습한 통계 값으로 테스트 세트도 변환해야 함.\n",
        "\n",
        "train_scaled = ss.transform(train_input)\n",
        "test_scaled = ss.transform(test_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1vEsMmAPIO6"
      },
      "source": [
        "### SGDClassifier 클래스로 모델 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qJFqnivPaD7",
        "outputId": "b61ac0fd-b6aa-4706-fd4e-4373a4d47e59"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sc = SGDClassifier(loss='log', max_iter=10, random_state=42) # 손실 함수를 '로지스틱 손실 함수'로 지정함.\n",
        "sc.fit(train_scaled, train_target)\n",
        "\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))\n",
        "# 'ConvergenceWarning' 경고가 뜨는 이유는 모델이 충분히 수렴하지 않았다는 의미임. `max_iter` 매개변수의 값을 늘려서 반복 횟수를 늘려줘야 함."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.773109243697479\n",
            "0.775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VROgF5ZJQq_C",
        "outputId": "39b888b5-1c13-4c04-da29-1ed44958f35a"
      },
      "source": [
        "# 모델을 이어서 훈련할 때는 `partial_fit()` 메서드를 사용함. 호출할 때마다 1 에포크씩 이어서 훈련함.\n",
        "sc.partial_fit(train_scaled, train_target, )\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))\n",
        "# 정확도가 향상됨.\n",
        "# 'train_scaled'과 'train_target'을 한꺼번에 사용했으니 확률적 경사 하강법이 아닌 배치 경사 하강법으로 여길 수 있음.\n",
        "# 그러나 `SGDClassifier` 클래스는 훈련 세트에서 1개씩 샘플을 꺼내어 경사 하강법 단계를 수행함.\n",
        "# 즉 '미니배치 경사 하강법'이나 '배치 하강법'을 제공하지 않는 클래스임."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8151260504201681\n",
            "0.825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkDgwq1tSiEl"
      },
      "source": [
        "### 에포크와 과대/과소적합\n",
        "\n",
        "- 에포크 횟수가 적으면 모델이 훈련 세트를 덜 학습하고, 경사를 다 내려오기 전에 훈련을 마치는 셈임.\n",
        "\n",
        " (과소적합 된 모델이 될 가능성이 높음)\n",
        "\n",
        "- 에포크 횟수가 많으면 모델이 훈련 세트를 완전히 학습하고, 경사를 많이 내려와서 훈련 세트에 잘 맞는 모델이 만들어짐.\n",
        "\n",
        " (과대적합 된 모델이 될 가능성이 높음)\n",
        "\n",
        "   - 조기 종료(Early stopping): 무작정 에포크 횟수를 늘리는 것은 과대적합 된 모델이 될 가능성이 높으므로, 과대적합이 되기 전에 훈련을 멈추는 것을 의미함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9NjQgsnV3Kb"
      },
      "source": [
        "#### 적절한 에포크 찾고 조기 종료 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4ty65uqRxSG",
        "outputId": "f7a1d89d-da8a-416f-d431-ff56f9ed6094"
      },
      "source": [
        "# 적절한 에포크를 찾고자 그래프를 그릴 준비를 함.\n",
        "import numpy as np\n",
        "\n",
        "sc = SGDClassifier(loss='log', random_state=42)\n",
        "\n",
        "# 훈련 세트와 테스트 세트에 대한 점수를 기록하고자 리스트 2개를 마련함.\n",
        "train_score = []\n",
        "test_score = []\n",
        "\n",
        "# `partial_fit()` 메서드만 사용하려면 훈련 세트에 있는 전체 클래스의 레이블을 `partial_fit()` 메서드에 있는 `classes` 매개변수에 전달해줘야 함.\n",
        "# 이를 위해 'train_target'에 있는 생선 7개의 목록을 만듦.\n",
        "# 아래는 `classes` 매개변수에 대한 설명임.\n",
        "\n",
        "# classes: ndarray of shape (n_classes,), default=None\n",
        "#     Classes across all calls to partial_fit.\n",
        "# Can be obtained by via np.unique(y_all), where y_all is the\n",
        "# target vector of the entire dataset.\n",
        "# This argument is required for the first call to partial_fit\n",
        "# and can be omitted in the subsequent calls.\n",
        "# Note that y doesn't need to contain all labels in classes.\n",
        "classes = np.unique(train_target) # `classes` 매개변수에 대한 설명대로 `np.unique()` 함수를 활용하여 생선 7개의 배열을 만듦.\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4_Tkf4obCHN"
      },
      "source": [
        "for _ in range(1, 300) : # `_` 는 나중에 사용하지 않고 그냥 버리는 값을 넣어두는 용도임. 0 ~ 299까지 반복 횟수를 임시로 저장하기 위함.\n",
        "    sc.partial_fit(train_scaled, train_target, classes=classes) # 생선 7개의 배열을 `classes` 매개변수에 전달함.\n",
        "\n",
        "    # 0 ~ 299번 반복해서 얻은 점수를 각 리스트에 전달함.\n",
        "    train_score.append(sc.score(train_scaled, train_target))\n",
        "    test_score.append(sc.score(test_scaled, test_target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "NBbaeQKZXIkv",
        "outputId": "27523fc3-292f-4b34-ebe9-3d240479e0aa"
      },
      "source": [
        "# 각 리스트에 전달한 점수를 그래프로 그림.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_score)\n",
        "plt.plot(test_score)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()\n",
        "# 백 번째 에포크 이후부터 훈련 세트와 테스트 테스의 점수가 점점 벌어지고 있음.\n",
        "# 즉 훈련 세트와 테스트 세트 점수가 가장 가까운 에포크가 적절한 에포크임."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98ZJIlBR04cm",
        "outputId": "16dea22a-af59-4d3d-a0e3-e62f1d19ac9c"
      },
      "source": [
        "sc = SGDClassifier(loss='log', max_iter=100, tol=None, random_state=42)\n",
        "# `SGDClassifier`클래스는 일정 에포크 동안 성능이 향상되지 않으면 훈련을 자동으로 멈춤.\n",
        "# `tol`: 반복을 멈출 조건을 지정하는 매개변수. 성능이 향상될 최솟값을 지정함.\n",
        "# 여기선 멈출 조건을 없음(None)으로 지정하여 자동으로 멈추지 않고 `max_iter = 100`만큼 무조건 반복하도록 설정함.\n",
        "sc.fit(train_scaled, train_target)\n",
        "\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.957983193277311\n",
            "0.925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ5o-sDs7Sfu"
      },
      "source": [
        "### 힌지 손실\n",
        "\n",
        "- `SGDClassifier` 클래스의 `loss` 매개변수의 기본값은 `hinge` 이며, 이는 '힌지 손실(hinge loss)'을 의미함.\n",
        "\n",
        "   - 힌지 손실(hinge loss): '서포트 벡터 머신(support vector machine)' 머신러닝 알고리즘을 위한 손실 함수."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSHxkjdi7RRU",
        "outputId": "376217a1-2a7f-485c-9a18-4288e970509f"
      },
      "source": [
        "# '힌지 손실'을 사용하여 같은 반복 횟수로 모델을 훈련함.\n",
        "sc = SGDClassifier(loss='hinge', max_iter=100, tol=None, random_state=42)\n",
        "sc.fit(train_scaled, train_target)\n",
        "\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9495798319327731\n",
            "0.925\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}