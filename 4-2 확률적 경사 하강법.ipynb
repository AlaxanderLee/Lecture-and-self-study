{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-2 확률적 경사 하강법.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOJof0ppSGgWWJOuE+iQVGZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Machine-learning_Theory/blob/master/4-2%20%ED%99%95%EB%A5%A0%EC%A0%81%20%EA%B2%BD%EC%82%AC%20%ED%95%98%EA%B0%95%EB%B2%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV_I8x_DZXFS"
      },
      "source": [
        "# **확률적 경사 하강법**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rweMcP6FT99"
      },
      "source": [
        "## **점진적인 학습**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**점진적 학습(=온라인 학습)**은 훈련한 모델을 버리지 않고 새로운 데이터만 조금씩 추가하여 훈련하는 방법입니다. 훈련에 사용한 데이터를 유지할 필요도 없고 이전에 훈련한 내용을 초기화할 필요도 없습니다. 대표적인 점진적 학습 알고리즘은 **확률적 경사 하강법(Stochastic Gradient Descent)**입니다."
      ],
      "metadata": {
        "id": "xxPI6ujtbngI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **확률적 경사 하강법**"
      ],
      "metadata": {
        "id": "aMbfzJyPbcT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**확률적 경사 하강법(Stochastic Gradient Descent)**은 가장 가파른 경사를 따라 최적 지점에 도달하는 것을 목표로 삼은 방법입니다. 훈련 세트에서 샘플 하나만 확률적으로 랜덤하게 골라서 가장 가파른 길을 찾고, 또 다른 샘플 하나를 랜덤하게 선택하여 경사를 조금 내려갑니다. 이렇게 전체 샘플을 모두 사용할 때까지 반복합니다. 훈련 세트를 한 번 모두 사용하는 과정을 **에포크(epoch)**라고 부릅니다. 샘플을 모두 사용했는데 만족할 만한 위치까지 경사를 모두 내려오지 못했다면 처음으로 돌아가 다시 경사를 내려옵니다. 수십, 수백 번 이상 에포크를 수행합니다.\n",
        "\n",
        "확률적 경사 하강법은 신경망 알고리즘에서 꼭 사용합니다. 신경망 알고리즘은 일반적으로 많은 데이터를 사용하기 때문에 한 번에 모든 데이터를 사용하기도 어렵고, 모델이 매우 복잡하기 때문에 수학적 방법으로 해답을 얻기도 쉽지 않기 때문입니다."
      ],
      "metadata": {
        "id": "Cokj-1-hbT_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **미니배치 경사 하강법**"
      ],
      "metadata": {
        "id": "5nGFYvWdf3V8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**미니배치 경사 하강법(Minibatch gradiant descent)**은 하나의 샘플이 아닌 무작위로 몇 개의 샘플을 선택해서 경사를 내려갑니다. 실전에서 매우 많이 사용하며, 특히 신경망 알고리즘에서 많이 사용합니다."
      ],
      "metadata": {
        "id": "TFZH7iuMbS6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **배치 경사 하강법**"
      ],
      "metadata": {
        "id": "SE-ExG9PgIKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**배치 경사 하강법(Batch gradiant descent)**은 경사를 한 번 내려오기 위해 전체 샘플을 사용합니다. 전체 샘플을 사용하므로 가장 안정적인 방법일 수 있으나 컴퓨터 자원을 많이 사용합니다. 데이터가 지나치게 많으면 전체 데이터를 모두 읽지 못할 수도 있습니다."
      ],
      "metadata": {
        "id": "GsTOVM0AgLKj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HSBbvjtZqqV"
      },
      "source": [
        "### **손실 함수**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**손실 함수(loss function)(=비용 함수(cost function))**는 경사 하강법으로 내려오는 경사를 의미하며, 머신러닝 알고리즘이 얼마나 엉터리인지 측정하는 기준입니다. 확률적 경사 하강법이 최적화할 대상으로 볼 수 있습니다. 손실 함수의 값은 작을수록 좋습니다.\n",
        "\n",
        "**비용 함수(cost function)**는 훈련 세트에 있는 모든 샘플에 대한 손실 함수의 합을 의미합니다. 보통 손실 함수와 구분하지 않고 섞어서 사용합니다.\n",
        "\n",
        "손실 함수는 샘플 하나에 대한 손실을 정의합니다. 분류에서 손실이란 정답을 못 맞히는 것입니다. 예컨대 도미는 양성 클래스(1), 빙어는 음성 클래스(0)일 때, 다음과 같은 예측과 정답을 가정하겠습니다.\n",
        "\n",
        "- 첫 번째 타깃은 1이고, 1로 예측하여 맞혔습니다. 예측 확률은 0.9입니다.\n",
        "\n",
        "- 두 번째 타깃은 1이고, 0으로 예측하여 틀렸습니다. 예측 확률은 0.3입니다.\n",
        " \n",
        "- 세 번째 타깃은 0이고, 0으로 예측하여 맞혔습니다. 예측 확률은 0.2입니다.\n",
        " \n",
        "- 네 번째 타깃은 0이고, 1로 예측하여 틀렸습니다. 예측 확률은 0.8입니다.\n",
        " \n",
        "4개 중 2개를 맞혔으니 예측 정확도는 0.5입니다. 만약 정확도에 음수를 취하면 -1이 가장 낮고, -0.0은 가장 높습니다. 다만 이렇게 4개의 샘플만 있다면 정확도는 0, 0.25, 0.5, 0.75, 1로 5개만 도출되므로 경사 하강법을 활용하여 조금씩 내려올 수 없습니다. 경사가 좀 더 연속적일 필요가 있습니다. 기술적으로 손실 함수는 미분이 가능해야 합니다. "
      ],
      "metadata": {
        "id": "zDcCDwuYhJHS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOsKuj7shHZC"
      },
      "source": [
        "#### **로지스틱 손실 함수**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**로지스틱 손실 함수(logistic loss function)(=이진 크로스엔트로피 손실 함수(Binary cross-entropy loss function)**는 이진 분류에 사용하는 손실 함수입니다. 이 손실 함수를 사용하면 로지스틱 회귀 모델이 생성됩니다. 손실 함수를 직접 만드는 일은 없지만 관련 내용을 간단하게나마 살펴보겠습니다. \n",
        "\n",
        "첫 번째 샘플에 대한 예측 확률은 0.9로 가정했습니다. 0.9에 양성 클래스 타깃인 1과 곱하고 음수로 취합니다. 이때 예측이 1에 가까울수록 좋은 모델이며, 예측과 타깃의 곱의 음수는 점점 작아집니다.\n",
        "\n",
        "$$0.9 \\times 1 -> -0.9$$\n",
        "\n",
        "두 번째 샘플에 대한 예측 확률은 0.3으로 가정했습니다. 0.3에 양성 클래스 타깃인 1과 곱하고 음수로 취합니다.\n",
        "\n",
        "$$0.3 \\times 1 -> -0.3$$\n",
        "\n",
        "첫 번째 샘플의 -0.9보다 0에 더 가까운 -0.3입니다. 0에 더 가까울수록 높은 손실로 여깁니다.\n",
        "\n",
        "세 번째 샘플에 대한 예측 확률은 0.2로 가정했습니다. 다만 양성 클래스 1이 아닌 음성 클래스 0이 타깃입니다. 음성 클래스 0과 예측 확률 0.2를 곱하면 무조건 0이 되므로 타깃을 양성 클래스처럼 바꾸는 작업이 필요합니다. 양성 클래스 1에서 예측 확률을 빼면 됩니다.\n",
        "\n",
        "$$1 - 0.2 = 0.8$$\n",
        "\n",
        "0.8에 1을 곱하고 음수를 취하는 것은 동일합니다.\n",
        "\n",
        "$$0.8 \\times 1 -> -0.8$$\n",
        "\n",
        "네 번째 샘플에 대한 예측 확률은 0.8로 가정했습니다. 이 샘플의 타깃도 음성 클래스 0입니다. 세 번째 샘플에서 수행한 작업과 같은 방식을 취하면 됩니다.\n",
        "\n",
        "$$1 - 0.8 = 0.2$$\n",
        "\n",
        "$$0.2 \\times 1 -> -0.2$$\n",
        "\n",
        "결론적으로 첫 번째, 세 번째 샘플은 제대로 예측했으므로 손실이 낮고, 두 번째, 네 번째 샘플은 예측에 실패했으므로 손실이 높습니다. 다시 한 번 강조하지만 0에 더 가까울수록 높은 손실로 여깁니다.\n",
        "\n",
        "이 예측 확률들에 로그 함수를 적용하면, 예측 확률의 범위(0 ~ 1)에서 로그 함수는 음수가 되므로 최종 손실 값은 양수가 됩니다. 손실이 양수가 되면 이해하기 더 수월합니다. 아울러 로그 함수는 0에 가까울수록 아주 큰 음수가 되므로 손실을 아주 크게 만들어서 모델에 큰 영향을 미칠 수도 있습니다. 타깃이 1일 때 $-log(예측 확률)$로 계산하고, 예측 확률이 1에서 멀어질수록 손실은 아주 큰 양수입니다. 타깃이 0일 때 $-log(1-예측 확률)$로 계산하고, 예측 확률이 0에서 멀어질수록 손실은 아주 큰 양수입니다.\n",
        "\n",
        "참고로 다중 분류의 경우 **크로스엔트로피 손실 함수(cross-entropy function)**를 사용합니다. 실무에서는 이진 분류와 다중 분류를 구분하지 않고 크로스엔트로피 손실 함수로 부르는 경우도 많습니다.\n",
        "\n",
        "회귀의 경우 손실 함수로 **평균 절댓값 오차**(타깃에서 예측을 뺀 절댓값을 모든 샘플에 평균한 값) 또는 **평균 제곱 오차**(타깃에서 예측을 뺀 값을 제곱한 다음 모든 샘플에 평균한 값)를 사용합니다. 값이 작을수록 좋은 모델입니다."
      ],
      "metadata": {
        "id": "hMJ1zgNFLDC9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPo9PpdcFW8m"
      },
      "source": [
        "## **SGDClassifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`SGDClassifier` 클래스는 확률적 경사 하강법을 제공하는 대표적인 분류용 클래스입니다. 관련 매개변수 목록은 아래와 같습니다.\n",
        "\n",
        "- `loss`: 손실 함수의 종류를 지정하는 매개변수입니다. `log`는 로지스틱 손실 함수입니다. 기본값은 `hinge`이며 **힌지 손실(hinge loss)**을 의미합니다. 아래에서 설명하겠습니다.\n",
        "\n",
        "- `penalty`: 규제의 종류를 지정하는 매개변수입니다. 기본값은 `l2`이며 L2 규제를 의미합니다.\n",
        "\n",
        "- `alpha`: 규제 강도를 지정하는 매개변수입니다. 기본값은 `0.0001`입니다.\n",
        "\n",
        "- `max_iter`: 수행할 에포크 횟수를 지정하는 매개변수입니다. `10`이면 10회를 반복합니다.\n",
        "\n",
        "- `tol`: 반복을 멈출 조건을 지정하는 매개변수입니다. 기본값은 `0.001`입니다.\n",
        "\n",
        "- `n_iter_no_change`: 손실이 `tol`만큼 줄어들지 않으면 알고리즘이 중단되도록 에포크를 지정하는 매개변수입니다. 기본값은 `5`입니다.\n",
        "\n",
        "`SGDRegressor` 클래스는 확률적 경사 하강법을 사용한 회귀 모델을 만드는 클래스입니다. `SGDClassifier` 클래스에서 사용하는 매개변수와 동일하게 사용하지만 매개변수 하나가 다릅니다.\n",
        "\n",
        "   - `loss`: 손실 함수의 종류를 지정하는 매개변수입니다. 기본값은 `squared_loss`이며 제곱 오차를 의미합니다."
      ],
      "metadata": {
        "id": "hTsC3lawRwiJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyWZrLgZPDeH"
      },
      "source": [
        "### **데이터 준비**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터를 준비하겠습니다."
      ],
      "metadata": {
        "id": "Yj3pK16rTVTz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaokJuINPzd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c184b2e-eb74-47a1-c377-87cb356c8506"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "fish = pd.read_csv('https://bit.ly/fish_csv_data')\n",
        "print(fish)\n",
        "print()\n",
        "print(fish.info())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Species  Weight  Length  Diagonal   Height   Width\n",
            "0     Bream   242.0    25.4      30.0  11.5200  4.0200\n",
            "1     Bream   290.0    26.3      31.2  12.4800  4.3056\n",
            "2     Bream   340.0    26.5      31.1  12.3778  4.6961\n",
            "3     Bream   363.0    29.0      33.5  12.7300  4.4555\n",
            "4     Bream   430.0    29.0      34.0  12.4440  5.1340\n",
            "..      ...     ...     ...       ...      ...     ...\n",
            "154   Smelt    12.2    12.2      13.4   2.0904  1.3936\n",
            "155   Smelt    13.4    12.4      13.5   2.4300  1.2690\n",
            "156   Smelt    12.2    13.0      13.8   2.2770  1.2558\n",
            "157   Smelt    19.7    14.3      15.2   2.8728  2.0672\n",
            "158   Smelt    19.9    15.0      16.2   2.9322  1.8792\n",
            "\n",
            "[159 rows x 6 columns]\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159 entries, 0 to 158\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Species   159 non-null    object \n",
            " 1   Weight    159 non-null    float64\n",
            " 2   Length    159 non-null    float64\n",
            " 3   Diagonal  159 non-null    float64\n",
            " 4   Height    159 non-null    float64\n",
            " 5   Width     159 non-null    float64\n",
            "dtypes: float64(5), object(1)\n",
            "memory usage: 7.6+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'Species' 열을 타깃으로 삼고, 나머지 열은 입력 데이터로 삼겠습니다."
      ],
      "metadata": {
        "id": "iBrXc27YT7nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n",
        "fish_target = fish['Species'].to_numpy()"
      ],
      "metadata": {
        "id": "8G2eGuviTtO_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 세트와 테스트 세트로 나누겠습니다."
      ],
      "metadata": {
        "id": "dKOL2RG5UGXc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR4yoE-rNeIV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(\n",
        "    fish_input, fish_target, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 세트와 테스트 세트의 특성을 표준화 전처리 하겠습니다."
      ],
      "metadata": {
        "id": "zuyUztxJUKc4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlE3QsZoNyJg"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "ss.fit(train_input)\n",
        "\n",
        "train_scaled = ss.transform(train_input)\n",
        "test_scaled = ss.transform(test_input)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1vEsMmAPIO6"
      },
      "source": [
        "### **SGDClassifier 클래스로 모델 훈련하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`SGDClassifier` 클래스로 모델을 훈련하겠습니다. 손실 함수는 로지스틱 손실 함수로 지정하고, 반복 횟수는 10번으로 지정하겠습니다. "
      ],
      "metadata": {
        "id": "Dxb4GbwzVpaq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qJFqnivPaD7",
        "outputId": "093933fb-aea8-423f-cacc-d2e69423fa77"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sc = SGDClassifier(loss='log', max_iter=10, random_state=42)\n",
        "sc.fit(train_scaled, train_target)\n",
        "\n",
        "print(f'훈련 세트 점수:   {sc.score(train_scaled, train_target)}')\n",
        "print(f'테스트 세트 점수: {sc.score(test_scaled, test_target)}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 세트 점수:   0.773109243697479\n",
            "테스트 세트 점수: 0.775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "과소적합입니다. `ConvergenceWarning` 경고가 뜨는 이유는 모델이 충분히 수렴하지 않았다는 의미입니다. `max_iter` 매개변수의 값을 늘려서 반복 횟수를 늘리는 편이 좋습니다.\n",
        "\n",
        "모델을 이어서 훈련해보겠습니다. 확률적 경사 하강법은 점진적 학습이 가능하므로 새로운 인스턴스를 선언하지 않고 기존 인스턴스로 지속해서 훈련할 수 있습니다. 지속해서 훈련하려면 `partial_fit()` 메서드를 사용합니다. 한 번 사용할 때마다 1 에포크씩 거치며 훈련합니다."
      ],
      "metadata": {
        "id": "fzNT3-QLV3jh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VROgF5ZJQq_C",
        "outputId": "281f7835-fd41-475c-d5f1-b34de765ba3b"
      },
      "source": [
        "sc.partial_fit(train_scaled, train_target, )\n",
        "print(f'훈련 세트 점수:   {sc.score(train_scaled, train_target)}')\n",
        "print(f'테스트 세트 점수: {sc.score(test_scaled, test_target)}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 세트 점수:   0.8151260504201681\n",
            "테스트 세트 점수: 0.825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정확도가 향상되었지만 여전히 과소적합입니다. `train_scaled`와 `train_target`을 한꺼번에 사용했으니 확률적 경사 하강법이 아닌 배치 경사 하강법으로 여길 수도 있습니다. 그러나 `SGDClassifier` 클래스는 훈련 세트에서 1개씩 샘플을 꺼내어 경사 하강법 단계를 수행하는 클래스입니다. 미니배치 경사 하강법이나 배치 하강법을 제공하지 않습니다."
      ],
      "metadata": {
        "id": "cmJ3r35eXt3r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkDgwq1tSiEl"
      },
      "source": [
        "### **에포크와 과대/과소적합**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "에포크 횟수에 따라 과대적합과 과소적합의 여부가 결정됩니다. 에포크 횟수가 적으면 모델이 훈련 세트를 덜 학습합니다. 경사를 덜 내려와서 과소적합 모델이 될 가능성이 높습니다. 반면 에포크 횟수가 많으면 모델이 훈련 세트를 완전히 학습합니다. 경사를 많이 내려와서 훈련 세트에 잘 맞는 모델이 만들어집니다. 과대적합 모델이 될 가능성이 높습니다. 에포크 횟수가 지나치게 많으면 과대적합 모델이 만들어지므로 **조기 종료(Early stopping)**를 통해 적절한 에포크 횟수에서 멈춰야 합니다."
      ],
      "metadata": {
        "id": "GdmEgI2fawLu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9NjQgsnV3Kb"
      },
      "source": [
        "#### **적절한 에포크 찾고 조기 종료 하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적절한 에포크를 찾기 위해 그래프를 그리겠습니다. 반복 횟수는 지정하지 않고 `partial_fit()` 메서드만 사용하겠습니다. 참고로 `partial_fit()` 메서드만 사용하려면 훈련 세트에 있는 전체 클래스 레이블을 `partial_fit()` 메서드에 있는 `classes` 매개변수에 전달해줘야 합니다. `classes` 매개변수에 전달하기 위해 `train_target`에 있는 생선 7종을 가진 리스트를 만들어야 합니다."
      ],
      "metadata": {
        "id": "7EZh0aFoc1_X"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4ty65uqRxSG",
        "outputId": "85e8f2de-8dfa-499b-bc96-e3c78bcd90d8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sc = SGDClassifier(loss='log', random_state=42)\n",
        "\n",
        "train_score = []\n",
        "test_score = []\n",
        "\n",
        "# 생선 7종을 가진 리스트를 생성합니다.\n",
        "classes = np.unique(train_target)\n",
        "print(classes)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "에포크 300번 동안 훈련을 반복하겠습니다. "
      ],
      "metadata": {
        "id": "I4qlezQdhM9C"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4_Tkf4obCHN"
      },
      "source": [
        "for _ in range(1, 300):    # `_`는 나중에 사용하지 않고 그냥 버리는 값을 넣어두는 용도입니다.\n",
        "    # 생선 7종을 가진 리스트를 `classes` 매개변수에 전달합니다.\n",
        "    sc.partial_fit(train_scaled, train_target, classes=classes)\n",
        "\n",
        "    train_score.append(sc.score(train_scaled, train_target))\n",
        "    test_score.append(sc.score(test_scaled, test_target))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 리스트에 전달한 점수를 그래프로 그리겠습니다."
      ],
      "metadata": {
        "id": "PBRnmh9gjpNt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "NBbaeQKZXIkv",
        "outputId": "9303525c-ae97-4fdb-8763-acc0ab8976eb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_score)\n",
        "plt.plot(test_score)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "백 번째 에포크 이후부터 훈련 세트와 테스트 테스의 점수가 점점 벌어지고 있습니다. 훈련 세트와 테스트 세트 점수가 가장 가까운 에포크가 적절한 에포크이므로 백 번째 에포크가 최적 반복 횟수입니다.\n",
        "\n",
        "`SGDClassifier` 클래스는 일정 에포크 동안 성능이 향상되지 않으면 훈련을 자동으로 멈춥니다. `tol` 매개변수는 반복을 멈출 조건을 지정하는 매개변수입니다. 성능이 향상될 최솟값을 지정합니다. 여기선 멈출 조건을 `None`으로 지정하여 자동으로 멈추지 않고 100번만큼 무조건 반복하도록 설정하겠습니다."
      ],
      "metadata": {
        "id": "DFsuHkxDjtNQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98ZJIlBR04cm",
        "outputId": "f000c3c4-d4b7-42ae-ca48-777164da3185"
      },
      "source": [
        "sc = SGDClassifier(loss='log', max_iter=100, tol=None, random_state=42)\n",
        "sc.fit(train_scaled, train_target)\n",
        "\n",
        "print(f'훈련 세트 점수:   {sc.score(train_scaled, train_target)}')\n",
        "print(f'테스트 세트 점수: {sc.score(test_scaled, test_target)}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 세트 점수:   0.957983193277311\n",
            "테스트 세트 점수: 0.925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ5o-sDs7Sfu"
      },
      "source": [
        "### **힌지 손실**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고로 `SGDClassifier` 클래스의 `loss` 매개변수의 기본값은 `hinge`이며, 이는 **힌지 손실(hinge loss)**을 의미합니다. 힌지손실은 **서포트 벡터 머신(support vector machine)** 머신러닝 알고리즘을 위한 손실 함수입니다. 서포트 벡터 머신에 대한 내용은 [링크](https://hleecaster.com/ml-svm-concept/)를 참조하시기 바랍니다."
      ],
      "metadata": {
        "id": "A0DNpBYloAxA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSHxkjdi7RRU",
        "outputId": "e17b8c6a-af1d-4040-8267-1852251478f9"
      },
      "source": [
        "sc = SGDClassifier(loss='hinge', max_iter=100, tol=None, random_state=42)\n",
        "sc.fit(train_scaled, train_target)\n",
        "\n",
        "print(f'훈련 세트 점수:   {sc.score(train_scaled, train_target)}')\n",
        "print(f'테스트 세트 점수: {sc.score(test_scaled, test_target)}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 세트 점수:   0.9495798319327731\n",
            "테스트 세트 점수: 0.925\n"
          ]
        }
      ]
    }
  ]
}