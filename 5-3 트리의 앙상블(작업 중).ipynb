{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5-3 트리의 앙상블(작업 중).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNl1HhyODRJfsLt///DmvYg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Lecture-and-self-study/blob/master/5-3%20%ED%8A%B8%EB%A6%AC%EC%9D%98%20%EC%95%99%EC%83%81%EB%B8%94(%EC%9E%91%EC%97%85%20%EC%A4%91).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52iVN67BFPWl"
      },
      "source": [
        "# 트리의 앙상블"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cSetDMTG7fd"
      },
      "source": [
        "## 정형 데이터와 비정형 데이터\n",
        "\n",
        "- 정형 데이터: 구조화 된 데이터로 CSV, Database, Excel에 저장하기 쉬움. '앙상블 학습(Ensemble learning)' 은 정형 데이터를 다루는 데 가장 뛰어난 성과를 내는 결정 트리 기반 알고리즘임.\n",
        "\n",
        "- 비정형 데이터: 비구조화 된 데이터로 텍스트 데이터, 사진, 디지털 음악 등을 의미함. 규칙성을 찾기 어려워 전통적인 머신러닝 방법으로 모델을 만들기 어려우므로 '신경망 알고리즘' 을 활용하여 모델을 만듦."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8VxCiG9G9wl"
      },
      "source": [
        "## 랜덤 포레스트\n",
        "\n",
        "- '랜덤 포레스트(Random Forest)'는 앙상블 학습의 대표 주자로 안정적인 성능을 내며, 앙상블 학습을 적용할 때 가장 먼저 시도하길 권장하는 모델임. 결정 트리를 랜덤하게 만들어 결정 트리의 숲을 만들고, 각 결정 트리의 예측을 사용하여 최종 예측을 만듦. \n",
        "\n",
        "- 각 트리를 훈련하기 위한 데이터를 랜덤하게 만드는데, 입력한 훈련 데이터에서 랜덤하게 샘플을 추출하여 훈련 데이터를 만듦. 이때 한 샘플이 중복되어 추출될 수 있음.\n",
        "\n",
        " - e.g. 가방 1,000개에서 샘플을 100개씩 뽑는다면 먼저 1개를 뽑고, 뽑았던 1개를 다시 가방에 넣음. 이렇게 계속 100개를 가방에서 뽑으면 중복된 샘플을 뽑을 수 있는데 이 샘플을 '부트스트랩 샘플(Bootstrap sample)' 이라고 부름. 기본적으로 훈련 세트의 크기와 같게 만듦. 가방 1,000개에서 중복하여 샘플 1,000개를 뽑기 때문에 부트스트랩 샘플은 훈련 세트와 크기가 같음.\n",
        "\n",
        " - 부트스트랩(Bootstrap): 보통 부트스트랩 방식이라고 부르며, 위 예시처럼 데이터 세트에서 중복을 허용하여 데이터를 샘플링하는 방식을 의미함.\n",
        "\n",
        "- 각 노드를 분할할 때 전체 특성 중에서 일부 특성을 무작위로 고른 다음 이 중에서 최선의 분할을 찾음.\n",
        "\n",
        " - RandomForestClassifier: 분류 클래스이며, 전체 특성 개수의 제곱근만큼 특성을 사용함. 즉 특성 4개가 있다면 노드마다 2개를 랜덤하게 선택하여 사용함.\n",
        " \n",
        " - RandomForestRegressor: 회귀 클래스이며, 전체 특성을 사용함.\n",
        "\n",
        "- 기본적으로 결정 트리 100개를 이 방식으로 훈련함.\n",
        "\n",
        " - 분류일 경우에는 각 트리의 클래스별 확률을 평균하여 가장 높은 확률을 가진 클래스를 예측으로 삼음. \n",
        " \n",
        " - 회귀일 경우에는 각 트리의 예측을 평균한 값을 예측으로 삼음.\n",
        "\n",
        "- 랜덤하게 선택한 샘플과 특성을 사용하기 때문에 훈련 세트에 과대적합되는 것을 방지하고, 검증 세트와 테스트 세트에서 안정적인 성능을 얻을 수 있음. 종종 기본 매개변수 설정만으로도 좋은 결과를 냄."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kGDfdypg7rG"
      },
      "source": [
        "### 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALbk0IYlgK3g"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
        "\n",
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "\n",
        "target = wine['class'].to_numpy()\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD7qgN-8iLiS",
        "outputId": "f39cccec-ce14-49c0-baa9-ba7b260adeb6"
      },
      "source": [
        "# 교차 검증을 수행함.\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_jobs = -1, random_state = 42)\n",
        "\n",
        "scores = cross_validate(rf, train_input, train_target, return_train_score = True, n_jobs = -1)\n",
        "print(scores)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "# 과대적합 상태임."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'fit_time': array([0.5771153 , 0.57878351, 0.54379249, 0.59855843, 0.43957901]), 'score_time': array([0.10182524, 0.10208392, 0.10220408, 0.10204697, 0.10196471]), 'test_score': array([0.88461538, 0.88942308, 0.90279115, 0.88931665, 0.88642926]), 'train_score': array([0.9971133 , 0.99663219, 0.9978355 , 0.9973545 , 0.9978355 ])}\n",
            "0.9973541965122431 0.8905151032797809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkXLggQ5HJI5"
      },
      "source": [
        "## 엑스트라 트리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSMrl_AsHKss"
      },
      "source": [
        "## 그레이디언트 부스팅"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MLRAKvKHNU5"
      },
      "source": [
        "## 히스토그램 기반 그레이디언트 부스팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnJA_djXFJit"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}