{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHAPTER7 텍스트 데이터 다루기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5f3/4+FBPxMUFjQtZlXeR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Machine-learning_Theory/blob/master/CHAPTER7%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%8B%A4%EB%A3%A8%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaMOLd5s0rqO"
      },
      "source": [
        "# 들어가며\n",
        "\n",
        "4장에서 데이터의 속성을 나타내는 두 가지 특성에 대해 다뤘습니다. 정량적인 연속형 특성, 고정된 목록에서 값이 정해지는 범주형 특성입니다. 이번 챕터에서는 많은 애플리케이션에서 사용하는 세 번째 유형의 데이터인 텍스트를 다룹니다. 예컨대 스팸 메일 분류의 경우에는 이메일 내용에 이 분류 작업에 필요한 중요한 정보가 들어 있습니다. 정치인의 의견을 분석하는 경우에는 언행이나 트윗이 중요한 정보를 가집니다. 고객 서비스의 경우에는 고객 메시지에 목적을 구분할 수 있는 정보가 있습니다. 메시지의 제목과 내용을 토대로 의도를 파악해서 해당 부서로 전달하거나 자동 응답으로 전환할 수 있습니다.\n",
        "\n",
        "텍스트 데이터는 주로 글자가 연결된 문자열로 표현됩니다. 길이가 서로 같은 경우는 거의 없습니다. 현재까지 살폈던 수치형 특성과 매우 상이하므로 전처리는 필수입니다. 내용의 길이가 다르므로 전처리 과정이 없으면 샘플마다 특성 수가 달라집니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFMw8a9uVBSP"
      },
      "source": [
        "# **7.1 문자열 데이터 종류**\n",
        "\n",
        "텍스트는 보통 문자열이지만 모든 문자열 특성을 텍스트로 다루는 것은 아닙니다. 문자열 특성은 범주형 변수로 표현할 수도 있습니다. 문자열 특성을 다루는 방법에 대해 인지하려면 데이터를 직접 살피는 수밖에 없습니다. 문자열 데이터 종류는 아래 4종류입니다.\n",
        "\n",
        "- **범주형 데이터**: 고정된 목록입니다. 예컨대 사람들에게 가장 좋아하는 색을 묻는 설문의 형태로 데이터를 수집하고자 한다면, 드롭다운(drop-down) 메뉴에서 'red', 'green', 'blue', 'yellow', 'black', 'white', 'puple', 'pink' 중 하나를 선택해야 합니다. 이 경우에 데이터셋에 색상 8개 중에 하나가 들어가고 범주형 변수로 인코딩 됩니다. 값들이 얼마나 자주 나타나는지 히스토그램을 그려볼 수 있습니다. 설문이 절반 정도 진행된 상태에서 설문자가 'black'을 'blacl'이라고 오타를 발견하여 수정했다면, 이 데이터셋에는 같은 의미를 나타내는 두 텍스트가 모두 들어있으므로 하나로 합쳐야 합니다.\n",
        "\n",
        "- **범주에 의미를 연결할 수 있는 임의의** 문자열: 드롭다운 메뉴 대신 텍스트 필드(test field)를 제공했다고 가정한다면, 설문자 대부분은 대체적으로 사용되는 표현을 사용하지만 몇몇 설문자는 '회색', '쥐색', '암청색'처럼 다른 표현을 사용할 수 있습니다. 이외 저 특이하게 색을 표현할지도 모릅니다. 이렇게 텍스트 필드로 받는 응답을 인코딩하려면 가장 보편적인 값을 선택하거나, 애플리케이션에 적합하도록 모든 응답을 포용할 수 있는 범주를 적절하게 정의해야 합니다. '여러 가지 색'이라는 범주를 만들어서 할당하거나, 인코딩이 불가능한 값은 '그 외'로 할당합니다. 이런 전처리는 수많은 수작업이 필요하고 자동화가 어렵습니다. 가능한 한 범주형 변수로 받는 것이 현명합니다.\n",
        "\n",
        "- **구조화된 문자열 데이터**: 정의된 범주에 속하진 않지만 직접 입력한 값들이 주소나 장소, 사람 이름, 날짜, 전화번호, 식별번호처럼 일정하게 구조화된 문자열 데이터 형식을 취할 수 있습니다. 이런 종류의 문자열은 분석하기 난해하고, 처리 방법이 문맥과 분야에 따라 매우 다릅니다. \n",
        "\n",
        "- **텍스트 데이터**: 자유로운 형태의 절과 문장으로 구성된 형태는 텍스트 데이터입니다. 트위터, 채팅, 리뷰, 소설 작품, 인터넷 문서 등 이런 종류를 통칭합니다. 대부분 단어로 구성된 문장에 정보를 담습니다. 텍스트 분석에서는 데이터셋을 말뭉치(corpus), 텍스트 하나를 의미하는 각 샘플은 문서(document)라고 합니다. 정보 검색(IR, information retrieval)과 자연어 처리(NLP, natural language processing) 공동체에서 유래한 표현들입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qViaTCdHVBP0"
      },
      "source": [
        "# **7.2 예제 애플리케이션: 영화 리뷰 감성 분석**\n",
        "\n",
        "지금부터 사용한 [데이터셋](http://ai.stanford.edu/~amaas/data/sentiment)의 출처는 스탠퍼드 대학교 연구원인 앤드루 마스가 IMDb라는 웹사이트입니다. 이 데이터셋은 리뷰 텍스트와 '양성' 혹은 '음성'을 나타내는 레이블을 포함합니다. 양성은 긍정적인 반응, 음성은 부정적인 반응입니다. 이런 형식은 데이터를 적절하게 표현한 게 아닐 수 있지만 그대로 사용하기로 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBXuR61jpde7"
      },
      "source": [
        "macOS나 리눅스를 사용한다면 아래 명령어로 데이터를 다운로드하고 압축을 해제합니다. 물론 코랩도 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uduD93Bpi_3",
        "outputId": "0cb2ec52-fb3f-4b68-859c-039f7263646b"
      },
      "source": [
        "# '!' 기호는 실행한다는 의미입니다.\n",
        "!wget -nc http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -P data\n",
        "!tar xzf data/aclImdb_v1.tar.gz --skip-old-files -C data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-15 06:54:00--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘data/aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  30.3MB/s    in 2.7s    \n",
            "\n",
            "2021-09-15 06:54:03 (30.3 MB/s) - ‘data/aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B7kqzPFqasv"
      },
      "source": [
        "압축을 해제하면 두 폴더에 텍스트 파일이 들어 있습니다. 하나는 훈련 데이터, 다른 하나는 테스트 데이터입니다. 이 두 폴더는 다시 pos와 neg 하위 폴더를 포함합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNuAg-HeqbAw",
        "outputId": "71918285-400f-46e9-ab66-c74c9f37d382"
      },
      "source": [
        "# !은 셸(shell) 명령을 실행하는 IPython의 매직 명령어입니다.\n",
        "# tree 명령이 없다면 find ./data -type d 명령을 사용해서\n",
        "# 하위 폴더의 목록을 볼 수 있습니다.\n",
        "!tree -dL 2 data/aclImdb # 이 명령은 유효하지 않습니다.\n",
        "!find ./data -type d # 유효한 명령입니다."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: tree: command not found\n",
            "./data\n",
            "./data/aclImdb\n",
            "./data/aclImdb/train\n",
            "./data/aclImdb/train/unsup\n",
            "./data/aclImdb/train/neg\n",
            "./data/aclImdb/train/pos\n",
            "./data/aclImdb/test\n",
            "./data/aclImdb/test/neg\n",
            "./data/aclImdb/test/pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gyYrl1dv3pO"
      },
      "source": [
        "pos 폴더에는 긍정적인 리뷰가 각각 파일 하나로 나뉘어 있고 neg 폴더도 마찬가지입니다. unsup 폴더에는 레이블이 없는 데이터가 있습니다. 이 폴더는 사용하지 않으므로 삭제합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-ZvKQfivWhp"
      },
      "source": [
        "!rm -r data/aclImdb/train/unsup"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T6SwLi9wIqo"
      },
      "source": [
        "하위 폴더가 레이블로 구분된 폴더 구조라면 `load_files` 함수를 사용하여 파일을 읽습니다. 이 함수를 사용하여 폴더를 읽을 때 레이블은 폴더의 알파벳순에 따라 0부터 부여됩니다. 여기서는 neg 폴더의 데이터는 레이블이 0이 되고, pos 폴더의 데이터는 레이블이 1이 됩니다. 먼저 훈련 데이터를 이 함수로 읽습니다. 참고로 지금까지는 데이터셋을 `train_test_split` 함수를 통해 훈련 세트와 테스트 세트로 나눠서 사용했으나 지금 사용할 데이터셋은 이미 두 세트로 나눠져 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvnXgLwjw0YL",
        "outputId": "0c4cc8ec-1197-4b43-82e3-0a715c70a9e9"
      },
      "source": [
        "from sklearn.datasets import load_files\n",
        "\n",
        "reviews_train = load_files('data/aclImdb/train/')\n",
        "# 텍스트와 레이블을 포함하고 있는 Bunch 오브젝트를 반환합니다.\n",
        "text_train, y_train = reviews_train.data, reviews_train.target\n",
        "print('text_train의 타입:', type(text_train))\n",
        "print('text_train의 길이:', len(text_train))\n",
        "print('text_train[6]:\\n', text_train[6])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_train의 타입: <class 'list'>\n",
            "text_train의 길이: 25000\n",
            "text_train[6]:\n",
            " b\"This movie has a special way of telling the story, at first i found it rather odd as it jumped through time and I had no idea whats happening.<br /><br />Anyway the story line was although simple, but still very real and touching. You met someone the first time, you fell in love completely, but broke up at last and promoted a deadly agony. Who hasn't go through this? but we will never forget this kind of pain in our life. <br /><br />I would say i am rather touched as two actor has shown great performance in showing the love between the characters. I just wish that the story could be a happy ending.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA5Oi-ixZAsQ"
      },
      "source": [
        "결과를 보면 길이는 25,000(리뷰 개수)이며 각 항목은 리뷰 한 개에 대한 문자열입니다. 리뷰는 HTML 줄바꿈 태그(`<br />`)를 포함합니다. 줄바꿈 태그가 머신러닝 모델에 큰 영향을 미치진 않지만 미리 태그를 삭제해서 데이터를 정리하면 좋습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ano8xWMaaFO7"
      },
      "source": [
        "text_train = [doc.replace(b'<br />', b' ') for doc in text_train]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BWfN4f8ahNR"
      },
      "source": [
        "'text_train'의 항목 타입은 파이썬 버전에 따라 상이합니다. 파이썬 3에서는 문자열 데이터의 바이너리 인코딩인 bytes 타입입니다. 파이썬 2에서는 문자열입니다. 자세히 다루지 않고 넘어갑니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO7STDl3a8HO"
      },
      "source": [
        "이 데이터셋은 양성 클래스와 음성 클래스를 같은 비율로 수집했으므로 양성과 음성 레이블의 수가 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAOk_T7Ncg_J",
        "outputId": "fdb9e37b-5423-4aa8-8540-18b9b829a113"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print('클래스별 샘플 수 (훈련 데이터):', np.bincount(y_train))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스별 샘플 수 (훈련 데이터): [12500 12500]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBqhfUJ8cwB_"
      },
      "source": [
        "같은 방식으로 테스트 데이터셋을 읽습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iulKjHnbc0Jb",
        "outputId": "55a390f6-c331-48ec-fd7f-bc601d1ee5f1"
      },
      "source": [
        "reviews_test = load_files('data/aclImdb/test/')\n",
        "text_test, y_test = reviews_test.data, reviews_test.target\n",
        "print('테스트 데이터의 문서 수:', len(text_test))\n",
        "print('클래스별 샘플 수 (테스트 데이터):', np.bincount(y_test))\n",
        "text_test = [doc.replace(b'<br />', b' ') for doc in text_test]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터의 문서 수: 25000\n",
            "클래스별 샘플 수 (테스트 데이터): [12500 12500]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMRznID6dfjK"
      },
      "source": [
        "우리는 리뷰가 하나 주어졌을 때 이 리뷰의 텍스트 내용을 보고 양성과 음성을 구분해야 합니다. 전형적인 이진 분류 문제인 것입니다. 그러나 텍스트 데이터는 머신러닝 모델이 다룰 수 있는 형태가 아닙니다. 텍스트의 문자열 표현을 머신러닝 알고리즘에 적용할 수 있게 수치 표현으로 바꿔야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qau0Slz4VBNV"
      },
      "source": [
        "# **7.3 텍스트 데이터를 BOW로 표현하기**\n",
        "\n",
        "머신러닝에서 텍스트를 표현하는 방법 중 **BOW(bag of words)**는 가장 간단하면서 효과적이고 널리 쓰이는 방법입니다. 이 방법을 통해 장, 문단, 문장, 서식과 같은 입력 텍스트의 구조 대부분을 잃고, 각 단어가 이 말뭉치에 있는 텍스트에 얼마나 많이 나타나는지만 헤아립니다. 구조와 상관없이 단어의 출현 횟수만 세므로 텍스트를 담는 가방(bag)으로 여길 수 있습니다. \n",
        "\n",
        "전체 말뭉치에 대해 BOW 표현을 계산하려면 다음 세 단계를 거칩니다.\n",
        "\n",
        "1. 토큰화(tokenization): 각 문서를 문서에 포함된 단어(토큰)로 나눕니다. 예를 들면 공백이나 구두점 등을 기준으로 분리합니다.\n",
        "\n",
        "1. 어휘 사전 구축: 모든 문서에 나타난 모든 단어의 어휘를 모으고 번호를 매깁니다. 알파벳 순서로 구성됩니다.\n",
        "\n",
        "1. 인코딩: 어휘 사전의 단어가 문서마다 몇 번이나 나타나는지 헤아립니다.\n",
        "\n",
        "1단계와 2단계에 관련한 세부 사항은 이 챕터의 뒷부분에서 상세하게 설명합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_AMi11MgrHk"
      },
      "source": [
        "BOW 표현을 만드는 방법을 설명하겠습니다.\n",
        "\n",
        "'This is how you get ants.' 라는 문자열을 처리하는 과정입니다.\n",
        "\n",
        "1. 토큰화: ['this', 'is', 'how', 'you', 'get', 'ants']\n",
        "\n",
        "1. 어휘 사전 구축: ['aardvark', 'amsterdam', 'ants', ... 'you', 'your', 'zyxst']\n",
        "\n",
        "1. 희소 행렬 인코딩: aardvark, ..., ants, ..., get, ..., you, ..., zyxst [0, ..., 0, 1, 0, ...., 0, 1, 0, ..., 0, 1, 0, ..., 0]\n",
        "\n",
        "출력은 각 문서에서 나타난 단어의 횟수가 담긴 벡터 하나입니다. 이를 위해 사전에 있는 각 단어가 문서마다 얼마나 자주 나타나는지 세야 합니다. 이 수치 표현은 전체 데이터셋에서 고유한 각 단어를 특성으로 가집니다. 원본 문자열에 있는 단어순은 BOW 특성 표현에서는 완전하게 무시됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s-r1xE3VBLA"
      },
      "source": [
        "## **7.3.1 샘플 데이터에 BOW 적용하기**\n",
        "\n",
        "BOW 표현은 `CountVecterizer` 클래스에 변환기 인터페이스로 구현되어 있습니다. 두 샘플만 포함한 데이터셋에 적용해서 작동하는 방식을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WYUfdTkPTIR"
      },
      "source": [
        "bards_words = ['The fool doth think he is wise,',\n",
        "               'but the wise man knows himself to be a fool']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al58LIyBPfwZ"
      },
      "source": [
        "`CountVectorizer` 클래스를 임포트 해서 객체를 만들고, 샘플 데이터에 `fit` 메서드를 적용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFpia0RrPuXn",
        "outputId": "cfe07cd9-f510-4de9-9398-ccfaef8d8dea"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer()\n",
        "vect.fit(bards_words)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATE-M6-eP_xj"
      },
      "source": [
        "`CountVectorizer` 클래스의 `fit` 메서드는 훈련 데이터를 토큰으로 나누고 어휘 사전을 구축하여 `vocabulary_` 속성에 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9TWNYhqQQre",
        "outputId": "d1aee4db-3ed5-4b7c-8610-6b52a4d8aec1"
      },
      "source": [
        "print('어휘 사전의 크기:', len(vect.vocabulary_))\n",
        "print('어휘 사전의 내용:\\n', vect.vocabulary_)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어휘 사전의 크기: 13\n",
            "어휘 사전의 내용:\n",
            " {'the': 9, 'fool': 3, 'doth': 2, 'think': 10, 'he': 4, 'is': 6, 'wise': 12, 'but': 1, 'man': 8, 'knows': 7, 'himself': 5, 'to': 11, 'be': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO2EA7nWQg6o"
      },
      "source": [
        "훈련 데이터에 대해 BOW 표현을 만들기 위해 `transform` 메서드를 호출합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpVI5__xQlzm",
        "outputId": "cae83bbe-4888-4a52-cf99-704b9243314e"
      },
      "source": [
        "bag_of_words = vect.transform(bards_words)\n",
        "print('BOW:', repr(bag_of_words))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOW: <2x13 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 16 stored elements in Compressed Sparse Row format>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL8ntiv4QzPH"
      },
      "source": [
        "BOW 표현은 0이 아닌 값만 저장하는 사이파이 희소 행렬로 저장됩니다. 행렬의 크기는 $2 \\times 13$이며, 각 행은 샘플 하나를 나타내고, 각 특성은 어휘 사전에 있는 단어입니다. 문서 대부분은 어휘 사전에 있는 단어 중에 일부만 포함합니다(특성 배열 대부분의 원소가 0이라서 희소 행렬을 사용합니다). 전체 영어 단어 수에 비하여 영화 리뷰에 얼마나 많은 단어가 나타날지(어휘 사전이 어떻게 구성될지) 생각해보면 이해하기 쉽습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_9MuOQ7T6LF"
      },
      "source": [
        "값이 0인 원소를 모두 저장하면 메모리를 낭비하는 것입니다. 희소 행렬의 실제 내용을 살피려면 `toarray` 메서드를 사용해서 0인 원소도 모두 저장되는 밀집된 넘파이 배열로 바꿔야 합니다. 다만 이 데이터셋은 단어 13개만 가졌으므로 배열 변형이 가능하지만 실제로 거대한 데이터셋에 적용한다면 MemorryError가 발생할 가능성이 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dFefyfPR9_d",
        "outputId": "24f7e674-ad0f-4e0c-9114-6e4e85598551"
      },
      "source": [
        "print('BOW의 밀집 표현:\\n', bag_of_words.toarray())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOW의 밀집 표현:\n",
            " [[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
            " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtDnSGUUSVyz"
      },
      "source": [
        "각 단어의 출현 횟수는 0 또는 1입니다. 'bards_words'에 있는 두 문자열 모두 같은 단어를 두 개 이상 가지지 않습니다.\n",
        "\n",
        "이 특성 벡터를 읽는 법을 설명합니다. 첫 번째 문자열('The fool doth think he is wise,')은 첫 번째 행으로 나타납니다. 어휘 사전의 첫 번째 단어인 'be'와 두 번째 단어인 'but'은 0번만큼 나옵니다. 세 번째 단어인 'doth'는 1번만큼 나옵니다. 두 행을 보면 네 번째 단어인 'fool'과 열 번째 단어인 'the', 열 세번째 단어인 'wise'는 두 문자열에 모두 포함됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJNeyC0HVBI1"
      },
      "source": [
        "## **7.3.2 영화 리뷰에 대한 BOW**\n",
        "\n",
        "이제 실제 데이터셋을 이용하여 BOW를 설명합니다. 앞에서 IMDb 리뷰의 훈련 데이터와 테스트 데이터를 읽어서 작업할 문자열 리스트인 'text_train'과 'text_test'로 바꿨습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrEqkhccXpbZ",
        "outputId": "45f0c741-9322-4b72-c363-b3bfdd54f3a1"
      },
      "source": [
        "vect = CountVectorizer().fit(text_train)\n",
        "X_train = vect.transform(text_train)\n",
        "print('X_train:\\n', repr(X_train))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:\n",
            " <25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 3431196 stored elements in Compressed Sparse Row format>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmeAbjHPYHgg"
      },
      "source": [
        "훈련 데이터의 BOW 표현인 'X_train'의 크기는 $25,000 \\times 74,849$입니다. 어휘 사전은 단어를 74,849개만큼 가졌습니다. 데이터는 사이파이 희소 행렬 형태로 저장되어 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znukb1pUZPbf"
      },
      "source": [
        "어휘 사전을 더 살펴봅니다. `CountVectorizer` 클래스의 객체가 가진 `get_feature_name` 메서드는 각 특성에 해당하는 단어를 리스트로 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQJCuR_RZeLE",
        "outputId": "f3a855fa-ff76-4e42-bfa1-d9280300ceeb"
      },
      "source": [
        "feature_names = vect.get_feature_names()\n",
        "print('특성(단어) 개수:', len(feature_names))\n",
        "print()\n",
        "print('처음 20개 특성:\\n', feature_names[:20])\n",
        "print()\n",
        "print('20010~20030까지 특성:\\n', feature_names[20010:20030])\n",
        "print()\n",
        "print('매 2000번째 특성:\\n', feature_names[::2000])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "특성(단어) 개수: 74849\n",
            "\n",
            "처음 20개 특성:\n",
            " ['00', '000', '0000000000001', '00001', '00015', '000s', '001', '003830', '006', '007', '0079', '0080', '0083', '0093638', '00am', '00pm', '00s', '01', '01pm', '02']\n",
            "\n",
            "20010~20030까지 특성:\n",
            " ['dratted', 'draub', 'draught', 'draughts', 'draughtswoman', 'draw', 'drawback', 'drawbacks', 'drawer', 'drawers', 'drawing', 'drawings', 'drawl', 'drawled', 'drawling', 'drawn', 'draws', 'draza', 'dre', 'drea']\n",
            "\n",
            "매 2000번째 특성:\n",
            " ['00', 'aesir', 'aquarian', 'barking', 'blustering', 'bête', 'chicanery', 'condensing', 'cunning', 'detox', 'draper', 'enshrined', 'favorit', 'freezer', 'goldman', 'hasan', 'huitieme', 'intelligible', 'kantrowitz', 'lawful', 'maars', 'megalunged', 'mostey', 'norrland', 'padilla', 'pincher', 'promisingly', 'receptionist', 'rivals', 'schnaas', 'shunning', 'sparse', 'subset', 'temptations', 'treatises', 'unproven', 'walkman', 'xylophonist']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csLODysZaeBm"
      },
      "source": [
        "어휘 사전의 처음 20개 중에 15개는 숫자입니다. 이 숫자들은 모두 리뷰 어딘가에 나타났으므로 단어로 추출됐습니다. 영화 리뷰라는 걸 고려하면 (제임스 본드 역할을 의미하는 '007'을 제외하면) 숫자는 별다른 의미를 가지지 않습니다. 의미 없는 단어 중에서 의미 있는 단어를 선별하는 일은 결코 쉬운 일이 아닙니다.\n",
        "\n",
        "'dra'로 시작하는 영어 단어 목록을 살펴보면, 'draught', 'drawback', 'drawer' 모두 단수와 복수형이 서로 다른 단어로 어휘 사전에 포함되어 있습니다. 이런 류의 단어들은 의미가 매우 비슷하므로 다른 특성으로 간주해서 개별적으로 기록하는 것은 옳지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbhVvxdCbsMl"
      },
      "source": [
        "예시한 '007'을 살펴봅니다. 어휘 사전에서 10번째에 위치한 단어입니다. 이 위치에 대한 값이 1인 행을 찾아서 훈련 데이터를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciQunoe5b5bH",
        "outputId": "3f40df43-c9d9-46ab-996a-53969ecdcb69"
      },
      "source": [
        "[text_train[i] for i in np.argwhere(X_train[:, 9] == 1)[:, 0]]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'\"Dutch Schultz\", AKA Arthur Fleggenheimer, was a real person and his rather nasty life is fairly well documented. This movie which purports to depict his life should have used a fictional character, because the overdramatized events are too strong a departure from the facts and the chronology. Not only that, it ignores some interesting details which other versions have included such as the public relations fiasco in upstate N.Y. and his religious conversion. It is true that he was executed by Luciano, Lansky, et. al. but that\\'s as far as it goes. The exploding plate scene which represents Luciano carrying out the execution of Bo Weinberg in his own home, assisted by his own mother is rediculous. Also, there is the scene in which Dutch approaches his own mother to pay protection to Legs Diamond. It just doesn\\'t work. The character of Mrs. Fleggenheimer doesn\\'t work either. This movie does not need a doting Jewish mother for comic relief. The lame representation of Legs Diamond was humorous enough. I\\'m sure the man is turning in his grave. And, by the way, Dutch did in fact personally kill people, but, he was not Rambo or 007. The scene in which he wipes out the brewery is absurd. I don\\'t know. Maybe it was supposed to be a comedy and I just didn\\'t get it.',\n",
              " b'First off, this is an excellent series, though we have sort of a James Bond effect. What I mean is that while the new Casino Royale takes place in 2006, it is chronologically the first adventure of 007, Dr. No (1962) being the second, while in Golden Eye, the first film with Pierce Brosnan, Judi Dench is referred to as the new replacement for the male \"M\" so how could she have been in place in the beginning before Bond became a double-0, aside from the fact that she is obviously 14 years older? This is more or less a \"poetic\" license to thrill. We need to turn our heads aside a bit if we wish to be entertained. No, the new Star Trek movie does not have any of the primitive electronics of the original series from nearly half a century ago. In the 1960\\'s communicators were fantasy. (now we call them cell phones) and there were sliding levers instead of buttons. OMG, do you think 400 years from now, they would have perfected Rogaine for Jean-Luc Picard? So, please, let\\'s give the producers some leeway.  But to try and make things a bit consistent, let us just ponder about the Cylons creation just 60 years prior to the end of Battlestar Galactica. If that is the case, where did all the Cylons that populated the original earth come from? We know that the technology exists for spontaneous jumps through space. Well, what happened if one of the Cyclon ships at war with the Caprica fleet was fired upon or there was a sunspot or whatever and one ship, loaded with human-looking Cylons, wound up not only jumping through space, but through time, back a thousand or ten thousand years with a crippled ship near Earth One. They colonized it, found out they could repopulate it and eventually destroyed themselves, but not before they themselves sent out a \"ragtag\" fleet to search for the legendary Caprica, only to find a habitable but unpopulated planet, which they colonized to become the humans, who eventually invented the Cylons. Time paradox? Of course. Which came first, the chicken or the road? Who cares? It\\'s fraking entertaining!',\n",
              " b'This game is the bomb and this is the 007 game of the year and should be on greatest hits. When I got Agent Under Fire, I thought that was a good game but then Nightfire came around and that was better, but now there is a new type of James Bond game. This time it a 3rd person shooter and there is more than 12 missions, the graphics of the game are out of this house. It even has all of the great actors and actresses in this game like Pierce Bronsan as once again James Bond, William Dafoe as the villain Nikolai Diavolo, and Judi Dench as M (forgive me all if I spell it wrong). This game would be own as the greatest James Bond game around.  I give this a 10/10',\n",
              " b'Don\\'t get me wrong. \"GoldenEye\" was revolutionary and is definitely the best FPS game to be based on the 007 franchise. But the series had fallen into a FPS rut. Enter \"Everything or Nothing\", which puts Bond in third-person. When I wrote my earlier review for \"From Russia With Love\", I had finished FRWL and just started EON and judged EON a bit harshly. Even though FRWL definitely has the edge in nostalgia and capturing the essence of the movie franchise, EON definitely is superior in terms of in-depth controls and gameplay variety. Missions range from standard running-and-gunning to driving an SUV, driving an Aston Martin, driving a limousine that is wired to explode, commandeering two different types of tanks a la \"GoldenEye\", riding a motorcycle, flying a helicopter, repelling down a shaft guarded by laser tripwires, and free falling after a plummeting damsel. Sure, vehicle controls are a little clumsy, but the issue here is the variety.  As movie adaptations, \"GoldenEye\" and FRWL were all that I could have hoped for. But EON\\'s original storyline adds to the feeling of controlling a James Bond adventure. This is helped by the impressive cast list of Willem DeFoe, Shannon Elizabeth, Heidi Klum, and Misaki Ito. Judi Dench and John Cleese reprise their movie roles of M and Q, respectively, and Pierce Brosnan, while no Sean Connery, adds credibility to the game\\'s proceedings. All characters resemble the stars, with the disappointing exception of Heidi Klum, who\\'s in-game model doesn\\'t do the real-life model justice. Mya\\'s theme song is on par with at least some of the big screen Bond title tunes.  The game also plays tribute to some of the older Bond movies. Willem DeFoe\\'s character is a former colleague of Christopher Walken\\'s baddie from \"A View to a Kill\". Richard Kiel appears as Jaws, the hulking henchman from \"The Spy Who Loved Me\" and \"Moonraker\" in three fight scenes, the first and best of which proceeds in the same fashion a fight in the movies would have.  Single-player gameplay mainly consists of standard on-foot missions as Bond. Like Bond, you will be able to choose whether to use stealth or go out with guns blazing. The game provides plenty of opportunities to utilize stealth, with plenty of wall and object cover. Unfortunately, unlike FRWL, only one button in EON controls both crouching and wall clinging, so Bond may end up crouching low when he\\'s supposed to be peeking around a corner, and vice-versa. The game also allows players to go into \"Bond reflex\" mode. While you browse your inventory, everything around you will go into super slo-mo, allowing you to analyze objects around you that can be interacted with. While this takes some getting used to, eventually this mode will allow you to perform many spectacular \"Bond moments\", such as shooting down a chandelier to take out four goons underneath, and greatly add to the Bond movie feeling.  There are 3 available difficulty levels: Operative, Agent, and Double Oh. On Operative, you can breeze through in a few hours. On Agent, a few weeks. On Double Oh, a few months. The difficulty level can be changed for each individual mission. Garnering high scores on missions will unlock gold and platinum awards and effect features such as vehicle upgrades and the skimpy outfits the Bond girls wear. Some missions can be extremely frustrating due to a scarcity of checkpoints, but when all is said and done, no mission is any longer than a single action scene in a Bond movie.  Multi-player, unfortunately, is not as thrilling. \"GoldenEye\" still has the best multi-player mode of any Bond game. EON\\'s main multi-player is a co-op campaign mode that puts players in charge of lesser MI6 agents on a less important mission than Bond\\'s. A more standard third-person death match can be unlocked from this mode. But the single-player mode is the most complete Bond experience to date. The ending, as with most Bond games, is anticlimactic. While the final mission is one of the most aggravating of the game, the final confrontation with the villain is disappointing. Also, levels that require Bond to be speedy become largely a matter of trial and error. Still, for any serious Bond fan, not playing this game is tantamount to missing one of the Bond films.',\n",
              " b'What a moving film. I have a dear friend who is in her sixties and for the past 15 years has told me that people don\\'t see her anymore, and she longs for companionship. Being in my late 40s I am beginning to see what she has been complaining about. You are no longer youthful, beautiful or touchable. When May says \"...this lump of a body...\" wow. How our bodies change and how we are told it is no longer beautiful. I love when she begins to change what she wears...the colorful scarf...no longer the frumpy wife.  It is a sad and wonderful picture at the same time. Sad in that May betrays her daughter\\'s trust...beautiful in that she finds herself through the difficulty of the affair, and chooses to move on and finally have her own life. I love the character\\'s daring to even initiate the love affair.  Mostly I love the movie because finally it is a picture that shows the intricate nature of relationships, be they familial or not. We see Paula\\'s vulnerability, yet she will have what she wants at all costs...(when she tells her mum that she will have a baby for Darren whether he wants one or not after her mother asks if Darren even wants a child). The movie hits the mark on the how relationships can change, and yet reveals what has been there all along, dormant. May has stifled her own creativity to raise a family. A family that she didn\\'t really want, but was \"something you just did when she was young\". I love the scene when Darren calls her an old tart, and she smiles and says \"I was never called that before\". It was truly a gem of a movie.  And Daniel Craig. Well, i just love him. I was pleasantly surprised. Not only is he pleasant on the eyes, he is a real talent. What a neat role. He is much more than any 007 that is for sure and I look forward to seeing him in more roles of this nature. The scene where he is pleasuring May and the look he gives her is sort of a look of wonder that he has such control over this woman, and also one of pleasure of being able to give this to her. He is actually enjoying giving her pleasure. A wonderful scene. The contrast is the love scene with Bruce. Bruce is totally absorbed with his own pleasure...two completely different men.  Alas...I wonder where is my Darren?',\n",
              " b'Shannon Lee,the daughter of Bruce Lee,delivers high kicking martial arts action in spades in this exhilarating Hong Kong movie and proves that like her late brother Brandon she is a real chip off the old block. There is high tech stuntwork to die for in this fast paced flick and the makers of the Bond movies should give it a look if they want to spice up the action quotient of the next 007 adventure as there is much innovative stuff here with some fresh and original second unit work to bolster up the already high action content of \"AND NOW,YOU\\'RE DEAD\". When you watch a movie as fast paced and entertaining as this you begin to wonder how cinema itself was able to survive before the martial arts genre was created.I genuinely believe that movies in general and action movies in particular were just marking time until the first kung fu movies made their debut. Bruce Lee was the father of modern action cinema and his legitimate surviving offspring Shannon does not let the family name down here.Although there are several pleasing performances in this movie (Michel Wong for one)it is Shannon Lee whom you will remember for a genuinely spectacular performance as Mandy the hitgirl supreme.Hell;you may well come away whistling her fights!',\n",
              " b\"When I first got my N64 when I was five or six,I fell in love with it,and my first game was Super Mario 64.And I LOVED IT!The graphics were great for it's time,a good plot,great courses and above all,the best music I heard in a Nintendo game.  I don't remember the plot completely,but I think Princess Peach was kidnapped by Bowser,and Mario has to rescue her.The object of the game is to get 120 stars from the curses in the castle.Each had about five or six challnges to get the stars.There are secert parts of the castle,where you can get more stars.But of course,you have beat Bowser.*I think there are three levels to beat Bowser on* Lets start with the characters.Mario is the main character,and gets helpful advice from Toad,so he is basically one of your only alliances.I heard that Luigi and Yoshi are in the game towards the end.The main villain is Bowser,and there are a bunch of other characters like Boo and Goomba.The characters are really great.  Next,how about the graphics?People say Gameplay is more important then the graphics,and I agree completely.But with he great plot,there are great graphics.Especially for it's time.I have a whole bunch of other Nintendo games like 007 and their graphics don't compare to Super Mario.Bright colors,great effects and awesome sound effects.I found the graphics in the water courses very very good.Next to the Bowser world ones,it has the best graphics in the game.  Now,the music.This is my favorite part of the game.Growing up,when I played this at a young age,I'd gladly leave the game on all night so the music would put me to sleep.Especially the music from Jolly Roger Bay,which was peaceful and wonderful.There are others that are great too,especially in,once again,the worlds with Bowser,are the ones that stick with me the most and are my favorites.  This game was my favorite past time as a developing gamer,and I love it.This game gets 10/10 or *****(5)/*****(5) GO PLAY THE GAME!\",\n",
              " b\"I thought the film could be a bit more complex,in a psychological sense perhaps, but the action and voice acting were top notch. The animation was heavy CG in many scenes, but very good ones at that. This is one of the Batman Returns/Forever type films, which include romances and the conflicts of Wayne and motives for dating. 007 fans would love this, and so would the females, great theme song! Wayne was portrayed very well in this film, and the Penquin was back to his true form, no mutant genes in him this time! I liked the fact Robin wasn't used too much, Tim Drake was just a good computer nerd, somewhat of an Indigo child or mind of the future.  The supporting cast was made up of some soap opera stars, decent talents and the characters were drawn to look like the voice actors too. Kelly Ripa was hilarious in this film.  I rate this below Phantasm, Return of the Joker, and Batman vs. Dracula, but liked the smarter script better than I enjoyed Subzero. 7/10\",\n",
              " b'What\\'s to like about this movie???  It is in colour!   It has some impressive underwater photography!   It has a rhythmic musical score in the background that works well at times!   So 3 out of 10!   Sometimes the music is speeded up! Especially when the shark or the baddies are about to move in!   Sometimes it is slowed! As if to convey to the audience it\\'s about to be time for sympathy!   As another one bites the dust! As if in a \"spagetti Western\" this has much similarity to!   It\\'s not that the Italians can\\'t produce quality productions! There was a series of TV movies with a heading like \"Octopus\" numbered about 1 to 7, screened on SBS TV in Australia in the 1990s about mafia-type conflicts! And they were excellent! But alas, you won\\'t find it here!!!  I assumed it was made about 1960s! Sadly it was 20 years out of date, as evidenced by a funeral scene near the end!   Then there was the razor-sharp bite of the speedy shark that makes for a red dust repeatedly emerging in the bluish waters!   Amidst it all, either in bar-room brawl or in observing the latest sea-side bloody demolition by the relentlessly hungry shark, the mate of the hero looks on through his glasses of little concern, as if he too was bored in his relentless role amidst a lack of much evidence of plot or anyone\\'s character development!   At least the hero indicates a fleeting concern belatedly, for his ex-wife!   But of course, even if the music fails to awaken our realisation, we have the sinister sound in the baddies\\' voices, as if to nudge us that another dark deed is about to emerge!   And near the end, someone thought of a twist! Just when we thought it was all totally predictable! But stay tuned, folks, for you may find another twist! If you are watching closely! To, more or less, warm your heart!   Follow the advice of the hero, and have a few beers along the way! It\\'ll make your viewing of \"Night of the Sharks\" more enjoyable!   Then you\\'ll be ready for something like a \"007\" movie to ease your way back into reality when this is over!!!',\n",
              " b\"Dark comedy? Gallows humor? How does one make a comedy out of murder? It can be risky business as the viewer is required to let go of their moral values and laugh at the antics of a man who kills people. So, the story has be rock solid with a good dash of suspended reality in order to make it work. So, Pierce Brosnan, the Irishman's answer to 007 is now cast as a chain-smoking, sex-addicted alcoholic who kills people for a living and is having a life crisis. He meets a struggling businessman, Greg Kinnear, and after a rocky beginning, he learns that he needs a friend. But, Greg's happily married to Hope Davis and Brosnan sees in him the basic things he doesn't have, love, home and a life. Add character actor, Philip Baker Hall as the hit-man's manager and we're off to the races. Brosnan is wonderfully crass and crude as the anti-hero and Kinnear delightful as his counterpart, the very human businessman. Hope Davis adds a sparkle as Kinnear's very conventional wife who is fascinated with this derelict who drifts into their lives. The ending is delightful and with some surprise to it. You should leave the theater feeling, at least, partly good-- if you're able to suspend being aghast at killing people.\",\n",
              " b'While flipping through the channels on a late Saturday night, my friends and I stumbled across this film. First of all, Irish actor Pierce Brosnan as a Native American? Seriously?! His accent was breaking through so much, although his character was apparently Scottish. Next, I was stunned to find that this film was made after he had already played James Bond/Agent 007 at least twice. This movie plays up the stereotypes, with the inspiring professor figure. The girl who played Pony should be paid to keep her mouth shut. And, this film won an award? I cannot believe it. Brosnan is an attractive man, but we seriously wanted to gauge our eyes out after watching this for just 10 seconds. We switched from \"Kicking and Screaming\" to this, and we wanted to switch back. We watched the 1995 children\\'s classic \"The Indian in the Cupboard\" earlier in the night, which also discussed the Iroquois. The following line represents our desire to run away: \"Take me outside, earth grasper.\" From \"Grey Owl\": \"If you don\\'t like it, you don\\'t have to watch.\"']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3gcaolxg04q"
      },
      "source": [
        "특성 추출 방법을 개선하기 전에 분류기를 만들어서 성능 수치를 확인합니다. 'y_train'에 있는 훈련 레이블과 'X_train'에 있는 훈련 데이터의 BOW 표현으로 분류기를 학습합니다. 이런 희소 행렬의 고차원 데이터셋에서는 `LogisticRegression` 같은 선형 모델의 성능이 매우 뛰어납니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PQzVWe4lnCJ"
      },
      "source": [
        "교차 검증을 사용해서 `LogisticRegression` 모델의 성능을 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTudwoHghMO0",
        "outputId": "5617ca64-5d23-45b6-a066-9b50b65d63e8"
      },
      "source": [
        "# 다소 오래 걸리는 작업입니다.\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "scores = cross_val_score(LogisticRegression(max_iter=1000), X_train, y_train, cv=5)\n",
        "print('교차 검증 평균 점수: {:.2f}'.format(np.mean(scores)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "교차 검증 평균 점수: 0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs6f3UrjiWpR"
      },
      "source": [
        "교차 검증 평균 점수 88%는 균형 잡힌 데이터셋에서 꽤 좋은 이진 분류 성능입니다.\n",
        "\n",
        "서적에서 서술하기를 위 코드는 전처리와 교차 검증을 설명한 6장의 규칙을 어기고 있습니다. `CountVectorizer` 클래스의 기본 설정에서는 실제로 어떤 통계도 수집하지 않기 때문에 결과에 어떠한 영향도 주지 않습니다. 처음부터 `Pipeline`을 사용하면 더 좋지만 쉽게 설명하기 위해 뒤로 미뤘습니다. `CountVectorizer` 클래스의 `min_df`, `max_df` 같은 매개변수의 기본값을 조정하면 교차 검증 결과에 영향을 줍니다. `Pipeline`을 사용하는 편이 더 낫습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdbbt9pPimgu"
      },
      "source": [
        "`LogisticRegression` 클래스에는 규제 매개변수 `C`가 있습니다. 그리드 서치를 사용해서 조정을 시도합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO33VdIGixWu",
        "outputId": "77047b53-00f6-450a-9aca-789860574451"
      },
      "source": [
        "# 매우 오래 걸리는 작업입니다.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=5000), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "print('최상의 교차 검증 점수: {:.2f}'.format(grid.best_score_))\n",
        "print('최적 매개변수: ', grid.best_params_)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최상의 교차 검증 점수: 0.89\n",
            "최적 매개변수:  {'C': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijvrqCwjmfkM"
      },
      "source": [
        "이 매개변수를 사용해서 테스트 세트의 일반화 성능을 측정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ndqb3jDmj6e",
        "outputId": "5b8428fa-a21d-49aa-f7eb-37ef16eec4e7"
      },
      "source": [
        "X_test = vect.transform(text_test)\n",
        "print('테스트 점수: {:.2f}'.format(grid.score(X_test, y_test)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 점수: 0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlB-rVzrqEzN"
      },
      "source": [
        "이제 단어 추출 방법을 개선합니다. `CountVectorizer` 클래스는 정규표현식을 사용해서 토큰을 추출합니다. 기본적으로 사용하는 정규 표현식은 '\\b\\w\\w+\\b'입니다(정확하게는 '(?u)\\b\\w\\w+\\b'입니다. 파이썬3에서 '(?u)'는 불필요한 패턴이지만 하위 호환성을 위해 남겼습니다). 이 식으로 경계(\\b)가 구분되고, 적어도 둘 이상의 문자나 숫자(\\w)가 연속된 단어를 찾는 것입니다. 한 글자로 된 단어는 찾지 않고, 'doesn't' 같은 축약형이나 'bit.ly' 같은 단어는 분리되고, 'h8ter'는 한 단어로 매칭됩니다. `CountVectorizer` 클래스는 모든 단어를 소문자로 바꾸므로 'soon', 'Soon', 'SOon'은 모두 같은 특성(토큰)이 됩니다.\n",
        "\n",
        "이런 간단한 메커니즘은 실제로는 잘 작동하지만 숫자처럼 의미 없는 특성을 생성합니다. 이런 특성을 최대한 생성하지 않도록 하는 방법은 적어도 문서 두 개(또는 다섯 개 등)에 나타난 토큰만을 사용하는 것입니다. 문서 하나에서만 나타난 토큰은 테스트 세트에 나타날 가능성이 적으므로 큰 도움이 되지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMb6ELzlsHbl"
      },
      "source": [
        "`min_df` 매개변수에 토큰이 나타날 최소 문서 개수를 지정할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShPJmxzbsMvI",
        "outputId": "409737b4-8ced-4596-f53b-2b54cf2e515d"
      },
      "source": [
        "vect = CountVectorizer(min_df=5).fit(text_train)\n",
        "X_train = vect.transform(text_train)\n",
        "print('min_df를 지정하여 제한한 X_train:', repr(X_train))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_df를 지정하여 제한한 X_train: <25000x27271 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 3354014 stored elements in Compressed Sparse Row format>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgE9Anohsigh"
      },
      "source": [
        "적어도 토큰이 다섯 번 이상 나타나야 하므로 특성 수가 1/3 정도인 27,271개로 감소했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NSBOWsqssmI"
      },
      "source": [
        "토큰 내용을 다시 살핍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf-h3cORsuXS",
        "outputId": "9f668029-cf95-4295-a9fd-9954c00841f6"
      },
      "source": [
        "feature_names = vect.get_feature_names()\n",
        "print('처음 특성 50개:\\n', feature_names[:50])\n",
        "print()\n",
        "print('20,010~20,030까지 특성:\\n', feature_names[20010:20030])\n",
        "print()\n",
        "print('매 700번째 특성:\\n', feature_names[::700])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "처음 특성 50개:\n",
            " ['00', '000', '007', '00s', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '100', '1000', '100th', '101', '102', '103', '104', '105', '107', '108', '10s', '10th', '11', '110', '112', '116', '117', '11th', '12', '120', '12th', '13', '135', '13th', '14', '140', '14th', '15', '150', '15th', '16', '160', '1600', '16mm', '16s', '16th']\n",
            "\n",
            "20,010~20,030까지 특성:\n",
            " ['repentance', 'repercussions', 'repertoire', 'repetition', 'repetitions', 'repetitious', 'repetitive', 'rephrase', 'replace', 'replaced', 'replacement', 'replaces', 'replacing', 'replay', 'replayable', 'replayed', 'replaying', 'replays', 'replete', 'replica']\n",
            "\n",
            "매 700번째 특성:\n",
            " ['00', 'affections', 'appropriately', 'barbra', 'blurbs', 'butchered', 'cheese', 'commitment', 'courts', 'deconstructed', 'disgraceful', 'dvds', 'eschews', 'fell', 'freezer', 'goriest', 'hauser', 'hungary', 'insinuate', 'juggle', 'leering', 'maelstrom', 'messiah', 'music', 'occasional', 'parking', 'pleasantville', 'pronunciation', 'recipient', 'reviews', 'sas', 'shea', 'sneers', 'steiger', 'swastika', 'thrusting', 'tvs', 'vampyre', 'westerns']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxWK0ss8tW-r"
      },
      "source": [
        "숫자 길이가 줄고 희귀한 단어와 철자가 틀린 단어들이 제거됐습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0oKW-O8tguP"
      },
      "source": [
        "그리드 서치를 통해 모델 성능을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63TR-HxVtlbR",
        "outputId": "cefbc7f7-3c33-43a7-d1fb-aa6ec3613a98"
      },
      "source": [
        "# 매우 오래 걸리는 작업입니다.\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=5000), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "print('최적의 교차 검증 점수: {:.2f}'.format(grid.best_score_))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 교차 검증 점수: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytD_clvpt8q0"
      },
      "source": [
        "교차 검증 점수는 변하지 않았습니다. 다만 불필요한 특성의 개수가 줄면서 처리 속도가 빨라지고 모델을 이해하기 쉬워졌습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_wl5LdGxyy6"
      },
      "source": [
        "참고로 훈련 데이터에 없던 단어(이하 '해당 단어')가 포함된 문서에 `CountVectorizer` 클래스의 `transform` 메서드를 적용하면 어휘 사전에 해당 단어가 없으므로 해당 단어를 무시합니다. 훈련 데이터에 없는 단어에 대해 학습하는 것은 불가능한 일입니다. 보통 분류 작업에서 문제가 되지는 않지만 스팸 감지와 같은 애플리케이션에서는 어휘 사전에 없는 단어가 문서에 얼마나 많이 나타나는지 기록한 특성은 유용하기도 합니다. 사이킷런에는 없는 기능이지만 직접 작성하기에 어렵지는 않습니다. 적절한 방식을 사용해서 어휘를 제한하지 않으면 훈련하는 동안 어휘 사전에 없는 단어는 생기지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPKGMqcGVBGO"
      },
      "source": [
        "# **7.4 불용어**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA5fcbqZVBDs"
      },
      "source": [
        "# **7.5 tf-idf로 데이터 스케일 변경하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbHWlHYNVBBS"
      },
      "source": [
        "# **7.6 모델 계수 조사**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cqMHHXGVA--"
      },
      "source": [
        "# **7.7 여러 단어로 만든 BOW(n-그램)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqpW38u6VA8b"
      },
      "source": [
        "# **7.8 고급 토큰화, 어간 추출, 표제어 추출**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTJCN-oyVA6I"
      },
      "source": [
        "## **7.8.1 KoNLPy를 사용한 영화 리뷰 분석**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsSIeHvZVA4B"
      },
      "source": [
        "# **7.9 토픽 모델링과 문서 군집화**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc6o9PMTVA1k"
      },
      "source": [
        "## **7.9.1 LDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALSkNuLWVAzA"
      },
      "source": [
        "# **7.10 요약 및 정리**"
      ]
    }
  ]
}