{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHAPTER7 텍스트 데이터 다루기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMSRfzkYWT9LGBjFWEwXGLN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Machine-learning_Theory/blob/master/CHAPTER7%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%8B%A4%EB%A3%A8%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaMOLd5s0rqO"
      },
      "source": [
        "# 들어가며\n",
        "\n",
        "4장에서 데이터의 속성을 나타내는 두 가지 특성에 대해 다뤘습니다. 정량적인 연속형 특성, 고정된 목록에서 값이 정해지는 범주형 특성입니다. 이번 챕터에서는 많은 애플리케이션에서 사용하는 세 번째 유형의 데이터인 텍스트를 다룹니다. 예컨대 스팸 메일 분류의 경우에는 이메일 내용에 이 분류 작업에 필요한 중요한 정보가 들어 있습니다. 정치인의 의견을 분석하는 경우에는 언행이나 트윗이 중요한 정보를 가집니다. 고객 서비스의 경우에는 고객 메시지에 목적을 구분할 수 있는 정보가 있습니다. 메시지의 제목과 내용을 토대로 의도를 파악해서 해당 부서로 전달하거나 자동 응답으로 전환할 수 있습니다.\n",
        "\n",
        "텍스트 데이터는 주로 글자가 연결된 문자열로 표현됩니다. 길이가 서로 같은 경우는 거의 없습니다. 현재까지 살폈던 수치형 특성과 매우 상이하므로 전처리는 필수입니다. 내용의 길이가 다르므로 전처리 과정이 없으면 샘플마다 특성 수가 달라집니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFMw8a9uVBSP"
      },
      "source": [
        "# **7.1 문자열 데이터 종류**\n",
        "\n",
        "텍스트는 보통 문자열이지만 모든 문자열 특성을 텍스트로 다루는 것은 아닙니다. 문자열 특성은 범주형 변수로 표현할 수도 있습니다. 문자열 특성을 다루는 방법에 대해 인지하려면 데이터를 직접 살피는 수밖에 없습니다. 문자열 데이터 종류는 아래 4종류입니다.\n",
        "\n",
        "- **범주형 데이터**: 고정된 목록입니다. 예컨대 사람들에게 가장 좋아하는 색을 묻는 설문의 형태로 데이터를 수집하고자 한다면, 드롭다운(drop-down) 메뉴에서 'red', 'green', 'blue', 'yellow', 'black', 'white', 'puple', 'pink' 중 하나를 선택해야 합니다. 이 경우에 데이터셋에 색상 8개 중에 하나가 들어가고 범주형 변수로 인코딩 됩니다. 값들이 얼마나 자주 나타나는지 히스토그램을 그려볼 수 있습니다. 설문이 절반 정도 진행된 상태에서 설문자가 'black'을 'blacl'이라고 오타를 발견하여 수정했다면, 이 데이터셋에는 같은 의미를 나타내는 두 텍스트가 모두 들어있으므로 하나로 합쳐야 합니다.\n",
        "\n",
        "- **범주에 의미를 연결할 수 있는 임의의** 문자열: 드롭다운 메뉴 대신 텍스트 필드(test field)를 제공했다고 가정한다면, 설문자 대부분은 대체적으로 사용되는 표현을 사용하지만 몇몇 설문자는 '회색', '쥐색', '암청색'처럼 다른 표현을 사용할 수 있습니다. 이외 저 특이하게 색을 표현할지도 모릅니다. 이렇게 텍스트 필드로 받는 응답을 인코딩하려면 가장 보편적인 값을 선택하거나, 애플리케이션에 적합하도록 모든 응답을 포용할 수 있는 범주를 적절하게 정의해야 합니다. '여러 가지 색'이라는 범주를 만들어서 할당하거나, 인코딩이 불가능한 값은 '그 외'로 할당합니다. 이런 전처리는 수많은 수작업이 필요하고 자동화가 어렵습니다. 가능한 한 범주형 변수로 받는 것이 현명합니다.\n",
        "\n",
        "- **구조화된 문자열 데이터**: 정의된 범주에 속하진 않지만 직접 입력한 값들이 주소나 장소, 사람 이름, 날짜, 전화번호, 식별번호처럼 일정하게 구조화된 문자열 데이터 형식을 취할 수 있습니다. 이런 종류의 문자열은 분석하기 난해하고, 처리 방법이 문맥과 분야에 따라 매우 다릅니다. \n",
        "\n",
        "- **텍스트 데이터**: 자유로운 형태의 절과 문장으로 구성된 형태는 텍스트 데이터입니다. 트위터, 채팅, 리뷰, 소설 작품, 인터넷 문서 등 이런 종류를 통칭합니다. 대부분 단어로 구성된 문장에 정보를 담습니다. 텍스트 분석에서는 데이터셋을 말뭉치(corpus), 텍스트 하나를 의미하는 각 샘플은 문서(document)라고 합니다. 정보 검색(IR, information retrieval)과 자연어 처리(NLP, natural language processing) 공동체에서 유래한 표현들입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qViaTCdHVBP0"
      },
      "source": [
        "# **7.2 예제 애플리케이션: 영화 리뷰 감성 분석**\n",
        "\n",
        "지금부터 사용한 [데이터셋](http://ai.stanford.edu/~amaas/data/sentiment)의 출처는 스탠퍼드 대학교 연구원인 앤드루 마스가 IMDb라는 웹사이트입니다. 이 데이터셋은 리뷰 텍스트와 '양성' 혹은 '음성'을 나타내는 레이블을 포함합니다. 양성은 긍정적인 반응, 음성은 부정적인 반응입니다. 이런 형식은 데이터를 적절하게 표현한 게 아닐 수 있지만 그대로 사용하기로 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBXuR61jpde7"
      },
      "source": [
        "macOS나 리눅스를 사용한다면 아래 명령어로 데이터를 다운로드하고 압축을 해제합니다. 물론 코랩도 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uduD93Bpi_3",
        "outputId": "92d714e6-aeb6-4206-87f7-5558a259ab9d"
      },
      "source": [
        "# '!' 기호는 실행한다는 의미입니다.\n",
        "!wget -nc http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -P data\n",
        "!tar xzf data/aclImdb_v1.tar.gz --skip-old-files -C data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-14 13:00:18--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘data/aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  27.8MB/s    in 2.9s    \n",
            "\n",
            "2021-09-14 13:00:21 (27.8 MB/s) - ‘data/aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B7kqzPFqasv"
      },
      "source": [
        "압축을 해제하면 두 폴더에 텍스트 파일이 들어 있습니다. 하나는 훈련 데이터, 다른 하나는 테스트 데이터입니다. 이 두 폴더는 다시 pos와 neg 하위 폴더를 포함합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNuAg-HeqbAw",
        "outputId": "9d5f976c-dfa6-4529-90ea-332786e60c47"
      },
      "source": [
        "# !은 셸(shell) 명령을 실행하는 IPython의 매직 명령어입니다.\n",
        "# tree 명령이 없다면 find ./data -type d 명령을 사용해서\n",
        "# 하위 폴더의 목록을 볼 수 있습니다.\n",
        "!tree -dL 2 data/aclImdb # 이 명령은 유효하지 않습니다.\n",
        "!find ./data -type d # 유효한 명령입니다."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: tree: command not found\n",
            "./data\n",
            "./data/aclImdb\n",
            "./data/aclImdb/test\n",
            "./data/aclImdb/test/neg\n",
            "./data/aclImdb/test/pos\n",
            "./data/aclImdb/train\n",
            "./data/aclImdb/train/unsup\n",
            "./data/aclImdb/train/neg\n",
            "./data/aclImdb/train/pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gyYrl1dv3pO"
      },
      "source": [
        "pos 폴더에는 긍정적인 리뷰가 각각 파일 하나로 나뉘어 있고 neg 폴더도 마찬가지입니다. unsup 폴더에는 레이블이 없는 데이터가 있습니다. 이 폴더는 사용하지 않으므로 삭제합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-ZvKQfivWhp"
      },
      "source": [
        "!rm -r data/aclImdb/train/unsup"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T6SwLi9wIqo"
      },
      "source": [
        "하위 폴더가 레이블로 구분된 폴더 구조라면 `load_files` 함수를 사용하여 파일을 읽습니다. 이 함수를 사용하여 폴더를 읽을 때 레이블은 폴더의 알파벳순에 따라 0부터 부여됩니다. 여기서는 neg 폴더의 데이터는 레이블이 0이 되고, pos 폴더의 데이터는 레이블이 1이 됩니다. 먼저 훈련 데이터를 이 함수로 읽습니다. 참고로 지금까지는 데이터셋을 `train_test_split` 함수를 통해 훈련 세트와 테스트 세트로 나눠서 사용했으나 지금 사용할 데이터셋은 이미 두 세트로 나눠져 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvnXgLwjw0YL",
        "outputId": "3e7f3048-433c-4f42-d345-6a1f8c5f2d64"
      },
      "source": [
        "from sklearn.datasets import load_files\n",
        "\n",
        "reviews_train = load_files('data/aclImdb/train/')\n",
        "# 텍스트와 레이블을 포함하고 있는 Bunch 오브젝트를 반환합니다.\n",
        "text_train, y_train = reviews_train.data, reviews_train.target\n",
        "print('text_train의 타입:', type(text_train))\n",
        "print('text_train의 길이:', len(text_train))\n",
        "print('text_train[6]:\\n', text_train[6])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_train의 타입: <class 'list'>\n",
            "text_train의 길이: 25000\n",
            "text_train[6]:\n",
            " b\"This movie has a special way of telling the story, at first i found it rather odd as it jumped through time and I had no idea whats happening.<br /><br />Anyway the story line was although simple, but still very real and touching. You met someone the first time, you fell in love completely, but broke up at last and promoted a deadly agony. Who hasn't go through this? but we will never forget this kind of pain in our life. <br /><br />I would say i am rather touched as two actor has shown great performance in showing the love between the characters. I just wish that the story could be a happy ending.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA5Oi-ixZAsQ"
      },
      "source": [
        "결과를 보면 길이는 25,000(리뷰 개수)이며 각 항목은 리뷰 한 개에 대한 문자열입니다. 리뷰는 HTML 줄바꿈 태그(`<br />`)를 포함합니다. 줄바꿈 태그가 머신러닝 모델에 큰 영향을 미치진 않지만 미리 태그를 삭제해서 데이터를 정리하면 좋습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ano8xWMaaFO7"
      },
      "source": [
        "text_train = [doc.replace(b'<br />', b' ') for doc in text_train]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BWfN4f8ahNR"
      },
      "source": [
        "'text_train'의 항목 타입은 파이썬 버전에 따라 상이합니다. 파이썬 3에서는 문자열 데이터의 바이너리 인코딩인 bytes 타입입니다. 파이썬 2에서는 문자열입니다. 자세히 다루지 않고 넘어갑니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO7STDl3a8HO"
      },
      "source": [
        "이 데이터셋은 양성 클래스와 음성 클래스를 같은 비율로 수집했으므로 양성과 음성 레이블의 수가 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAOk_T7Ncg_J",
        "outputId": "89fef880-f671-49bd-e89c-dbbc67c2dd6a"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print('클래스별 샘플 수 (훈련 데이터):', np.bincount(y_train))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스별 샘플 수 (훈련 데이터): [12500 12500]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBqhfUJ8cwB_"
      },
      "source": [
        "같은 방식으로 테스트 데이터셋을 읽습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iulKjHnbc0Jb",
        "outputId": "650ffa3b-497c-4c7d-90ad-74effd65b54e"
      },
      "source": [
        "reviews_test = load_files('data/aclImdb/test/')\n",
        "text_test, y_test = reviews_test.data, reviews_test.target\n",
        "print('테스트 데이터의 문서 수:', len(text_test))\n",
        "print('클래스별 샘플 수 (테스트 데이터):', np.bincount(y_test))\n",
        "text_test = [doc.replace(b'<br />', b' ') for doc in text_test]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터의 문서 수: 25000\n",
            "클래스별 샘플 수 (테스트 데이터): [12500 12500]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMRznID6dfjK"
      },
      "source": [
        "우리는 리뷰가 하나 주어졌을 때 이 리뷰의 텍스트 내용을 보고 양성과 음성을 구분해야 합니다. 전형적인 이진 분류 문제인 것입니다. 그러나 텍스트 데이터는 머신러닝 모델이 다룰 수 있는 형태가 아닙니다. 텍스트의 문자열 표현을 머신러닝 알고리즘에 적용할 수 있게 수치 표현으로 바꿔야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qau0Slz4VBNV"
      },
      "source": [
        "# **7.3 텍스트 데이터를 BOW로 표현하기**\n",
        "\n",
        "머신러닝에서 텍스트를 표현하는 방법 중 **BOW(bag of words)**는 가장 간단하면서 효과적이고 널리 쓰이는 방법입니다. 이 방법을 통해 장, 문단, 문장, 서식과 같은 입력 텍스트의 구조 대부분을 잃고, 각 단어가 이 말뭉치에 있는 텍스트에 얼마나 많이 나타나는지만 헤아립니다. 구조와 상관없이 단어의 출현 횟수만 세므로 텍스트를 담는 가방(bag)으로 여길 수 있습니다. \n",
        "\n",
        "전체 말뭉치에 대해 BOW 표현을 계산하려면 다음 세 단계를 거칩니다.\n",
        "\n",
        "1. 토큰화(tokenization): 각 문서를 문서에 포함된 단어(토큰)로 나눕니다. 예를 들면 공백이나 구두점 등을 기준으로 분리합니다.\n",
        "\n",
        "1. 어휘 사전 구축: 모든 문서에 나타난 모든 단어의 어휘를 모으고 번호를 매깁니다. 알파벳 순서로 구성됩니다.\n",
        "\n",
        "1. 인코딩: 어휘 사전의 단어가 문서마다 몇 번이나 나타나는지 헤아립니다.\n",
        "\n",
        "1단계와 2단계에 관련한 세부 사항은 이 챕터의 뒷부분에서 상세하게 설명합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_AMi11MgrHk"
      },
      "source": [
        "BOW 표현을 만드는 방법을 설명하겠습니다.\n",
        "\n",
        "'This is how you get ants.' 라는 문자열을 처리하는 과정입니다.\n",
        "\n",
        "1. 토큰화: ['this', 'is', 'how', 'you', 'get', 'ants']\n",
        "\n",
        "1. 어휘 사전 구축: ['aardvark', 'amsterdam', 'ants', ... 'you', 'your', 'zyxst']\n",
        "\n",
        "1. 희소 행렬 인코딩: aardvark, ..., ants, ..., get, ..., you, ..., zyxst [0, ..., 0, 1, 0, ...., 0, 1, 0, ..., 0, 1, 0, ..., 0]\n",
        "\n",
        "출력은 각 문서에서 나타난 단어의 횟수가 담긴 벡터 하나입니다. 이를 위해 사전에 있는 각 단어가 문서마다 얼마나 자주 나타나는지 세야 합니다. 이 수치 표현은 전체 데이터셋에서 고유한 각 단어를 특성으로 가집니다. 원본 문자열에 있는 단어순은 BOW 특성 표현에서는 완전하게 무시됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s-r1xE3VBLA"
      },
      "source": [
        "## **7.3.1 샘플 데이터에 BOW 적용하기**\n",
        "\n",
        "휴식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJNeyC0HVBI1"
      },
      "source": [
        "## **7.3.2 영화 리뷰에 대한 BOW**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPKGMqcGVBGO"
      },
      "source": [
        "# **7.4 불용어**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA5fcbqZVBDs"
      },
      "source": [
        "# **7.5 tf-idf로 데이터 스케일 변경하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbHWlHYNVBBS"
      },
      "source": [
        "# **7.6 모델 계수 조사**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cqMHHXGVA--"
      },
      "source": [
        "# **7.7 여러 단어로 만든 BOW(n-그램)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqpW38u6VA8b"
      },
      "source": [
        "# **7.8 고급 토큰화, 어간 추출, 표제어 추출**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTJCN-oyVA6I"
      },
      "source": [
        "## **7.8.1 KoNLPy를 사용한 영화 리뷰 분석**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsSIeHvZVA4B"
      },
      "source": [
        "# **7.9 토픽 모델링과 문서 군집화**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc6o9PMTVA1k"
      },
      "source": [
        "## **7.9.1 LDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALSkNuLWVAzA"
      },
      "source": [
        "# **7.10 요약 및 정리**"
      ]
    }
  ]
}