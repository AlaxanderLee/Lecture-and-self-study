{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHAPTER3 평가.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNx+8b5kKyQx2EMA6nSL3B7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Machine-learning_Theory/blob/master/CHAPTER3%20%ED%8F%89%EA%B0%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **들어가며**"
      ],
      "metadata": {
        "id": "fpZeqHxHYdTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 예측 성능을 평가하는 성능 평가 지표는 분류와 회귀에 따라 여러 종류가 있습니다. 이번 챕터에서는 분류 위주의 성능 평가 지표를 살펴보고 5장에서 회귀를 위한 성능 평가 지표를 살펴보겠습니다.\n",
        "\n",
        "분류의 평가 방법은 일반적으로 실제 결과 데이터와 예측 결과 데이터가 얼마나 정확하고 오류가 적게 발생하는가에 기반합니다. 다만 이렇게 정확도만을 기반으로 판단하면 잘못된 평가 결과를 얻을 수 있습니다. 특히 0이나 1로 결정값이 한정되는 이진 분류의 성능 평가 지표는 정확도가 아닌 다른 성능 평가 지표가 더 유효한 경우가 많습니다. "
      ],
      "metadata": {
        "id": "lznuFJDk3cww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. 정확도(Accuracy)**"
      ],
      "metadata": {
        "id": "gPxbVrwQYdQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "정확도는 실제 데이터에서 예측 데이터가 얼마나 같은지 판단하는 지표입니다. 정확도를 구하는 공식은 아래와 같습니다.\n",
        "\n",
        "$$ 정확도(Accuracy) = \\frac{예측 결과가 동일한 데이터 건수}{전체 예측 데이터 건수}$$\n",
        "\n",
        "이진 분류의 경우 데이터 구성에 따라 모델 성능을 왜곡할 수 있기 때문에 정확도만을 기반으로 성능을 평가하지 않습니다. 정확도 지표가 모델 성능을 어떻게 왜곡하는지 살펴보겠습니다.\n",
        "\n",
        "전 챕터에서 타이타닉 데이터셋으로 예측했을 때 예측 정확도는 80%대였습니다. 그러나 남자보다 여자가 생존 확률이 높았기 때문에 별다른 알고리즘을 적용하지 않아도 비슷한 수치가 나올 수 있습니다. 여자는 무조건 생존으로 예측하고 남자는 무조건 사망으로 예측해도 높은 정확도를 나타낼 것입니다.\n",
        "\n",
        "`BaseEstimator` 클래스를 상속받아 아무 학습을 수행하지 않고 성별에 따라 생존자를 예측하는 단순한 분류기를 생성하겠습니다. `BaseEstimator` 클래스를 상속받으면 Customized 형태의 Estimator를 만들 수 있습니다. 생성할 `MyDummyClassifier` 클래스는 `fit()` 메서드는 아무것도 수행하지 않으며 `predict()` 메서드는 'Sex' 피처가 1이면 0, 그렇지 않으면 1로 예측하는 단순한 분류기입니다."
      ],
      "metadata": {
        "id": "YwoZjfVMI7O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class MyDummyClassifier(BaseEstimator):\n",
        "    def fit(self, X, y=None):\n",
        "        pass\n",
        "    def predict(self, X):\n",
        "        pred = np.zeros((X.shape[0], 1))\n",
        "        for i in range(X.shape[0]):\n",
        "            if X['Sex'].iloc[i] == 1:\n",
        "                pred[i] = 0\n",
        "            else:\n",
        "                pred[i] = 1\n",
        "        return pred"
      ],
      "metadata": {
        "id": "deR7EXuBvjvZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전 챕터에서 생성한 함수를 다시 선언하겠습니다."
      ],
      "metadata": {
        "id": "_5cJKEXhKtiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 결측치를 처리하는 함수를 선언합니다.\n",
        "def fillna(df):\n",
        "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "    df['Cabin'].fillna('N', inplace=True)\n",
        "    df['Embarked'].fillna('N', inplace=True)\n",
        "    df['Fare'].fillna(0, inplace=True)\n",
        "    return df\n",
        "\n",
        "# 데이터 분석에 불필요한 피처를 제거하는 함수를 선언합니다.\n",
        "def drop_features(df):\n",
        "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "# 레이블 인코딩을 수행하는 함수를 선언합니다.\n",
        "def format_features(df):\n",
        "    df['Cabin'] = df['Cabin'].str[:1]\n",
        "    features = ['Sex', 'Cabin', 'Embarked']\n",
        "    for feature in features:\n",
        "        le = LabelEncoder()\n",
        "        le = le.fit(df[feature])\n",
        "        df[feature] = le.transform(df[feature])\n",
        "    return df\n",
        "\n",
        "# 전처리를 위해 생성한 모든 함수를 호출하는 함수를 선언합니다.\n",
        "def transform_features(df):\n",
        "    df = fillna(df)\n",
        "    df = drop_features(df)\n",
        "    df = format_features(df)\n",
        "    return df"
      ],
      "metadata": {
        "id": "c4Ec-nBKKChF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`MyDummyClassifier` 분류기로 생존자를 예측하겠습니다."
      ],
      "metadata": {
        "id": "t3UxR7ajKxlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "titanic_df = pd.read_csv('/content/gdrive/MyDrive/titanic/titanic_train.csv')\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
        "X_titanic_df = transform_features(X_titanic_df)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)\n",
        "\n",
        "myclf = MyDummyClassifier()\n",
        "myclf.fit(X_train, y_train)\n",
        "\n",
        "mypredictions = myclf.predict(X_test)\n",
        "print('Dummy Clssifier의 정확도는: {:.4f}'.format(accuracy_score(y_test, mypredictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_f-1nGwHQgE",
        "outputId": "671efb86-88af-43cb-aabd-82760cf79f86"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n",
            "Dummy Clssifier의 정확도는: 0.7877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 구성이 편중되어 있으므로 단순한 알고리즘을 적용해도 높은 정확도가 도출됩니다. 데이터 100개 중에 레이블 0인 데이터가 90개, 레이블 1인 데이터가 10개라면 무조건 0으로 예측하게 했을 때 정확도는 90%가 됩니다.\n",
        "\n",
        "MNIST 데이터 세트를 변환하여 불균형한 데이터 세트로 만들고, 정확도 지표를 적용했을 때 발생하는 문제를 확인해보겠습니다. 0 ~ 9 숫자 이미지의 픽셀 정보를 가지고 있고, 이를 기반으로 숫자 Digit를 예측하는 데 사용됩니다. 원래 이 데이터 세트는 레이블 값이 0 ~ 9까지 있는 멀티 레이블 분류를 위한 것이지만 이진 분류 문제로 바꿔 보겠습니다. 레이블 7이면 True이고 나머지는 False로 바꾸겠습니다. 10%만 True입니다.\n",
        "\n",
        "불균형한 데이터 세트와 Dummy Classifier를 생성하겠습니다."
      ],
      "metadata": {
        "id": "fjcUbykiLO3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "class MyFakeClassifier(BaseEstimator):\n",
        "    def fit(self, X, y):\n",
        "        pass\n",
        "\n",
        "    # X 데이터 세트의 크기만큼 모두 0값으로 만듭니다.\n",
        "    def predict(self, X):\n",
        "        return np.zeros((len(X), 1), dtype=bool)\n",
        "    \n",
        "digits = load_digits()\n",
        "\n",
        "# 7이면 `True`이고 `astype(int)`로 1로 변환하고,\n",
        "# 7이 아니면 `False`이고 0으로 변환합니다.\n",
        "y = (digits.target == 7).astype(int)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    digits.data, y, random_state=11)"
      ],
      "metadata": {
        "id": "7WKQslspYJI8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성한 분류기로 정확도를 측정해보겠습니다."
      ],
      "metadata": {
        "id": "TZOcAUYELVE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('레이블 테스트 세트 크기:', y_test.shape)\n",
        "print('테스트 세트 레이블 0과 1의 분포도')\n",
        "print(pd.Series(y_test).value_counts())\n",
        "\n",
        "fakeclf = MyFakeClassifier()\n",
        "fakeclf.fit(X_train, y_train)\n",
        "fakepred = fakeclf.predict(X_test)\n",
        "print('모든 예측을 0으로 해도 정확도는 {:.3f}'.format(accuracy_score(y_test, fakepred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qapvaxLPbc6d",
        "outputId": "1672464f-1f0d-491e-b08d-88e790513250"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "레이블 테스트 세트 크기: (450,)\n",
            "테스트 세트 레이블 0과 1의 분포도\n",
            "0    405\n",
            "1     45\n",
            "dtype: int64\n",
            "모든 예측을 0으로 해도 정확도는 0.900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이처럼 불균형한 레이블로 구성된 데이터 세트의 경우 성능 측정을 위해 정확도 평가 지표를 사용하는 것은 적절하지 않습니다."
      ],
      "metadata": {
        "id": "gLhQn95aGrj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. 오차 행렬**"
      ],
      "metadata": {
        "id": "6NLMfL89YdOK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이진 분류에서 성능 지표로 활용되는 오차행렬(confusion matrix, 혼동행렬)은 예측 오류의 정도와 예측 오류 유형을 나타내는 지표입니다. "
      ],
      "metadata": {
        "id": "Q2TPgOo2BMZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "휴식 중\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3FOjsS4MLIdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. 정밀도와 재현율**"
      ],
      "metadata": {
        "id": "YxD3R51fYdLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1. 정밀도/재현율 트레이드오프**"
      ],
      "metadata": {
        "id": "JenR9t3VYdI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2. 정밀도와 재현율의 맹점**"
      ],
      "metadata": {
        "id": "Or6OA-dwYdGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2.1. 정밀도가 100%가 되는 방법**"
      ],
      "metadata": {
        "id": "ZLEsf4HuYdD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2.2. 재현율이 100%가 되는 방법**"
      ],
      "metadata": {
        "id": "v_RDgc1wYdBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. F1 스코어**"
      ],
      "metadata": {
        "id": "YqAaCD9kYc-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. ROC 곡선과 AUC**"
      ],
      "metadata": {
        "id": "1MJCOAZnZAVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. 파마 인디언 당뇨병 예측**"
      ],
      "metadata": {
        "id": "LZdQFoGzZATJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. 정리**"
      ],
      "metadata": {
        "id": "zS098Ck9ZAQk"
      }
    }
  ]
}