{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHAPTER4 분류.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsXrt3Z/omDUTSp1k2QrBm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Machine-learning_Theory/blob/master/CHAPTER4%20%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. 분류(classification)의 개요**"
      ],
      "metadata": {
        "id": "L6blTcamZ7UE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앙상블을 주로 다루는 챕터입니다. 앙상블은 정형 데이터의 예측 분석 영역에서 매우 좋은 예측 성능을 발휘합니다. 대부분 동일한 알고리즘을 결합하며, 기본 알고리즘으로 사용하는 것은 결정 트리입니다."
      ],
      "metadata": {
        "id": "jl5ih4rHGMpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. 결정 트리**"
      ],
      "metadata": {
        "id": "8LuLY558Z7Rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "결정 노드는 정보 균일도가 높은 데이터 세트를 먼저 선택할 수 있도록 규칙 조건을 만듭니다. 정보 균일도가 데이터 세트로 쪼개질 수 있도록 조건을 찾아 서브 데이터 세트를 만들고, 다시 이 서브 데이터 세트에서 균일도가 높은 자식 데이터 세트를 쪼개는 방식을 자식 트리로 내려가면서 반복하는 방식으로 데이터 값을 예측합니다. 쉽게 예측할 수 있는 조건을 찾아서 분류하는 것이 가장 효율적이기 때문입니다.\n",
        "\n",
        "이러한 정보 균일도를 측정하는 대표적 방법은 엔트로피를 이용한 **정보 이득(Information Gain)**과 지니계수입니다.\n",
        "\n",
        "정보 이득은 **엔트로피(주어진 데이터 집합의 혼잡도)**를 기반으로 합니다. 정보 이득 지수는 1에서 엔트로피 지수를 뺀 값입니다. 서로 다른 값이 섞여 있으면 엔트로피가 높고, 같은 값이 섞여 있으면 엔트로피가 낮습니다. \n",
        "\n",
        "지니 계수는 경제학에서 불평등 지수를 나타내는 데 쓰이는 지수입니다. 머신러닝에서는 지니 계수가 낮을수록 데이터 균일도가 높은 것으로 해석하여 지니 계수가 낮은 속성을 기준으로 분할합니다. 다시 말하면, 데이터 세트를 분할하는 데 가장 좋은 조건은 정보 이득이 높거나 지니 계수가 낮은 조건입니다. `DecisionTreeClassifier` 클래스는 기본적으로 지니 계수를 이용하여 데이터를 분할합니다. "
      ],
      "metadata": {
        "id": "EJxq6ZeiMImi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.1. 결정 트리 모델의 특징**"
      ],
      "metadata": {
        "id": "Mo5lQ-k_Z7PA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "결정 트리는 정보 균일도가 기반이므로 쉽고 직관적입니다. 대부분의 경우 피처 스케일링과 정규화 같은 전처리 작업도 불필요합니다. 다만 과적합되기 쉬우므로 트리 크기를 제한하면서 성능을 튜닝하는 편이 좋습니다."
      ],
      "metadata": {
        "id": "6Pwczlw8XXyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2. 결정 트리 파라미터**"
      ],
      "metadata": {
        "id": "aPgGOGUBZ7Mh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "휴식 중\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "wyohYldiYLwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.3. 결정 트리 모델의 시각화**"
      ],
      "metadata": {
        "id": "wUWCJxQlZ7J6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.4. 결정 트리 과적합(overfitting)**"
      ],
      "metadata": {
        "id": "gABNBBDCZ7Hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.5. 결정 트리 실습 - 사용자 행동 인식 데이터 세트**"
      ],
      "metadata": {
        "id": "T4Rf0i9zZ7Ez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. 앙상블 학습**"
      ],
      "metadata": {
        "id": "lctk2pssZ7CR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1. 앙상블 학습 개요**"
      ],
      "metadata": {
        "id": "66bGobX0Z6_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2. 보팅 유형 - 하드 보팅(hard voting)과 소프트 보팅(soft voting)**"
      ],
      "metadata": {
        "id": "jE8SnQLEZ69Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.3. 보팅 분류기(voting classifier)**"
      ],
      "metadata": {
        "id": "kq1gaDodZ668"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. 랜덤 포레스트**"
      ],
      "metadata": {
        "id": "pA56rMJMZ64k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1. 랜덤 포레스트 개요 및 실습**"
      ],
      "metadata": {
        "id": "uzxfpXTjZ62A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.2. 랜덤 포레스트 하이퍼 파라미터 및 튜닝**"
      ],
      "metadata": {
        "id": "CHvQJZJIZ6zd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. GBM(Gradient Boosting Machine)**"
      ],
      "metadata": {
        "id": "RGNrcwAKZ6xA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.1. GBM의 개요 및 실습**"
      ],
      "metadata": {
        "id": "GVWOuYxWbI6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.2. GBM 하이퍼 파라미터 및 튜닝**"
      ],
      "metadata": {
        "id": "AMi4mGtKbI3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. XGBoost(eXtra Gradient Boost)**"
      ],
      "metadata": {
        "id": "IEL0NYcMbI00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.1. XGBoost 개요**"
      ],
      "metadata": {
        "id": "XSA5gdUrbIyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.2. XGBoost 설치하기**"
      ],
      "metadata": {
        "id": "wqsldGkVbIwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.3. 파이썬 래퍼 XGBoost 하이퍼 파라미터**"
      ],
      "metadata": {
        "id": "k3abK_kwbItr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.4. 파이썬 래퍼 XGBoost 적용 - 위스콘신 유방암 예측**"
      ],
      "metadata": {
        "id": "VrSE_QX9cCBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.5. 사이킷런 래퍼 XGBoost의 개요 및 적용**"
      ],
      "metadata": {
        "id": "JFM0-kQvcB-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. LightGBM**"
      ],
      "metadata": {
        "id": "bPG8c5fDcB73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.1. LightGBM 설치**"
      ],
      "metadata": {
        "id": "nEaRwjM5cB4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.2. LightGBM 하이퍼 파라미터**"
      ],
      "metadata": {
        "id": "3FNuWZ-5cB2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.3. 하이퍼 파라미터 튜닝 방안**"
      ],
      "metadata": {
        "id": "q2R78lTXcBzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.4. 파이썬 래퍼 LightGBM과 사이킷런 래퍼 XGBoost, LightGBM 하이퍼 파라미터 비교**"
      ],
      "metadata": {
        "id": "QcNDmQHycBw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.5. LightGBM 적용 - 위스콘신 유방암 예측**"
      ],
      "metadata": {
        "id": "Ro7xeqcCbIrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. 분류 실습 - 캐글 산탄데르 고객 만족 예측**"
      ],
      "metadata": {
        "id": "5w3bEDEobIoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8.1. 데이터 전처리**"
      ],
      "metadata": {
        "id": "RDtLJeNhc6Yo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8.2. XGBoost 모델 학습과 하이퍼 파라미터 튜닝**"
      ],
      "metadata": {
        "id": "6bSw6czbc6WJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8.3. LightGBM 모델 학습과 하이퍼 파라미터 튜닝**"
      ],
      "metadata": {
        "id": "Pck-aYLkc6Tk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. 분류 실습 - 캐글 신용카드 사기 검출**"
      ],
      "metadata": {
        "id": "HpyB_iU5c6Re"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.1. 언더 샘플링과 오버 샘플링의 이해**"
      ],
      "metadata": {
        "id": "vTrvsAhHc6Og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.2. 데이터 일차 가공 및 모델 학습/예측/평가**"
      ],
      "metadata": {
        "id": "lkRMpXaOc6Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.3. 데이터 분포도 변환 후 모델 학습/예측 평가**"
      ],
      "metadata": {
        "id": "PQPUdzSZdwPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.4. 이상치 데이터 제거 후 모델 학습/예측/평가**"
      ],
      "metadata": {
        "id": "1ItzaqZadwMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.5. SMOTE 오버 샘플링 적용 후 모델 학습/예측/평가**"
      ],
      "metadata": {
        "id": "J6n7HdmIdwJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. 스태킹 앙상블**"
      ],
      "metadata": {
        "id": "LeEiZ2DgdwHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10.1. 기본 스태킹 모델**"
      ],
      "metadata": {
        "id": "-1c0frvUdwD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10.2. CV 세트 기반의 스태킹**"
      ],
      "metadata": {
        "id": "-6WXD3JDdwA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11. 정리**"
      ],
      "metadata": {
        "id": "8BPEqyaWdv-Y"
      }
    }
  ]
}