{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHAPTER5 회귀.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOjcOfc6ectfV1tfod3LOsn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Machine-learning_Theory/blob/master/CHAPTER5%20%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. 회귀 소개**"
      ],
      "metadata": {
        "id": "df78pAKeesnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 일반 선형 회귀: 예측값과 실젯값의 **RSS(Residual Sum of Squares)**를 최소화할 수 있도록 회귀 계수를 최적화하며 규제를 적용하지 않은 모델입니다.\n",
        "\n",
        "- **릿지(Ridge)** 회귀: 선형 회귀에 **L2 규제**를 추가한 회귀 모델입니다. L2 규제는 상대적으로 큰 회귀 계수 값의 예측 영향도를 감소시키기 위해 회귀 계수값을 더 작게 만듭니다.\n",
        "\n",
        "- **라쏘(Lasso)** 회귀: 선형 회귀에 **L1 규제(=피처 선택 기능)**를 추가한 회귀 모델입니다. L1 규제는 예측 형향력이 작은 피처의 회귀 계수를 0으로 만들어 회귀 예측 시 피처가 선택되지 않도록 할 수 있습니다.\n",
        "\n",
        "- **엘라스틱넷(ElasticNet)**: **L2**, **L1** 규제를 결합한 회귀 모델입니다. 피처가 많은 데이터 세트에서 적용됩니다. L1 규제로 피처 개수를 줄이면서 L2 규제로 계수 값 크기를 조정합니다.\n",
        "\n",
        "- **로지스틱 회귀(Logistic Regression)**: 회귀 모델 아닌 분류용 선형 모델입니다. 이진 분류뿐만 아니라 희소 영역의 분류(텍스트 분류 등) 같은 영역에서 좋은 예측 성능을 발휘합니다."
      ],
      "metadata": {
        "id": "QEvUqOgIn8OL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. 단순 선형 회귀를 통한 회귀 이해**"
      ],
      "metadata": {
        "id": "nzrGVn7weslW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "실젯값과 회귀 모델의 차이에 따른 오류 값을 남은 오류 또는 **잔차**라고 부릅니다. 최적의 회귀 모델은 잔차 합이 최소가 되는 모델이며 잔차 합이 최소가 될 수 있는 최적의 회귀 계수를 가진 것을 의미합니다.\n",
        "\n",
        "잔차는 양수나 음수 모두 될 수 있습니다. 보통 잔차를 계산할 때는 절댓값을 취해서 더하는 방식(**MAE, Mean Absolute Error**), 오류 값의 제곱을 구해서 더하는 방식(**RSS, Residual Sum of Squares**)을 사용합니다. 일반적으로는 RSS 방식을 취합니다. 회귀에서 RSS는 비용(Cost)이고 회귀 계수로 구성되는 RSS를 **비용 함수(손실 함수, Loss Function)**라고 부릅니다. 머신러닝 회귀 알고리즘은 데이터를 계속 학습하면서 이 비용 함수가 반환하는 값인 잔차(오류 값)을 지속해서 감소시키고 더 감소하지 않는 최소 잔차를 구하는 것입니다.\n",
        "\n",
        "수학 수식은 생략하겠습니다."
      ],
      "metadata": {
        "id": "K5_v2fHXBGdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. 비용 최소화하기 - 경사 하강법(Gradient Descent) 소개**"
      ],
      "metadata": {
        "id": "CMYcQ9flesi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**경사 하강법**은 비용 함수 RSS를 최소화하는 방법을 직관적으로 제공하는 방식입니다. 점진적이고 반복적으로 계산하면서 회귀 계수 값을 업데이트하고 궁극적으로는 오류 값이 최소가 되는 회귀 계수를 도출하는 방식입니다. 딥러닝의 기반인 신경망에서도 경사 하강법을 통해 학습합니다.\n",
        "\n",
        "경사 하강법은 반복적으로 비용 함수의 반환 값(예측값과 실젯값의 차이)이 작아지는 방향성을 가지고 W 파라미터(회귀 계수)를 계속 조정합니다. 최초 오류 값을 100으로 가정한다면 두 번째 오류 값은 90, 세 번째 오류 값은 80처럼 지속해서 오류를 감소시키는 방향으로 계속 업데이트합니다. 오류 값이 더 감소할 수 없으면 최소 비용으로 판단하고 최적 파라미터로 반환합니다.\n",
        "\n",
        "수학적 설명과 수식, 코드 구현은 생략하겠습니다. 자세한 내용은 서적을 참고하시기 바랍니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "QBS3S-uTHKfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. 사이킷런 LinearRegression을 이용한 보스턴 주택 가격 예측**"
      ],
      "metadata": {
        "id": "FfM3JS5Cesgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "휴식 중\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0vE7qUhcQ1eM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1. LinearRegression 클래스 - Ordinary Least Squares**"
      ],
      "metadata": {
        "id": "64D8OztaeseY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.2. 회귀 평가 지표**"
      ],
      "metadata": {
        "id": "UmnPfvB5esb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.3. LinearRegression을 이용해 보스턴 주택 가격 회귀 구현**"
      ],
      "metadata": {
        "id": "0VBRrrelesZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. 다항 회귀와 과(대)적합/과소적합 이해**"
      ],
      "metadata": {
        "id": "UNeQDiQhesXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.1. 다항 회귀 이해**"
      ],
      "metadata": {
        "id": "lp48crYYesVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.2. 다항 회귀를 이용한 과소적합 및 과적합 이해**"
      ],
      "metadata": {
        "id": "xDSqLqINesS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.3. 편향-분산 트레이드오프(bias-variance trade off)**"
      ],
      "metadata": {
        "id": "XUrBk9zResQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. 규제 선형 모델 - 릿지, 라쏘, 엘라스틱넷**"
      ],
      "metadata": {
        "id": "uEF8_rlpesOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.1. 규제 선형 모델의 개요**"
      ],
      "metadata": {
        "id": "1aljAnKLesL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.2. 릿지 회귀**"
      ],
      "metadata": {
        "id": "p59_KnfCesJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.3. 라쏘 회귀**"
      ],
      "metadata": {
        "id": "Vu0qetCKesHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.4. 엘라스틱넷 회귀**"
      ],
      "metadata": {
        "id": "n0kywtH7esFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.5. 선형 회귀 모델을 위한 데이터 변환**"
      ],
      "metadata": {
        "id": "SQrLFVcVesDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. 로지스틱 회귀**"
      ],
      "metadata": {
        "id": "TLVjhMijesAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. 회귀 트리**"
      ],
      "metadata": {
        "id": "wSpFITeyer-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. 회귀 실습 - 자전거 대여 수요 예측**"
      ],
      "metadata": {
        "id": "tgRYmJ8ner8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.1. 데이터 클렌징 및 가공**"
      ],
      "metadata": {
        "id": "Y4LULj6Igkpr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.2. 로그 변환, 피처 인코딩과 모델 학습/예측/평가**"
      ],
      "metadata": {
        "id": "Sd7tonIXgknR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. 회귀 실습 - 캐글 주택 가격: 고급 회귀 기법**"
      ],
      "metadata": {
        "id": "vf9rluYNgkk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10.1. 데이터 사전 처리(preprocessing)**"
      ],
      "metadata": {
        "id": "ONUIJa31gki0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10.2. 선형 회귀 모델 학습/예측/평가**"
      ],
      "metadata": {
        "id": "--YRaGuygkgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10.3. 회귀 트리 모델 학습/예측/평가**"
      ],
      "metadata": {
        "id": "QKWAOO4AgkeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10.4. 회귀 모델의 예측 결과 혼합을 통한 최종 예측**"
      ],
      "metadata": {
        "id": "BH8v0O8Cgkbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10.5. 스태킹 앙상블 모델을 통한 회귀 예측**"
      ],
      "metadata": {
        "id": "mRlAUFCGgkZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11. 정리**"
      ],
      "metadata": {
        "id": "_p9I4jiggkCf"
      }
    }
  ]
}