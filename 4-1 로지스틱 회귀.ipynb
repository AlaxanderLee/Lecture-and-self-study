{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-1 로지스틱 회귀.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOn/yKFxDEPmA7m5qg3hR5N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeSeungwon89/Lecture-and-self-study/blob/master/4-1%20%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%20%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYZ9VegVO7KC"
      },
      "source": [
        "# 로지스틱 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH8C6yDMhvpZ"
      },
      "source": [
        "## 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv0xcheHh0jB",
        "outputId": "3d02b7e2-84b8-4c13-8a7a-d3d0ddd3020e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "fish = pd.read_csv('https://bit.ly/fish_csv_data')\n",
        "\n",
        "fish.head()\n",
        "\n",
        "print(fish)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Species  Weight  Length  Diagonal   Height   Width\n",
            "0     Bream   242.0    25.4      30.0  11.5200  4.0200\n",
            "1     Bream   290.0    26.3      31.2  12.4800  4.3056\n",
            "2     Bream   340.0    26.5      31.1  12.3778  4.6961\n",
            "3     Bream   363.0    29.0      33.5  12.7300  4.4555\n",
            "4     Bream   430.0    29.0      34.0  12.4440  5.1340\n",
            "..      ...     ...     ...       ...      ...     ...\n",
            "154   Smelt    12.2    12.2      13.4   2.0904  1.3936\n",
            "155   Smelt    13.4    12.4      13.5   2.4300  1.2690\n",
            "156   Smelt    12.2    13.0      13.8   2.2770  1.2558\n",
            "157   Smelt    19.7    14.3      15.2   2.8728  2.0672\n",
            "158   Smelt    19.9    15.0      16.2   2.9322  1.8792\n",
            "\n",
            "[159 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJb-O-K4j48R",
        "outputId": "6dee9bdf-c8c6-452c-baa0-c4f5c2944da3"
      },
      "source": [
        "# 어떤 종류의 생선이 있는지 고유값을 추출함.\n",
        "print(pd.unique(fish['Species']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bream' 'Roach' 'Whitefish' 'Parkki' 'Perch' 'Pike' 'Smelt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOV7GYGij67X",
        "outputId": "193e0d48-1563-45b9-f9c0-d38643e45671"
      },
      "source": [
        "# 나머지 열 5개는 입력 데이터로 만들고, Species 열을 타깃으로 만듦. \n",
        "fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n",
        "\n",
        "fish_target = fish[['Species']].to_numpy()\n",
        "# 타깃 데이터에 2개 이상의 클래스가 포함된 문제를 '다중 분류(multi-class classification)' 라고 함.\n",
        "# 이진 분류에서는 양성 클래스와 음성 클래스를 1과 0으로 지정하여 데이터를 만들었으나,\n",
        "# 사이킷런에서는 문자열로 된 타깃 값을 그대로 사용할 수 있음.\n",
        "\n",
        "print(fish_input, fish_target)\n",
        "print(fish_input[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.42000e+02 2.54000e+01 3.00000e+01 1.15200e+01 4.02000e+00]\n",
            " [2.90000e+02 2.63000e+01 3.12000e+01 1.24800e+01 4.30560e+00]\n",
            " [3.40000e+02 2.65000e+01 3.11000e+01 1.23778e+01 4.69610e+00]\n",
            " [3.63000e+02 2.90000e+01 3.35000e+01 1.27300e+01 4.45550e+00]\n",
            " [4.30000e+02 2.90000e+01 3.40000e+01 1.24440e+01 5.13400e+00]\n",
            " [4.50000e+02 2.97000e+01 3.47000e+01 1.36024e+01 4.92740e+00]\n",
            " [5.00000e+02 2.97000e+01 3.45000e+01 1.41795e+01 5.27850e+00]\n",
            " [3.90000e+02 3.00000e+01 3.50000e+01 1.26700e+01 4.69000e+00]\n",
            " [4.50000e+02 3.00000e+01 3.51000e+01 1.40049e+01 4.84380e+00]\n",
            " [5.00000e+02 3.07000e+01 3.62000e+01 1.42266e+01 4.95940e+00]\n",
            " [4.75000e+02 3.10000e+01 3.62000e+01 1.42628e+01 5.10420e+00]\n",
            " [5.00000e+02 3.10000e+01 3.62000e+01 1.43714e+01 4.81460e+00]\n",
            " [5.00000e+02 3.15000e+01 3.64000e+01 1.37592e+01 4.36800e+00]\n",
            " [3.40000e+02 3.20000e+01 3.73000e+01 1.39129e+01 5.07280e+00]\n",
            " [6.00000e+02 3.20000e+01 3.72000e+01 1.49544e+01 5.17080e+00]\n",
            " [6.00000e+02 3.20000e+01 3.72000e+01 1.54380e+01 5.58000e+00]\n",
            " [7.00000e+02 3.30000e+01 3.83000e+01 1.48604e+01 5.28540e+00]\n",
            " [7.00000e+02 3.30000e+01 3.85000e+01 1.49380e+01 5.19750e+00]\n",
            " [6.10000e+02 3.35000e+01 3.86000e+01 1.56330e+01 5.13380e+00]\n",
            " [6.50000e+02 3.35000e+01 3.87000e+01 1.44738e+01 5.72760e+00]\n",
            " [5.75000e+02 3.40000e+01 3.95000e+01 1.51285e+01 5.56950e+00]\n",
            " [6.85000e+02 3.40000e+01 3.92000e+01 1.59936e+01 5.37040e+00]\n",
            " [6.20000e+02 3.45000e+01 3.97000e+01 1.55227e+01 5.28010e+00]\n",
            " [6.80000e+02 3.50000e+01 4.06000e+01 1.54686e+01 6.13060e+00]\n",
            " [7.00000e+02 3.50000e+01 4.05000e+01 1.62405e+01 5.58900e+00]\n",
            " [7.25000e+02 3.50000e+01 4.09000e+01 1.63600e+01 6.05320e+00]\n",
            " [7.20000e+02 3.50000e+01 4.06000e+01 1.63618e+01 6.09000e+00]\n",
            " [7.14000e+02 3.60000e+01 4.15000e+01 1.65170e+01 5.85150e+00]\n",
            " [8.50000e+02 3.60000e+01 4.16000e+01 1.68896e+01 6.19840e+00]\n",
            " [1.00000e+03 3.70000e+01 4.26000e+01 1.89570e+01 6.60300e+00]\n",
            " [9.20000e+02 3.85000e+01 4.41000e+01 1.80369e+01 6.30630e+00]\n",
            " [9.55000e+02 3.85000e+01 4.40000e+01 1.80840e+01 6.29200e+00]\n",
            " [9.25000e+02 3.95000e+01 4.53000e+01 1.87542e+01 6.74970e+00]\n",
            " [9.75000e+02 4.10000e+01 4.59000e+01 1.86354e+01 6.74730e+00]\n",
            " [9.50000e+02 4.10000e+01 4.65000e+01 1.76235e+01 6.37050e+00]\n",
            " [4.00000e+01 1.41000e+01 1.62000e+01 4.14720e+00 2.26800e+00]\n",
            " [6.90000e+01 1.82000e+01 2.03000e+01 5.29830e+00 2.82170e+00]\n",
            " [7.80000e+01 1.88000e+01 2.12000e+01 5.57560e+00 2.90440e+00]\n",
            " [8.70000e+01 1.98000e+01 2.22000e+01 5.61660e+00 3.17460e+00]\n",
            " [1.20000e+02 2.00000e+01 2.22000e+01 6.21600e+00 3.57420e+00]\n",
            " [0.00000e+00 2.05000e+01 2.28000e+01 6.47520e+00 3.35160e+00]\n",
            " [1.10000e+02 2.08000e+01 2.31000e+01 6.16770e+00 3.39570e+00]\n",
            " [1.20000e+02 2.10000e+01 2.37000e+01 6.11460e+00 3.29430e+00]\n",
            " [1.50000e+02 2.20000e+01 2.47000e+01 5.80450e+00 3.75440e+00]\n",
            " [1.45000e+02 2.20000e+01 2.43000e+01 6.63390e+00 3.54780e+00]\n",
            " [1.60000e+02 2.25000e+01 2.53000e+01 7.03340e+00 3.82030e+00]\n",
            " [1.40000e+02 2.25000e+01 2.50000e+01 6.55000e+00 3.32500e+00]\n",
            " [1.60000e+02 2.25000e+01 2.50000e+01 6.40000e+00 3.80000e+00]\n",
            " [1.69000e+02 2.40000e+01 2.72000e+01 7.53440e+00 3.83520e+00]\n",
            " [1.61000e+02 2.34000e+01 2.67000e+01 6.91530e+00 3.63120e+00]\n",
            " [2.00000e+02 2.35000e+01 2.68000e+01 7.39680e+00 4.12720e+00]\n",
            " [1.80000e+02 2.52000e+01 2.79000e+01 7.08660e+00 3.90600e+00]\n",
            " [2.90000e+02 2.60000e+01 2.92000e+01 8.87680e+00 4.49680e+00]\n",
            " [2.72000e+02 2.70000e+01 3.06000e+01 8.56800e+00 4.77360e+00]\n",
            " [3.90000e+02 3.17000e+01 3.50000e+01 9.48500e+00 5.35500e+00]\n",
            " [2.70000e+02 2.60000e+01 2.87000e+01 8.38040e+00 4.24760e+00]\n",
            " [2.70000e+02 2.65000e+01 2.93000e+01 8.14540e+00 4.24850e+00]\n",
            " [3.06000e+02 2.80000e+01 3.08000e+01 8.77800e+00 4.68160e+00]\n",
            " [5.40000e+02 3.10000e+01 3.40000e+01 1.07440e+01 6.56200e+00]\n",
            " [8.00000e+02 3.64000e+01 3.96000e+01 1.17612e+01 6.57360e+00]\n",
            " [1.00000e+03 4.00000e+01 4.35000e+01 1.23540e+01 6.52500e+00]\n",
            " [5.50000e+01 1.47000e+01 1.65000e+01 6.84750e+00 2.32650e+00]\n",
            " [6.00000e+01 1.55000e+01 1.74000e+01 6.57720e+00 2.31420e+00]\n",
            " [9.00000e+01 1.77000e+01 1.98000e+01 7.40520e+00 2.67300e+00]\n",
            " [1.20000e+02 1.90000e+01 2.13000e+01 8.39220e+00 2.91810e+00]\n",
            " [1.50000e+02 2.00000e+01 2.24000e+01 8.89280e+00 3.29280e+00]\n",
            " [1.40000e+02 2.07000e+01 2.32000e+01 8.53760e+00 3.29440e+00]\n",
            " [1.70000e+02 2.07000e+01 2.32000e+01 9.39600e+00 3.41040e+00]\n",
            " [1.45000e+02 2.15000e+01 2.41000e+01 9.73640e+00 3.15710e+00]\n",
            " [2.00000e+02 2.30000e+01 2.58000e+01 1.03458e+01 3.66360e+00]\n",
            " [2.73000e+02 2.50000e+01 2.80000e+01 1.10880e+01 4.14400e+00]\n",
            " [3.00000e+02 2.60000e+01 2.90000e+01 1.13680e+01 4.23400e+00]\n",
            " [5.90000e+00 8.40000e+00 8.80000e+00 2.11200e+00 1.40800e+00]\n",
            " [3.20000e+01 1.37000e+01 1.47000e+01 3.52800e+00 1.99920e+00]\n",
            " [4.00000e+01 1.50000e+01 1.60000e+01 3.82400e+00 2.43200e+00]\n",
            " [5.15000e+01 1.62000e+01 1.72000e+01 4.59240e+00 2.63160e+00]\n",
            " [7.00000e+01 1.74000e+01 1.85000e+01 4.58800e+00 2.94150e+00]\n",
            " [1.00000e+02 1.80000e+01 1.92000e+01 5.22240e+00 3.32160e+00]\n",
            " [7.80000e+01 1.87000e+01 1.94000e+01 5.19920e+00 3.12340e+00]\n",
            " [8.00000e+01 1.90000e+01 2.02000e+01 5.63580e+00 3.05020e+00]\n",
            " [8.50000e+01 1.96000e+01 2.08000e+01 5.13760e+00 3.03680e+00]\n",
            " [8.50000e+01 2.00000e+01 2.10000e+01 5.08200e+00 2.77200e+00]\n",
            " [1.10000e+02 2.10000e+01 2.25000e+01 5.69250e+00 3.55500e+00]\n",
            " [1.15000e+02 2.10000e+01 2.25000e+01 5.91750e+00 3.30750e+00]\n",
            " [1.25000e+02 2.10000e+01 2.25000e+01 5.69250e+00 3.66750e+00]\n",
            " [1.30000e+02 2.13000e+01 2.28000e+01 6.38400e+00 3.53400e+00]\n",
            " [1.20000e+02 2.20000e+01 2.35000e+01 6.11000e+00 3.40750e+00]\n",
            " [1.20000e+02 2.20000e+01 2.35000e+01 5.64000e+00 3.52500e+00]\n",
            " [1.30000e+02 2.20000e+01 2.35000e+01 6.11000e+00 3.52500e+00]\n",
            " [1.35000e+02 2.20000e+01 2.35000e+01 5.87500e+00 3.52500e+00]\n",
            " [1.10000e+02 2.20000e+01 2.35000e+01 5.52250e+00 3.99500e+00]\n",
            " [1.30000e+02 2.25000e+01 2.40000e+01 5.85600e+00 3.62400e+00]\n",
            " [1.50000e+02 2.25000e+01 2.40000e+01 6.79200e+00 3.62400e+00]\n",
            " [1.45000e+02 2.27000e+01 2.42000e+01 5.95320e+00 3.63000e+00]\n",
            " [1.50000e+02 2.30000e+01 2.45000e+01 5.21850e+00 3.62600e+00]\n",
            " [1.70000e+02 2.35000e+01 2.50000e+01 6.27500e+00 3.72500e+00]\n",
            " [2.25000e+02 2.40000e+01 2.55000e+01 7.29300e+00 3.72300e+00]\n",
            " [1.45000e+02 2.40000e+01 2.55000e+01 6.37500e+00 3.82500e+00]\n",
            " [1.88000e+02 2.46000e+01 2.62000e+01 6.73340e+00 4.16580e+00]\n",
            " [1.80000e+02 2.50000e+01 2.65000e+01 6.43950e+00 3.68350e+00]\n",
            " [1.97000e+02 2.56000e+01 2.70000e+01 6.56100e+00 4.23900e+00]\n",
            " [2.18000e+02 2.65000e+01 2.80000e+01 7.16800e+00 4.14400e+00]\n",
            " [3.00000e+02 2.73000e+01 2.87000e+01 8.32300e+00 5.13730e+00]\n",
            " [2.60000e+02 2.75000e+01 2.89000e+01 7.16720e+00 4.33500e+00]\n",
            " [2.65000e+02 2.75000e+01 2.89000e+01 7.05160e+00 4.33500e+00]\n",
            " [2.50000e+02 2.75000e+01 2.89000e+01 7.28280e+00 4.56620e+00]\n",
            " [2.50000e+02 2.80000e+01 2.94000e+01 7.82040e+00 4.20420e+00]\n",
            " [3.00000e+02 2.87000e+01 3.01000e+01 7.58520e+00 4.63540e+00]\n",
            " [3.20000e+02 3.00000e+01 3.16000e+01 7.61560e+00 4.77160e+00]\n",
            " [5.14000e+02 3.28000e+01 3.40000e+01 1.00300e+01 6.01800e+00]\n",
            " [5.56000e+02 3.45000e+01 3.65000e+01 1.02565e+01 6.38750e+00]\n",
            " [8.40000e+02 3.50000e+01 3.73000e+01 1.14884e+01 7.79570e+00]\n",
            " [6.85000e+02 3.65000e+01 3.90000e+01 1.08810e+01 6.86400e+00]\n",
            " [7.00000e+02 3.60000e+01 3.83000e+01 1.06091e+01 6.74080e+00]\n",
            " [7.00000e+02 3.70000e+01 3.94000e+01 1.08350e+01 6.26460e+00]\n",
            " [6.90000e+02 3.70000e+01 3.93000e+01 1.05717e+01 6.36660e+00]\n",
            " [9.00000e+02 3.90000e+01 4.14000e+01 1.11366e+01 7.49340e+00]\n",
            " [6.50000e+02 3.90000e+01 4.14000e+01 1.11366e+01 6.00300e+00]\n",
            " [8.20000e+02 3.90000e+01 4.13000e+01 1.24313e+01 7.35140e+00]\n",
            " [8.50000e+02 4.00000e+01 4.23000e+01 1.19286e+01 7.10640e+00]\n",
            " [9.00000e+02 4.00000e+01 4.25000e+01 1.17300e+01 7.22500e+00]\n",
            " [1.01500e+03 4.00000e+01 4.24000e+01 1.23808e+01 7.46240e+00]\n",
            " [8.20000e+02 4.00000e+01 4.25000e+01 1.11350e+01 6.63000e+00]\n",
            " [1.10000e+03 4.20000e+01 4.46000e+01 1.28002e+01 6.86840e+00]\n",
            " [1.00000e+03 4.30000e+01 4.52000e+01 1.19328e+01 7.27720e+00]\n",
            " [1.10000e+03 4.30000e+01 4.55000e+01 1.25125e+01 7.41650e+00]\n",
            " [1.00000e+03 4.35000e+01 4.60000e+01 1.26040e+01 8.14200e+00]\n",
            " [1.00000e+03 4.40000e+01 4.66000e+01 1.24888e+01 7.59580e+00]\n",
            " [2.00000e+02 3.23000e+01 3.48000e+01 5.56800e+00 3.37560e+00]\n",
            " [3.00000e+02 3.40000e+01 3.78000e+01 5.70780e+00 4.15800e+00]\n",
            " [3.00000e+02 3.50000e+01 3.88000e+01 5.93640e+00 4.38440e+00]\n",
            " [3.00000e+02 3.73000e+01 3.98000e+01 6.28840e+00 4.01980e+00]\n",
            " [4.30000e+02 3.80000e+01 4.05000e+01 7.29000e+00 4.57650e+00]\n",
            " [3.45000e+02 3.85000e+01 4.10000e+01 6.39600e+00 3.97700e+00]\n",
            " [4.56000e+02 4.25000e+01 4.55000e+01 7.28000e+00 4.32250e+00]\n",
            " [5.10000e+02 4.25000e+01 4.55000e+01 6.82500e+00 4.45900e+00]\n",
            " [5.40000e+02 4.30000e+01 4.58000e+01 7.78600e+00 5.12960e+00]\n",
            " [5.00000e+02 4.50000e+01 4.80000e+01 6.96000e+00 4.89600e+00]\n",
            " [5.67000e+02 4.60000e+01 4.87000e+01 7.79200e+00 4.87000e+00]\n",
            " [7.70000e+02 4.80000e+01 5.12000e+01 7.68000e+00 5.37600e+00]\n",
            " [9.50000e+02 5.17000e+01 5.51000e+01 8.92620e+00 6.17120e+00]\n",
            " [1.25000e+03 5.60000e+01 5.97000e+01 1.06863e+01 6.98490e+00]\n",
            " [1.60000e+03 6.00000e+01 6.40000e+01 9.60000e+00 6.14400e+00]\n",
            " [1.55000e+03 6.00000e+01 6.40000e+01 9.60000e+00 6.14400e+00]\n",
            " [1.65000e+03 6.34000e+01 6.80000e+01 1.08120e+01 7.48000e+00]\n",
            " [6.70000e+00 9.80000e+00 1.08000e+01 1.73880e+00 1.04760e+00]\n",
            " [7.50000e+00 1.05000e+01 1.16000e+01 1.97200e+00 1.16000e+00]\n",
            " [7.00000e+00 1.06000e+01 1.16000e+01 1.72840e+00 1.14840e+00]\n",
            " [9.70000e+00 1.10000e+01 1.20000e+01 2.19600e+00 1.38000e+00]\n",
            " [9.80000e+00 1.12000e+01 1.24000e+01 2.08320e+00 1.27720e+00]\n",
            " [8.70000e+00 1.13000e+01 1.26000e+01 1.97820e+00 1.28520e+00]\n",
            " [1.00000e+01 1.18000e+01 1.31000e+01 2.21390e+00 1.28380e+00]\n",
            " [9.90000e+00 1.18000e+01 1.31000e+01 2.21390e+00 1.16590e+00]\n",
            " [9.80000e+00 1.20000e+01 1.32000e+01 2.20440e+00 1.14840e+00]\n",
            " [1.22000e+01 1.22000e+01 1.34000e+01 2.09040e+00 1.39360e+00]\n",
            " [1.34000e+01 1.24000e+01 1.35000e+01 2.43000e+00 1.26900e+00]\n",
            " [1.22000e+01 1.30000e+01 1.38000e+01 2.27700e+00 1.25580e+00]\n",
            " [1.97000e+01 1.43000e+01 1.52000e+01 2.87280e+00 2.06720e+00]\n",
            " [1.99000e+01 1.50000e+01 1.62000e+01 2.93220e+00 1.87920e+00]] [['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Whitefish']\n",
            " ['Whitefish']\n",
            " ['Whitefish']\n",
            " ['Whitefish']\n",
            " ['Whitefish']\n",
            " ['Whitefish']\n",
            " ['Parkki']\n",
            " ['Parkki']\n",
            " ['Parkki']\n",
            " ['Parkki']\n",
            " ['Parkki']\n",
            " ['Parkki']\n",
            " ['Parkki']\n",
            " ['Parkki']\n",
            " ['Parkki']\n",
            " ['Parkki']\n",
            " ['Parkki']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Smelt']]\n",
            "[[242.      25.4     30.      11.52     4.02  ]\n",
            " [290.      26.3     31.2     12.48     4.3056]\n",
            " [340.      26.5     31.1     12.3778   4.6961]\n",
            " [363.      29.      33.5     12.73     4.4555]\n",
            " [430.      29.      34.      12.444    5.134 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p5hWJnjlFvN",
        "outputId": "e9b25e37-5229-47a1-d235-89ee0af9a9ea"
      },
      "source": [
        "# 훈련 세트와 테스트 세트로 나눔.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state = 42)\n",
        "\n",
        "print(train_input, train_target)\n",
        "print(test_input, test_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7.20000e+02 3.50000e+01 4.06000e+01 1.63618e+01 6.09000e+00]\n",
            " [5.00000e+02 4.50000e+01 4.80000e+01 6.96000e+00 4.89600e+00]\n",
            " [7.50000e+00 1.05000e+01 1.16000e+01 1.97200e+00 1.16000e+00]\n",
            " [1.10000e+02 2.20000e+01 2.35000e+01 5.52250e+00 3.99500e+00]\n",
            " [1.40000e+02 2.07000e+01 2.32000e+01 8.53760e+00 3.29440e+00]\n",
            " [6.90000e+01 1.82000e+01 2.03000e+01 5.29830e+00 2.82170e+00]\n",
            " [1.10000e+02 2.10000e+01 2.25000e+01 5.69250e+00 3.55500e+00]\n",
            " [6.20000e+02 3.45000e+01 3.97000e+01 1.55227e+01 5.28010e+00]\n",
            " [1.30000e+02 2.13000e+01 2.28000e+01 6.38400e+00 3.53400e+00]\n",
            " [8.50000e+01 2.00000e+01 2.10000e+01 5.08200e+00 2.77200e+00]\n",
            " [6.85000e+02 3.65000e+01 3.90000e+01 1.08810e+01 6.86400e+00]\n",
            " [5.00000e+02 3.10000e+01 3.62000e+01 1.43714e+01 4.81460e+00]\n",
            " [5.14000e+02 3.28000e+01 3.40000e+01 1.00300e+01 6.01800e+00]\n",
            " [2.00000e+02 2.30000e+01 2.58000e+01 1.03458e+01 3.66360e+00]\n",
            " [1.00000e+03 4.40000e+01 4.66000e+01 1.24888e+01 7.59580e+00]\n",
            " [7.14000e+02 3.60000e+01 4.15000e+01 1.65170e+01 5.85150e+00]\n",
            " [8.70000e+00 1.13000e+01 1.26000e+01 1.97820e+00 1.28520e+00]\n",
            " [1.00000e+03 4.30000e+01 4.52000e+01 1.19328e+01 7.27720e+00]\n",
            " [1.10000e+02 2.08000e+01 2.31000e+01 6.16770e+00 3.39570e+00]\n",
            " [4.30000e+02 2.90000e+01 3.40000e+01 1.24440e+01 5.13400e+00]\n",
            " [4.56000e+02 4.25000e+01 4.55000e+01 7.28000e+00 4.32250e+00]\n",
            " [9.25000e+02 3.95000e+01 4.53000e+01 1.87542e+01 6.74970e+00]\n",
            " [9.50000e+02 5.17000e+01 5.51000e+01 8.92620e+00 6.17120e+00]\n",
            " [2.50000e+02 2.75000e+01 2.89000e+01 7.28280e+00 4.56620e+00]\n",
            " [1.70000e+02 2.07000e+01 2.32000e+01 9.39600e+00 3.41040e+00]\n",
            " [4.75000e+02 3.10000e+01 3.62000e+01 1.42628e+01 5.10420e+00]\n",
            " [1.45000e+02 2.27000e+01 2.42000e+01 5.95320e+00 3.63000e+00]\n",
            " [3.00000e+02 3.73000e+01 3.98000e+01 6.28840e+00 4.01980e+00]\n",
            " [2.42000e+02 2.54000e+01 3.00000e+01 1.15200e+01 4.02000e+00]\n",
            " [6.50000e+02 3.90000e+01 4.14000e+01 1.11366e+01 6.00300e+00]\n",
            " [1.20000e+02 1.90000e+01 2.13000e+01 8.39220e+00 2.91810e+00]\n",
            " [1.45000e+02 2.20000e+01 2.43000e+01 6.63390e+00 3.54780e+00]\n",
            " [1.25000e+02 2.10000e+01 2.25000e+01 5.69250e+00 3.66750e+00]\n",
            " [8.50000e+02 3.60000e+01 4.16000e+01 1.68896e+01 6.19840e+00]\n",
            " [0.00000e+00 2.05000e+01 2.28000e+01 6.47520e+00 3.35160e+00]\n",
            " [8.40000e+02 3.50000e+01 3.73000e+01 1.14884e+01 7.79570e+00]\n",
            " [7.25000e+02 3.50000e+01 4.09000e+01 1.63600e+01 6.05320e+00]\n",
            " [6.80000e+02 3.50000e+01 4.06000e+01 1.54686e+01 6.13060e+00]\n",
            " [6.90000e+02 3.70000e+01 3.93000e+01 1.05717e+01 6.36660e+00]\n",
            " [8.00000e+01 1.90000e+01 2.02000e+01 5.63580e+00 3.05020e+00]\n",
            " [1.20000e+02 2.00000e+01 2.22000e+01 6.21600e+00 3.57420e+00]\n",
            " [1.60000e+03 6.00000e+01 6.40000e+01 9.60000e+00 6.14400e+00]\n",
            " [2.65000e+02 2.75000e+01 2.89000e+01 7.05160e+00 4.33500e+00]\n",
            " [1.22000e+01 1.22000e+01 1.34000e+01 2.09040e+00 1.39360e+00]\n",
            " [3.45000e+02 3.85000e+01 4.10000e+01 6.39600e+00 3.97700e+00]\n",
            " [1.60000e+02 2.25000e+01 2.50000e+01 6.40000e+00 3.80000e+00]\n",
            " [8.50000e+02 4.00000e+01 4.23000e+01 1.19286e+01 7.10640e+00]\n",
            " [5.50000e+01 1.47000e+01 1.65000e+01 6.84750e+00 2.32650e+00]\n",
            " [3.20000e+01 1.37000e+01 1.47000e+01 3.52800e+00 1.99920e+00]\n",
            " [9.75000e+02 4.10000e+01 4.59000e+01 1.86354e+01 6.74730e+00]\n",
            " [3.20000e+02 3.00000e+01 3.16000e+01 7.61560e+00 4.77160e+00]\n",
            " [9.70000e+00 1.10000e+01 1.20000e+01 2.19600e+00 1.38000e+00]\n",
            " [1.10000e+03 4.20000e+01 4.46000e+01 1.28002e+01 6.86840e+00]\n",
            " [6.00000e+01 1.55000e+01 1.74000e+01 6.57720e+00 2.31420e+00]\n",
            " [1.97000e+01 1.43000e+01 1.52000e+01 2.87280e+00 2.06720e+00]\n",
            " [1.45000e+02 2.40000e+01 2.55000e+01 6.37500e+00 3.82500e+00]\n",
            " [1.97000e+02 2.56000e+01 2.70000e+01 6.56100e+00 4.23900e+00]\n",
            " [2.72000e+02 2.70000e+01 3.06000e+01 8.56800e+00 4.77360e+00]\n",
            " [4.50000e+02 2.97000e+01 3.47000e+01 1.36024e+01 4.92740e+00]\n",
            " [7.00000e+02 3.70000e+01 3.94000e+01 1.08350e+01 6.26460e+00]\n",
            " [8.20000e+02 4.00000e+01 4.25000e+01 1.11350e+01 6.63000e+00]\n",
            " [1.61000e+02 2.34000e+01 2.67000e+01 6.91530e+00 3.63120e+00]\n",
            " [4.00000e+01 1.41000e+01 1.62000e+01 4.14720e+00 2.26800e+00]\n",
            " [8.50000e+01 1.96000e+01 2.08000e+01 5.13760e+00 3.03680e+00]\n",
            " [1.00000e+02 1.80000e+01 1.92000e+01 5.22240e+00 3.32160e+00]\n",
            " [9.50000e+02 4.10000e+01 4.65000e+01 1.76235e+01 6.37050e+00]\n",
            " [1.40000e+02 2.25000e+01 2.50000e+01 6.55000e+00 3.32500e+00]\n",
            " [3.90000e+02 3.00000e+01 3.50000e+01 1.26700e+01 4.69000e+00]\n",
            " [1.50000e+02 2.20000e+01 2.47000e+01 5.80450e+00 3.75440e+00]\n",
            " [2.73000e+02 2.50000e+01 2.80000e+01 1.10880e+01 4.14400e+00]\n",
            " [9.00000e+02 4.00000e+01 4.25000e+01 1.17300e+01 7.22500e+00]\n",
            " [5.56000e+02 3.45000e+01 3.65000e+01 1.02565e+01 6.38750e+00]\n",
            " [1.30000e+02 2.25000e+01 2.40000e+01 5.85600e+00 3.62400e+00]\n",
            " [1.15000e+02 2.10000e+01 2.25000e+01 5.91750e+00 3.30750e+00]\n",
            " [1.55000e+03 6.00000e+01 6.40000e+01 9.60000e+00 6.14400e+00]\n",
            " [1.65000e+03 6.34000e+01 6.80000e+01 1.08120e+01 7.48000e+00]\n",
            " [1.35000e+02 2.20000e+01 2.35000e+01 5.87500e+00 3.52500e+00]\n",
            " [4.50000e+02 3.00000e+01 3.51000e+01 1.40049e+01 4.84380e+00]\n",
            " [7.00000e+02 3.60000e+01 3.83000e+01 1.06091e+01 6.74080e+00]\n",
            " [3.40000e+02 3.20000e+01 3.73000e+01 1.39129e+01 5.07280e+00]\n",
            " [8.00000e+02 3.64000e+01 3.96000e+01 1.17612e+01 6.57360e+00]\n",
            " [5.40000e+02 4.30000e+01 4.58000e+01 7.78600e+00 5.12960e+00]\n",
            " [3.63000e+02 2.90000e+01 3.35000e+01 1.27300e+01 4.45550e+00]\n",
            " [7.00000e+02 3.30000e+01 3.85000e+01 1.49380e+01 5.19750e+00]\n",
            " [8.70000e+01 1.98000e+01 2.22000e+01 5.61660e+00 3.17460e+00]\n",
            " [5.90000e+00 8.40000e+00 8.80000e+00 2.11200e+00 1.40800e+00]\n",
            " [7.70000e+02 4.80000e+01 5.12000e+01 7.68000e+00 5.37600e+00]\n",
            " [5.00000e+02 2.97000e+01 3.45000e+01 1.41795e+01 5.27850e+00]\n",
            " [4.30000e+02 3.80000e+01 4.05000e+01 7.29000e+00 4.57650e+00]\n",
            " [9.00000e+01 1.77000e+01 1.98000e+01 7.40520e+00 2.67300e+00]\n",
            " [3.90000e+02 3.17000e+01 3.50000e+01 9.48500e+00 5.35500e+00]\n",
            " [3.00000e+02 2.87000e+01 3.01000e+01 7.58520e+00 4.63540e+00]\n",
            " [2.00000e+02 2.35000e+01 2.68000e+01 7.39680e+00 4.12720e+00]\n",
            " [1.22000e+01 1.30000e+01 1.38000e+01 2.27700e+00 1.25580e+00]\n",
            " [5.40000e+02 3.10000e+01 3.40000e+01 1.07440e+01 6.56200e+00]\n",
            " [1.69000e+02 2.40000e+01 2.72000e+01 7.53440e+00 3.83520e+00]\n",
            " [1.30000e+02 2.20000e+01 2.35000e+01 6.11000e+00 3.52500e+00]\n",
            " [6.85000e+02 3.40000e+01 3.92000e+01 1.59936e+01 5.37040e+00]\n",
            " [3.06000e+02 2.80000e+01 3.08000e+01 8.77800e+00 4.68160e+00]\n",
            " [9.80000e+00 1.20000e+01 1.32000e+01 2.20440e+00 1.14840e+00]\n",
            " [3.00000e+02 3.40000e+01 3.78000e+01 5.70780e+00 4.15800e+00]\n",
            " [7.80000e+01 1.88000e+01 2.12000e+01 5.57560e+00 2.90440e+00]\n",
            " [9.80000e+00 1.12000e+01 1.24000e+01 2.08320e+00 1.27720e+00]\n",
            " [2.90000e+02 2.63000e+01 3.12000e+01 1.24800e+01 4.30560e+00]\n",
            " [2.90000e+02 2.60000e+01 2.92000e+01 8.87680e+00 4.49680e+00]\n",
            " [3.00000e+02 3.50000e+01 3.88000e+01 5.93640e+00 4.38440e+00]\n",
            " [2.60000e+02 2.75000e+01 2.89000e+01 7.16720e+00 4.33500e+00]\n",
            " [1.80000e+02 2.50000e+01 2.65000e+01 6.43950e+00 3.68350e+00]\n",
            " [9.00000e+02 3.90000e+01 4.14000e+01 1.11366e+01 7.49340e+00]\n",
            " [1.20000e+02 2.20000e+01 2.35000e+01 5.64000e+00 3.52500e+00]\n",
            " [4.00000e+01 1.50000e+01 1.60000e+01 3.82400e+00 2.43200e+00]\n",
            " [1.01500e+03 4.00000e+01 4.24000e+01 1.23808e+01 7.46240e+00]\n",
            " [1.99000e+01 1.50000e+01 1.62000e+01 2.93220e+00 1.87920e+00]\n",
            " [5.75000e+02 3.40000e+01 3.95000e+01 1.51285e+01 5.56950e+00]\n",
            " [3.00000e+02 2.60000e+01 2.90000e+01 1.13680e+01 4.23400e+00]\n",
            " [2.50000e+02 2.80000e+01 2.94000e+01 7.82040e+00 4.20420e+00]\n",
            " [6.00000e+02 3.20000e+01 3.72000e+01 1.49544e+01 5.17080e+00]\n",
            " [1.50000e+02 2.25000e+01 2.40000e+01 6.79200e+00 3.62400e+00]\n",
            " [3.00000e+02 2.73000e+01 2.87000e+01 8.32300e+00 5.13730e+00]] [['Bream']\n",
            " ['Pike']\n",
            " ['Smelt']\n",
            " ['Perch']\n",
            " ['Parkki']\n",
            " ['Roach']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Perch']\n",
            " ['Parkki']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Smelt']\n",
            " ['Perch']\n",
            " ['Roach']\n",
            " ['Bream']\n",
            " ['Pike']\n",
            " ['Bream']\n",
            " ['Pike']\n",
            " ['Perch']\n",
            " ['Parkki']\n",
            " ['Bream']\n",
            " ['Perch']\n",
            " ['Pike']\n",
            " ['Bream']\n",
            " ['Perch']\n",
            " ['Parkki']\n",
            " ['Roach']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Roach']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Roach']\n",
            " ['Pike']\n",
            " ['Perch']\n",
            " ['Smelt']\n",
            " ['Pike']\n",
            " ['Roach']\n",
            " ['Perch']\n",
            " ['Parkki']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Perch']\n",
            " ['Smelt']\n",
            " ['Perch']\n",
            " ['Parkki']\n",
            " ['Smelt']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Roach']\n",
            " ['Bream']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Roach']\n",
            " ['Bream']\n",
            " ['Roach']\n",
            " ['Parkki']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Pike']\n",
            " ['Pike']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Whitefish']\n",
            " ['Pike']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Roach']\n",
            " ['Perch']\n",
            " ['Pike']\n",
            " ['Bream']\n",
            " ['Pike']\n",
            " ['Parkki']\n",
            " ['Roach']\n",
            " ['Perch']\n",
            " ['Roach']\n",
            " ['Smelt']\n",
            " ['Whitefish']\n",
            " ['Roach']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Whitefish']\n",
            " ['Smelt']\n",
            " ['Pike']\n",
            " ['Roach']\n",
            " ['Smelt']\n",
            " ['Bream']\n",
            " ['Roach']\n",
            " ['Pike']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Smelt']\n",
            " ['Bream']\n",
            " ['Parkki']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Perch']\n",
            " ['Perch']]\n",
            "[[7.80000e+01 1.87000e+01 1.94000e+01 5.19920e+00 3.12340e+00]\n",
            " [1.34000e+01 1.24000e+01 1.35000e+01 2.43000e+00 1.26900e+00]\n",
            " [2.00000e+02 3.23000e+01 3.48000e+01 5.56800e+00 3.37560e+00]\n",
            " [2.70000e+02 2.60000e+01 2.87000e+01 8.38040e+00 4.24760e+00]\n",
            " [1.50000e+02 2.30000e+01 2.45000e+01 5.21850e+00 3.62600e+00]\n",
            " [1.00000e+03 3.70000e+01 4.26000e+01 1.89570e+01 6.60300e+00]\n",
            " [7.00000e+00 1.06000e+01 1.16000e+01 1.72840e+00 1.14840e+00]\n",
            " [1.80000e+02 2.52000e+01 2.79000e+01 7.08660e+00 3.90600e+00]\n",
            " [1.88000e+02 2.46000e+01 2.62000e+01 6.73340e+00 4.16580e+00]\n",
            " [1.25000e+03 5.60000e+01 5.97000e+01 1.06863e+01 6.98490e+00]\n",
            " [6.50000e+02 3.35000e+01 3.87000e+01 1.44738e+01 5.72760e+00]\n",
            " [1.00000e+03 4.00000e+01 4.35000e+01 1.23540e+01 6.52500e+00]\n",
            " [6.00000e+02 3.20000e+01 3.72000e+01 1.54380e+01 5.58000e+00]\n",
            " [1.50000e+02 2.00000e+01 2.24000e+01 8.89280e+00 3.29280e+00]\n",
            " [7.00000e+02 3.50000e+01 4.05000e+01 1.62405e+01 5.58900e+00]\n",
            " [9.20000e+02 3.85000e+01 4.41000e+01 1.80369e+01 6.30630e+00]\n",
            " [1.00000e+03 4.35000e+01 4.60000e+01 1.26040e+01 8.14200e+00]\n",
            " [2.18000e+02 2.65000e+01 2.80000e+01 7.16800e+00 4.14400e+00]\n",
            " [2.25000e+02 2.40000e+01 2.55000e+01 7.29300e+00 3.72300e+00]\n",
            " [7.00000e+02 3.30000e+01 3.83000e+01 1.48604e+01 5.28540e+00]\n",
            " [1.00000e+01 1.18000e+01 1.31000e+01 2.21390e+00 1.28380e+00]\n",
            " [6.10000e+02 3.35000e+01 3.86000e+01 1.56330e+01 5.13380e+00]\n",
            " [5.00000e+02 3.15000e+01 3.64000e+01 1.37592e+01 4.36800e+00]\n",
            " [5.00000e+02 3.07000e+01 3.62000e+01 1.42266e+01 4.95940e+00]\n",
            " [9.55000e+02 3.85000e+01 4.40000e+01 1.80840e+01 6.29200e+00]\n",
            " [1.10000e+03 4.30000e+01 4.55000e+01 1.25125e+01 7.41650e+00]\n",
            " [1.70000e+02 2.35000e+01 2.50000e+01 6.27500e+00 3.72500e+00]\n",
            " [2.70000e+02 2.65000e+01 2.93000e+01 8.14540e+00 4.24850e+00]\n",
            " [6.70000e+00 9.80000e+00 1.08000e+01 1.73880e+00 1.04760e+00]\n",
            " [9.90000e+00 1.18000e+01 1.31000e+01 2.21390e+00 1.16590e+00]\n",
            " [5.10000e+02 4.25000e+01 4.55000e+01 6.82500e+00 4.45900e+00]\n",
            " [7.00000e+01 1.74000e+01 1.85000e+01 4.58800e+00 2.94150e+00]\n",
            " [5.15000e+01 1.62000e+01 1.72000e+01 4.59240e+00 2.63160e+00]\n",
            " [5.67000e+02 4.60000e+01 4.87000e+01 7.79200e+00 4.87000e+00]\n",
            " [3.40000e+02 2.65000e+01 3.11000e+01 1.23778e+01 4.69610e+00]\n",
            " [1.20000e+02 2.20000e+01 2.35000e+01 6.11000e+00 3.40750e+00]\n",
            " [1.60000e+02 2.25000e+01 2.53000e+01 7.03340e+00 3.82030e+00]\n",
            " [1.20000e+02 2.10000e+01 2.37000e+01 6.11460e+00 3.29430e+00]\n",
            " [1.45000e+02 2.15000e+01 2.41000e+01 9.73640e+00 3.15710e+00]\n",
            " [8.20000e+02 3.90000e+01 4.13000e+01 1.24313e+01 7.35140e+00]] [['Perch']\n",
            " ['Smelt']\n",
            " ['Pike']\n",
            " ['Whitefish']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Smelt']\n",
            " ['Roach']\n",
            " ['Perch']\n",
            " ['Pike']\n",
            " ['Bream']\n",
            " ['Whitefish']\n",
            " ['Bream']\n",
            " ['Parkki']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Bream']\n",
            " ['Smelt']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Whitefish']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Pike']\n",
            " ['Perch']\n",
            " ['Perch']\n",
            " ['Pike']\n",
            " ['Bream']\n",
            " ['Perch']\n",
            " ['Roach']\n",
            " ['Roach']\n",
            " ['Parkki']\n",
            " ['Perch']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfIEQKqblFln"
      },
      "source": [
        "# 표준화 전처리가 필요함.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "\n",
        "ss.fit(train_input) # train_input 하나만 훈련하면 됨. 훈련한 리스트를 기준으로 테스트 할 리스트도 변환함.\n",
        "\n",
        "train_scaled = ss.transform(train_input)\n",
        "test_scaled = ss.transform(test_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH9dUXt5hila"
      },
      "source": [
        "## k-최근접 이웃 분류기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0-Hv_E2mx32"
      },
      "source": [
        "### k-최근접 이웃 분류기의 확률 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shaafpo5O0nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2804e80-18af-48f5-9643-c2c8643bc09c"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "kn = KNeighborsClassifier(n_neighbors = 3) # 최근접 이웃 개수인 k를 3으로 지정함.\n",
        "\n",
        "kn.fit(train_scaled, train_target)\n",
        "\n",
        "print(kn.score(train_scaled, train_target))\n",
        "print(kn.score(test_scaled, test_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8907563025210085\n",
            "0.85\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMGXhW2SWUeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed30fe0d-431d-4cde-9e30-fced3fa5f9f6"
      },
      "source": [
        "# 타깃값을 그대로 사이킷런 모델에 적용하면 순서가 자동으로 알파벳 순으로 정렬됨.\n",
        "# 'pd,unique(fish['Species'])' 로 출력했던 순서와 다름.\n",
        "# 정렬된 타깃값은 'classes_' 속성에 저장됨.\n",
        "print(kn.classes_) # Bream은 첫 번째 클래스, Parkki는 두 번째 클래스가 됨."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUkDJyI8As8j",
        "outputId": "83db7278-d892-4b73-c3f7-aa61485acee2"
      },
      "source": [
        "# 'predict()' 메서드는 test_scaled 값을 넣으면 예측을 타깃값으로 출력함.\n",
        "print(kn.predict(test_scaled[:5])) # 'kneighbors()' 메서드의 입력은 2차원 배열이어야 함. '슬라이싱 연산자' 를 사용해야 함.\n",
        "\n",
        "# 'predict_proba()' 메서드는 클래스별 확률값을 반환함.\n",
        "import numpy as np\n",
        "\n",
        "proba = kn.predict_proba(test_scaled[:5])\n",
        "\n",
        "print(proba)\n",
        "print(np.round(proba, decimals = 4))\n",
        "# 넘파이 'round()' 함수는 소수점 첫 번째 자리에서 반올림 함.\n",
        "# decimal은 십진법을 의미함. 'decimals' 매개변수로 유지할 소수점 아래 자릿수를 지정함.\n",
        "# 'decimals = 4' 는 소수점 네 번째 자리까지 표기함. 즉 다섯 번째 자리에서 반올림 함.\n",
        "\n",
        "# 'kn.classes_' 속성에 저장된 값의 순서로서 첫 번째 열은 Bream에 대한 확률, 두 번째 열은 Parkki에 대한 확률을 의미함.\n",
        "# 세 번째 속성인 Perch의 확률이 1이므로, 첫 번째 샘플은 Perch라고 예측하고 출력함."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']\n",
            "[[0.         0.         1.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         1.\n",
            "  0.        ]\n",
            " [0.         0.         0.         1.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.66666667 0.         0.33333333 0.\n",
            "  0.        ]\n",
            " [0.         0.         0.66666667 0.         0.33333333 0.\n",
            "  0.        ]]\n",
            "[[0.     0.     1.     0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     1.     0.    ]\n",
            " [0.     0.     0.     1.     0.     0.     0.    ]\n",
            " [0.     0.     0.6667 0.     0.3333 0.     0.    ]\n",
            " [0.     0.     0.6667 0.     0.3333 0.     0.    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eJogftlU2hK",
        "outputId": "f2ed6687-47e6-4fd6-9597-81d0acbca7ae"
      },
      "source": [
        "# 예측이 얼마나 맞는지 일일이 출력해 봄.\n",
        "distance, indexes = kn.kneighbors(test_scaled[0:1]) # 첫 번째 샘플의 최근접 이웃의 클래스를 확인함.\n",
        "\n",
        "print(kn.predict(test_scaled[:5]))\n",
        "\n",
        "print(test_target[0:1]) # Perch여야 함.\n",
        "\n",
        "print(distance)\n",
        "print(indexes)\n",
        "\n",
        "print(train_target[indexes]) # Perch(확률 1)로 맞게 예측함."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']\n",
            "[['Perch']]\n",
            "[[0.13880285 0.15188629 0.15908025]]\n",
            "[[39 64 63]]\n",
            "[[['Perch']\n",
            "  ['Perch']\n",
            "  ['Perch']]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbHKvYkbVDhM",
        "outputId": "d45ee03c-78fc-4eda-a329-cab63492191e"
      },
      "source": [
        "distance, indexes = kn.kneighbors(test_scaled[1:2]) # 두 번째 샘플의 최근접 이웃의 클래스를 확인함.\n",
        "\n",
        "print(kn.predict(test_scaled[:5]))\n",
        "\n",
        "print(test_target[1:2]) # Smelt여야 함.\n",
        "\n",
        "print(distance)\n",
        "print(indexes)\n",
        "\n",
        "print(train_target[indexes]) # Smelt(확률 1)로 맞게 예측함."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']\n",
            "[['Smelt']]\n",
            "[[0.07310337 0.10341686 0.11506625]]\n",
            "[[93 99 43]]\n",
            "[[['Smelt']\n",
            "  ['Smelt']\n",
            "  ['Smelt']]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1piQlXYLVMB6",
        "outputId": "5bdeb0b5-241a-471f-c76b-a8ecf84ce7cc"
      },
      "source": [
        "distance, indexes = kn.kneighbors(test_scaled[2:3]) # 세 번째 샘플의 최근접 이웃의 클래스를 확인함.\n",
        "\n",
        "print(kn.predict(test_scaled[:5]))\n",
        "\n",
        "print(test_target[2:3]) # Pike여야 함.\n",
        "\n",
        "print(distance)\n",
        "print(indexes)\n",
        "\n",
        "print(train_target[indexes]) # Pike(확률 1)로 맞게 예측함."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']\n",
            "[['Pike']]\n",
            "[[0.63337713 0.80646808 0.82050896]]\n",
            "[[100 105  27]]\n",
            "[[['Pike']\n",
            "  ['Pike']\n",
            "  ['Pike']]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvrFRvzmCzE7",
        "outputId": "b5e6532e-2fb9-4848-ba35-92da9a2003d1"
      },
      "source": [
        "distance, indexes = kn.kneighbors(test_scaled[3:4]) # 네 번째 샘플의 최근접 이웃의 클래스를 확인함.\n",
        "\n",
        "print(kn.predict(test_scaled[:5]))\n",
        "\n",
        "print(test_target[2:3]) # Whitefish여야 함.\n",
        "\n",
        "print(distance)\n",
        "print(indexes)\n",
        "\n",
        "print(train_target[indexes]) # Whitefish(확률 0)로 틀린 예측임. Roach(확률 0.33), Perch(확률 0.66)로 Perch로 예측함."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']\n",
            "[['Pike']]\n",
            "[[0.20774583 0.24862983 0.33682411]]\n",
            "[[104 115 106]]\n",
            "[[['Roach']\n",
            "  ['Perch']\n",
            "  ['Perch']]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWbqnNUHXCgY",
        "outputId": "8371dcb3-6e87-4c2e-9be6-8fd144480ae4"
      },
      "source": [
        "distance, indexes = kn.kneighbors(test_scaled[4:5]) # 다섯 번째 샘플의 최근접 이웃의 클래스를 확인함.\n",
        "\n",
        "print(kn.predict(test_scaled[:5]))\n",
        "\n",
        "print(test_target[4:5]) # Perch여야 함.\n",
        "\n",
        "print(distance)\n",
        "print(indexes)\n",
        "\n",
        "print(train_target[indexes]) # Perch(확률 0.66)로 맞게 예측함. Perch(확률 0.66), Roach(확률 0.33).\n",
        "# 3개의 최근접 이웃만 사용하므로 가능한 확률은 0/3, 1/3, 2/3, 3/3임. 더 좋은 방법을 찾아야 함."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']\n",
            "[['Perch']]\n",
            "[[0.17898697 0.1859878  0.19013472]]\n",
            "[[72 26 68]]\n",
            "[[['Perch']\n",
            "  ['Perch']\n",
            "  ['Roach']]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bDyJtZVEZjN"
      },
      "source": [
        "## 로지스틱 회귀(Logistic regression)\n",
        "- 이름만 회귀이고 분류 모델임.\n",
        "\n",
        "- 반복적인 알고리즘을 사용함.\n",
        "\n",
        "  - max_iter: 반복 횟수를 지정하는 매개변수. 기본값은 100.\n",
        "\n",
        "- 릿지 회귀처럼 계수의 제곱을 규제함. (L2 규제)\n",
        "\n",
        "  - C: 규제를 제어하는 매개변수. alpha와 반대로 값이 작을수록 규제가 커짐. 기본값은 1.\n",
        "\n",
        "- L2 규제(릿지 방식)과 L1 규제(라쏘 방식)을 선택할 수 있음.\n",
        "\n",
        "  - penalty: 규제 방식을 선택하는 매개변수. 기본값은 'l2'.\n",
        "\n",
        "- 사용할 알고리즘을 선택할 수 있음.\n",
        "\n",
        "   - solver: 사용할 알고리즘을 선택하는 매개변수. 기본값은 'lbfgs'. 확률적 평균 경사 하강법인 'saga' 를 선택할 수 있음. \n",
        "\n",
        "- 선형 회귀와 동일하게 선형 방정식을 학습함.\n",
        "\n",
        "  - E.g. $z = a * (Weight) + b * (Length) + c * (Diagonal) + d * (Height) + e * (Width) + f$\n",
        "\n",
        "  - a, b, c, d, e는 '가중치(계수)', f는 '절편'.\n",
        "\n",
        "  - 이진 분류의 경우 '로지스틱 함수(Logistic function)' = '시그모이드 함수(Sigmoid function)' 를 사용함.\n",
        "\n",
        "   확률인 0 ~ 1 사이 값으로 만들기 위해 사용함.\n",
        "\n",
        "   $1 / 1 + e^-z$ (선형 방정식의 출력 z의 음수를 사용하여 자연 상수 e를 거듭제곱하고 1을 더한 값의 역수를 취함.)\n",
        "  \n",
        "   z가 아주 큰 음수일 때 0, 아주 큰 양수일 때 1에 가까워짐.\n",
        "\n",
        "   z가 0일 때는 0.5가 됨.\n",
        "\n",
        "  - 다중 분류의 경우 '소프트맥스(Softmax)' = '정규화된 지수 함수' 를 사용함.\n",
        "\n",
        "   아래에서 상세하게 설명함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "iUCNXBkAEXpX",
        "outputId": "db8dc769-b5f0-4742-e3cc-072bcce33cc2"
      },
      "source": [
        "# '시그모이드 함수' 를 나타내는 그래프를 그림.\n",
        "# -5 ~ 5 사이를 0.1 간격으로 정하여 배열 z를 만들고, 다음 z 위치마다 시그모이드 함수를 계산함.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "z = np.arange(-5, 5, 0.1) # -5 ~ 5 범위를 0.1 간격으로 만듦.\n",
        "\n",
        "phi = 1 / (1 + np.exp(-z)) # np.exp(): 지수 함수를 계산함.\n",
        "print(np.exp(-z))\n",
        "\n",
        "plt.plot(z, phi)\n",
        "\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('phi')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.48413159e+02 1.34289780e+02 1.21510418e+02 1.09947172e+02\n",
            " 9.94843156e+01 9.00171313e+01 8.14508687e+01 7.36997937e+01\n",
            " 6.66863310e+01 6.03402876e+01 5.45981500e+01 4.94024491e+01\n",
            " 4.47011845e+01 4.04473044e+01 3.65982344e+01 3.31154520e+01\n",
            " 2.99641000e+01 2.71126389e+01 2.45325302e+01 2.21979513e+01\n",
            " 2.00855369e+01 1.81741454e+01 1.64446468e+01 1.48797317e+01\n",
            " 1.34637380e+01 1.21824940e+01 1.10231764e+01 9.97418245e+00\n",
            " 9.02501350e+00 8.16616991e+00 7.38905610e+00 6.68589444e+00\n",
            " 6.04964746e+00 5.47394739e+00 4.95303242e+00 4.48168907e+00\n",
            " 4.05519997e+00 3.66929667e+00 3.32011692e+00 3.00416602e+00\n",
            " 2.71828183e+00 2.45960311e+00 2.22554093e+00 2.01375271e+00\n",
            " 1.82211880e+00 1.64872127e+00 1.49182470e+00 1.34985881e+00\n",
            " 1.22140276e+00 1.10517092e+00 1.00000000e+00 9.04837418e-01\n",
            " 8.18730753e-01 7.40818221e-01 6.70320046e-01 6.06530660e-01\n",
            " 5.48811636e-01 4.96585304e-01 4.49328964e-01 4.06569660e-01\n",
            " 3.67879441e-01 3.32871084e-01 3.01194212e-01 2.72531793e-01\n",
            " 2.46596964e-01 2.23130160e-01 2.01896518e-01 1.82683524e-01\n",
            " 1.65298888e-01 1.49568619e-01 1.35335283e-01 1.22456428e-01\n",
            " 1.10803158e-01 1.00258844e-01 9.07179533e-02 8.20849986e-02\n",
            " 7.42735782e-02 6.72055127e-02 6.08100626e-02 5.50232201e-02\n",
            " 4.97870684e-02 4.50492024e-02 4.07622040e-02 3.68831674e-02\n",
            " 3.33732700e-02 3.01973834e-02 2.73237224e-02 2.47235265e-02\n",
            " 2.23707719e-02 2.02419114e-02 1.83156389e-02 1.65726754e-02\n",
            " 1.49955768e-02 1.35685590e-02 1.22773399e-02 1.11089965e-02\n",
            " 1.00518357e-02 9.09527710e-03 8.22974705e-03 7.44658307e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEp8K0HBMnU_"
      },
      "source": [
        "### 이진 분류 수행하기\n",
        "\n",
        "- 이진 분류일 경우 '시그모이드 함수'의 출력이 0.5보다 크면 양성 클래스, 0.5보다 작으면 음성 클래스임.\n",
        "\n",
        " (사이킷런의 경우 0.5는 음성 클래스로 판단함.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcAZl9END_PB"
      },
      "source": [
        "#### 불리언 인덱싱으로 특정 샘플 고르기\n",
        "\n",
        " - 불리언 인덱싱(Boolean indexing): True와 False로 구성된 1차원 배열을 활용하여 True에 해당하는 행을 선택함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23PIgyJYMjSY",
        "outputId": "06698c24-e89a-4dc5-ce38-9690ab523a87"
      },
      "source": [
        "char_arr = np.array(['A', 'B', 'C', 'D' ,'E'])\n",
        "\n",
        "print(char_arr[[True, False, True, False, False]])\n",
        "# True를 전달한 배열에 속한 원소를 출력함."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A' 'C']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdckOj-6OUBq",
        "outputId": "52e86557-15ff-4798-c6dc-af0c49791cec"
      },
      "source": [
        "# '불리언 인덱싱' 을 사용하여 도미(Bream)와 빙어(Smelt) 행만 골라냄.\n",
        "bream_smelt_indexes = (train_target == 'Bream') | (train_target == 'Smelt') # Bream인 행과 Smelt인 행을 비교 연산자인 OR(|)을 사용하여 합쳐서 True로 출력함.\n",
        "# True와 False로 이루어진 (119, 1)이라는 2차원 리스트가 만들어짐. 2차원 배열로는 불리언 인덱싱을 할 수 없음.\n",
        "# 2차원 배열이 만들어지는 이유는 잘 모르겠음. 어쨌든 1차원(119,)으로 줄여야 함.\n",
        "bream_smelt_indexes = bream_smelt_indexes.reshape(-1) # 'bream_smelt_indexes.flatten()' 과 'bream_smelt_indexes.ravel()' 도 1차원으로 줄이는 함수임.\n",
        "\n",
        "print(bream_smelt_indexes)\n",
        "\n",
        "# 골라 낸 행(True)을 훈련 세트에 전달하여 Bream과 Smelt만 따로 훈련해 봄.\n",
        "train_bream_smelt = train_scaled[bream_smelt_indexes] # 인덱싱이므로 []를 사용해야 함. ()는 적용되지 않음.\n",
        "target_bream_smelt = train_target[bream_smelt_indexes]\n",
        "\n",
        "print(train_bream_smelt)\n",
        "print(target_bream_smelt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True False  True False False False False  True False False False  True\n",
            " False False False  True  True False False  True False  True False False\n",
            " False  True False False  True False False False False  True False False\n",
            "  True  True False False False False False  True False False False False\n",
            " False  True False  True False False  True False False False  True False\n",
            " False False False False False  True False  True False False False False\n",
            " False False False False False  True False  True False False  True  True\n",
            " False False False  True False False False False False  True False False\n",
            " False  True False  True False False  True  True False False False False\n",
            " False False False False  True  True False False  True False False]\n",
            "[[ 0.91965782  0.60943175  0.81041221  1.85194896  1.00075672]\n",
            " [-1.0858536  -1.68646987 -1.70848587 -1.70159849 -2.0044758 ]\n",
            " [ 0.63818253  0.56257661  0.73223951  1.64473401  0.50705737]\n",
            " [ 0.30041219  0.23459067  0.42823457  1.36042157  0.22329758]\n",
            " [ 0.9027693   0.70314202  0.88858491  1.89027545  0.85537174]\n",
            " [-1.0824759  -1.61150165 -1.62162731 -1.7000674  -1.92815631]\n",
            " [ 0.10337949  0.04717013  0.23714575  0.88445197  0.41799764]\n",
            " [ 1.49668216  1.03112796  1.21864741  2.44274986  1.40289707]\n",
            " [ 0.23004337  0.23459067  0.42823457  1.3336029   0.39983213]\n",
            " [-0.42579405 -0.29018684 -0.11028847  0.65627104 -0.26107519]\n",
            " [ 1.28557569  0.70314202  0.89727076  1.98228866  1.06683526]\n",
            " [ 0.93373158  0.60943175  0.83646978  1.85150445  0.97832415]\n",
            " [ 0.80706771  0.60943175  0.81041221  1.63137406  1.0255057 ]\n",
            " [-1.07262426 -1.52716241 -1.55214047 -1.67235972 -1.86207776]\n",
            " [ 1.6374198   1.17169337  1.27076255  2.41341232  1.40143407]\n",
            " [-1.07966115 -1.63961473 -1.67374245 -1.6462819  -1.87036806]\n",
            " [-1.05151362 -1.33037084 -1.39579507 -1.47914678 -1.45146425]\n",
            " [ 0.15967454  0.11276732  0.29794674  1.17051775  0.29205828]\n",
            " [ 1.56705098  1.17169337  1.32287768  2.16352457  1.17174409]\n",
            " [-0.00921063  0.1408804   0.3240043   0.94026245  0.14734384]\n",
            " [ 0.15967454  0.1408804   0.33269016  1.26991474  0.24109734]\n",
            " [-0.14994827  0.32830094  0.52377898  1.24719543  0.3806913 ]\n",
            " [-0.08520896  0.04717013  0.19371647  0.95507939  0.00439718]\n",
            " [ 0.86336276  0.42201121  0.62800925  1.5003429   0.45670601]\n",
            " [ 0.30041219  0.11276732  0.28057503  1.31303204  0.50608204]\n",
            " [-1.07262426 -1.45219419 -1.51739705 -1.62627903 -1.94607798]\n",
            " [ 0.82114147  0.51572148  0.68881023  1.76102232  0.5621025 ]\n",
            " [-1.07937967 -1.54590446 -1.56951218 -1.64420753 -2.01154694]\n",
            " [-1.07937967 -1.62087268 -1.63899902 -1.67413775 -1.93303295]\n",
            " [-0.29068592 -0.2058476  -0.0060582   0.89334213 -0.08697896]\n",
            " [-1.05095067 -1.26477365 -1.30893652 -1.46447801 -1.56606541]\n",
            " [ 0.51151865  0.51572148  0.7148678   1.54738669  0.68347   ]\n",
            " [ 0.58188748  0.32830094  0.51509312  1.50439286  0.4404302 ]]\n",
            "[['Bream']\n",
            " ['Smelt']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Smelt']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Smelt']\n",
            " ['Bream']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Bream']\n",
            " ['Smelt']\n",
            " ['Bream']\n",
            " ['Smelt']\n",
            " ['Smelt']\n",
            " ['Bream']\n",
            " ['Smelt']\n",
            " ['Bream']\n",
            " ['Bream']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiVeXJrFIIZd"
      },
      "source": [
        "#### 로지스틱 회귀 모델 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMXiAmDPC04-",
        "outputId": "cd34c577-9d27-4d19-b10f-e895b15e935b"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "lr.fit(train_bream_smelt, target_bream_smelt)\n",
        "\n",
        "print(lr.predict(train_bream_smelt[:5]))\n",
        "print(lr.predict_proba(train_bream_smelt[:5]))\n",
        "\n",
        "print(lr.classes_)\n",
        "# 이진 분류이므로 알파벳순인 Bream이 음성 클래스(0), Smelt가 양성 클래스(1)임.\n",
        "# Bream을 양성 클래스로 사용하려면 Bream의 타깃값을 1로 만들고 나머지는 0으로 만들면 됨."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bream' 'Smelt' 'Bream' 'Bream' 'Bream']\n",
            "[[0.99759855 0.00240145]\n",
            " [0.02735183 0.97264817]\n",
            " [0.99486072 0.00513928]\n",
            " [0.98584202 0.01415798]\n",
            " [0.99767269 0.00232731]]\n",
            "['Bream' 'Smelt']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjfzINspf94U"
      },
      "source": [
        "##### 시그모이드 함수에 적용하여 확률 얻기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR0ClXicKKRq",
        "outputId": "524f276c-3c28-435f-ad61-591e9f300092"
      },
      "source": [
        "# 로지스틱 회귀가 학습한 '계수' 를 확인함.\n",
        "print(lr.coef_, lr.intercept_)\n",
        "# z = -0.404 * Weight - 0.576 * Length - 0.663 * Diagonal - 1.013 * Height - 0.732 * Width - 2.161"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.4037798  -0.57620209 -0.66280298 -1.01290277 -0.73168947]] [-2.16155132]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_AaTFKmLcAW",
        "outputId": "6e11fcc5-7ade-44a8-c633-9e31fedae6b4"
      },
      "source": [
        "# 'decision_function()' 메서드로 양성 클래스에 대한 z값을 출력함.\n",
        "decisions = lr.decision_function(train_bream_smelt[:5])\n",
        "print(decisions)\n",
        "# 이 z값을 시그모이드 함수에 적용하면 확률을 얻을 수 있음."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-6.02927744  3.57123907 -5.26568906 -4.24321775 -6.0607117 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWR8sp48NqJI",
        "outputId": "6aa57587-7d28-4ec7-ef66-d2e9fb7a518a"
      },
      "source": [
        "# z값을 '시그모이드 함수' 에 적용하여 확률을 얻음.\n",
        "from scipy.special import expit # expit(): 시그모이드 함수. 1 / (1 + np.exp(-z))보다 편리하고 안전함.\n",
        "print(expit(decisions))\n",
        "# 'predict_proba()' 메서드가 출력한 두 번째 열의 값(양성 클래스)과 동일함."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z2jbylXNTT3"
      },
      "source": [
        "### 다중 분류 수행하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgKF2PHOgk0p"
      },
      "source": [
        "#### 로지스틱 회귀 모델 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zftsNU9COa42",
        "outputId": "077c7328-dfb8-4e09-dc80-b8335a6f79e8"
      },
      "source": [
        "# 이진 분류 과정과 크게 다르지 않음.\n",
        "lr = LogisticRegression(C = 20, max_iter = 1000) # 규제를 완화하고자 'C'를 20으로 늘리고, 충분히 훈련하고자 'max_iter' 를 1000으로 늘림.\n",
        "\n",
        "lr.fit(train_scaled, train_target) # 이진 분류와 달리 7개 생선 데이터를 사용함.\n",
        "\n",
        "print(lr.score(train_scaled, train_target))\n",
        "print(lr.score(test_scaled, test_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9327731092436975\n",
            "0.925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HVwMHaDTD3u",
        "outputId": "0e003101-cdd2-48fa-d871-c67c83fe701a"
      },
      "source": [
        "print(lr.predict(test_scaled[:5]))\n",
        "\n",
        "proba = lr.predict_proba(test_scaled[:5])\n",
        "print(proba)\n",
        "print(np.round(proba, decimals = 3))\n",
        "\n",
        "print(lr.classes_) # 첫 번째 예측의 경우 0.841로 Perch로 예측함."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Perch' 'Smelt' 'Pike' 'Roach' 'Perch']\n",
            "[[7.24997035e-06 1.35120247e-02 8.41274752e-01 3.14318278e-04\n",
            "  1.35668463e-01 6.67127629e-03 2.55191550e-03]\n",
            " [7.15098082e-09 2.55595742e-03 4.39087249e-02 3.37993009e-05\n",
            "  7.31059778e-03 9.46185658e-01 5.25557023e-06]\n",
            " [1.86557390e-05 2.79656281e-06 3.40599281e-02 9.34804690e-01\n",
            "  1.50477398e-02 1.60365274e-02 2.96620003e-05]\n",
            " [1.09325104e-02 3.40496773e-02 3.05542864e-01 6.60897368e-03\n",
            "  5.66578556e-01 6.87249396e-05 7.62186940e-02]\n",
            " [4.48987235e-06 3.67288298e-04 9.04002989e-01 2.41270143e-03\n",
            "  8.94740262e-02 2.40965058e-03 1.32885484e-03]]\n",
            "[[0.    0.014 0.841 0.    0.136 0.007 0.003]\n",
            " [0.    0.003 0.044 0.    0.007 0.946 0.   ]\n",
            " [0.    0.    0.034 0.935 0.015 0.016 0.   ]\n",
            " [0.011 0.034 0.306 0.007 0.567 0.    0.076]\n",
            " [0.    0.    0.904 0.002 0.089 0.002 0.001]]\n",
            "['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B_X4Vs4gZqk"
      },
      "source": [
        "##### 소프트맥스 함수에 적용하여 확률 얻기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u22Hi3CeUkAa",
        "outputId": "96342540-458b-4846-dc41-7dec06ace12f"
      },
      "source": [
        "print(lr.coef_, lr.intercept_)\n",
        "# 특성 5개를 사용하므로 'coef_' 의 열은 5개임.\n",
        "# 행이 7개(클래스 7개)인 건 z를 7개 계산한다는 의미임. 다중 분류는 클래스마다 z값을 하나씩 계산함.\n",
        "# 가장 높은 z값을 출력하는 클래스가 예측 클래스(예측한 값, 타깃)가 됨.\n",
        "# 이진 분류는 '시그모이드 함수' 를 사용하여 하나의 선형 방정식의 출력값(z)을 0 ~ 1 사이(확률)로 압축했지만,\n",
        "# 다중 분류는 '소프트맥스(softmax) 함수' 를 사용하여 여러 개의 선형 방정식의 출력값(z)을 0 ~ 1 사이(확률)로 압축함.\n",
        "# 지수 함수를 사용하므로 '정규화된 지수 함수' 라고도 함.\n",
        "\n",
        "# z값 7개의 이름을 z1 ~ z7로 붙임.\n",
        "# z1 ~ z7 값을 사용하여 지수 함수 e^z1 ~ e^z7을 계산하여 모두 더함. 이를 e_sum으로 정함.\n",
        "# e_sum = e^z1 + e^z2 + e^z3 + e^z4 + e^z5 + e^z6 + e^z7\n",
        "\n",
        "# 그리고 나서 e^z1 ~ e^z7을 각각 e_sum으로 나눔.\n",
        "# s1 = e^z1 / e_sum\n",
        "# s2 = e^z2 / e_sum\n",
        "# .\n",
        "# .\n",
        "# .\n",
        "# s7 = e^z7 / e_sum\n",
        "\n",
        "# 마지막으로 s1 ~ s7까지 더하면 분자와 분모가 같아지면서 1이 됨. 즉 생선 7개의 확률 합은 1임."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.49002911 -1.02919221  2.59351113  7.70354318 -1.20068079]\n",
            " [ 0.19619256 -2.0106062  -3.77982687  6.50490143 -1.99486463]\n",
            " [ 3.56278472  6.34361428 -8.48973364 -5.75756295  3.79309039]\n",
            " [-0.10458533  3.60316654  3.93067417 -3.61731229 -1.75070607]\n",
            " [-1.40059104 -6.07505264  5.25967743 -0.87222909  1.86043657]\n",
            " [-1.38528628  1.49217379  1.3922839  -5.67732641 -4.40095877]\n",
            " [ 0.62151448 -2.32410356 -0.90658611  1.71598614  3.69368329]] [-0.09204845 -0.26290731  3.25101057 -0.14742485  2.65496057 -6.78780765\n",
            "  1.38421712]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zop9qr4lfljg",
        "outputId": "4bcc2dc0-6f3d-4801-b756-0bc6150f1e7b"
      },
      "source": [
        "# 'decision_function()' 메서드로 z1 ~ z7 의 값을 구하고 소프트맥스 함수를 사용하여 확률로 바꿈.\n",
        "decision = lr.decision_function(test_scaled[:5])\n",
        "print(np.round(decision, decimals = 2))\n",
        "\n",
        "from scipy.special import softmax\n",
        "\n",
        "proba = softmax(decision, axis = 1) # 'axis' 매개변수를 1로 지정하여 각 행(샘플)에 대해 계산함. 그렇지 않으면 배열 전체에 대해 소프트맥스를 계산함.\n",
        "print(np.round(proba, decimals = 3))\n",
        "# 위에서 lr로 훈련하고 predict_proba로 예측한 결과와 같은 값을 출력함."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ -6.5    1.03   5.16  -2.73   3.34   0.33  -0.63]\n",
            " [-10.86   1.93   4.77  -2.4    2.98   7.84  -4.26]\n",
            " [ -4.34  -6.23   3.17   6.49   2.36   2.42  -3.87]\n",
            " [ -0.68   0.45   2.65  -1.19   3.26  -5.75   1.26]\n",
            " [ -6.4   -1.99   5.82  -0.11   3.5   -0.11  -0.71]]\n",
            "[[0.    0.014 0.841 0.    0.136 0.007 0.003]\n",
            " [0.    0.003 0.044 0.    0.007 0.946 0.   ]\n",
            " [0.    0.    0.034 0.935 0.015 0.016 0.   ]\n",
            " [0.011 0.034 0.306 0.007 0.567 0.    0.076]\n",
            " [0.    0.    0.904 0.002 0.089 0.002 0.001]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}